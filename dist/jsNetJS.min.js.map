{"version":3,"sources":["jsNetJS.concat.js"],"names":["ConvLayer","[object Object]","size","filterSize","zeroPadding","stride","activation","this","activationName","undefined","NetMath","NetUtil","format","bind","state","layer","nextLayer","layerIndex","prevLayer","net","conv","FCLayer","channels","PoolLayer","activations","length","Math","floor","prevLayerOutWidth","max","sqrt","outMapSize","inMapValuesCount","pow","inZPMapValuesCount","Error","filters","Array","map","f","Filter","forEach","filter","weights","channelWeights","weightsRow","weightsInitFn","weightsConfig","activationMap","row","v","errorMap","bias","dropout","dropoutMap","init","updateFn","activationConfig","eluAlpha","getActivations","filterI","sumMap","convolve","input","sumY","sumX","random","emY","emX","weightIndex","neuronI","neurons","neuron","error","buildConvErrorMap","col","errors","buildConvDWeights","deltaBias","channel","deltaWeights","l2Error","l2","l1Error","l1","abs","regularized","miniBatchSize","weightUpdateFn","maxNorm","maxNormTotal","validationBias","validationWeights","wd","wy","slice","data","fi","c","r","push","valI","window","exports","n","Neuron","weightsCount","ni","dropped","sum","ai","derivative","reduce","p","wi","dwi","w","Layer","wRow","biasGain","weightGains","getWeightGain","column","setWeightGain","biasCache","weightsCache","getWeightsCache","setWeightsCache","adadeltaBiasCache","adadeltaCache","getAdadeltaCache","setAdadeltaCache","m","rreluSlope","InputLayer","span","super","value","prime","val","exp","lreluSlope","sech","tanh","elu","target","output","vi","log","calculated","desired","index","prev","curr","meansquarederror","deltaValue","learningRate","weightI","newVal","min","rmsDecay","mt","iterations","vt","rho","momentum","limit","values","i","mean","stdDeviation","x1","x2","fanIn","fanOut","gaussian","lecunnormal","uniform","lecununiform","rowStart","colStart","filterRow","filterCol","indeces","maxValue","exponentials","exponentialsSum","e","arr","avg","diffs","multiplier","layers","li","setWeight","getWeight","type","replace","toLowerCase","date","Date","formatted","getMilliseconds","getSeconds","getHours","getMinutes","join","j","x","zP","extraRows","splice","vol","mapValues","d","inputVol","arrayToVolume","outputMap","paddedLength","fSSpread","di","addZeroPadding","inputY","inputX","weightsY","weightsX","outY","outX","paddedRow","nlFilterI","errMap","emYI","channelsCount","channelI","inputValues","inputMap","arrayToMap","eY","eX","mapStartI","mapSize","returnArr","arguments","rowI","colI","training","validation","test","split","minVal","Infinity","maxVal","originalData","total","totalCorrect","rowTotal","count","percent","correctPercent","correct","wrong","bottomRow","columnTotal","toFixed","console","table","padNum","num","toString","leftPad","rightPad","repeat","colourText","colourBackground","process","stdout","write","Network","cost","pool","epochs","validations","includes","distribution","every","item","Number","isInteger","initLayers","collectedErrors","expected","ceil","joinLayer","outSize","trainingConfusionMatrix","testConfusionMatrix","validationConfusionMatrix","Object","assign","assignNext","assignPrev","isArray","flat","warn","forward","backward","dataSet","callback","callbackInterval","collectErrors","shuffle","Promise","resolve","reject","interval","earlyStopping","threshold","patienceCounter","bestError","patience","elapsed","iterationIndex","epochsCounter","startTime","now","logAndResolve","l","restoreValidation","doEpoch","validationError","doIteration","async","hasOwnProperty","trainingError","classification","indexOf","validate","checkEarlyStopping","applyDeltaWeights","resetDeltaWeights","setTimeout","text","validationIndex","totalValidationErrors","validateItem","lastValidationError","stop","backUpValidation","testSet","totalError","testInput","iterationError","toJSON","fromJSON","IMGArrays","opts","layerData","toIMG","rawData","fromIMG","dataCount","getDataSize","printConfusionMatrix","makeConfusionMatrix","version","OutputLayer","softmax","s","constructor","name","maxPool","errs"],"mappings":"AAAA,mBAEMA,UAEFC,YAAaC,MAAMC,WAACA,WAAUC,YAAEA,YAAWC,OAAEA,OAAMC,WAAEA,gBAE7CH,aAAgBI,KAAKJ,WAAaA,YAClCE,SAAgBE,KAAKF,OAASA,QAC9BH,OAAgBK,KAAKL,KAAOA,MAEhCK,KAAKH,YAAcA,YACnBG,KAAKC,eAAiBF,gBAENG,GAAZH,aAKIC,KAAKD,aAHc,kBAAZA,aAA0BA,cAGI,mBAAZA,WAAyBA,WAAaI,QAAQC,QAAQC,OAAON,aAAaO,KAAKN,QAIhHA,KAAKO,MAAQ,kBAGjBb,WAAYc,OACRR,KAAKS,UAAYD,MAGrBd,WAAYc,MAAOE,YASf,OAPAV,KAAKW,UAAYH,MAEjBR,KAAKU,WAAaA,WAClBV,KAAKL,KAAOK,KAAKL,MAAQ,EACzBK,KAAKJ,WAAaI,KAAKJ,YAAcI,KAAKY,IAAIC,KAAKjB,YAAc,EACjEI,KAAKF,OAASE,KAAKF,QAAUE,KAAKY,IAAIC,KAAKf,QAAU,GAE7C,GACJ,KAAKU,iBAAiBM,QAClBd,KAAKe,SAAWf,KAAKY,IAAIG,UAAW,EACpC,MAEJ,KAAKP,iBAAiBf,UAClBO,KAAKe,SAAWP,MAAMb,KACtB,MAEJ,KAAKa,iBAAiBQ,UAClBhB,KAAKe,SAAWP,MAAMS,YAAYC,YAIpBhB,GAAlBF,KAAKH,cACLG,KAAKH,iBAAyCK,GAA3BF,KAAKY,IAAIC,KAAKhB,YAAyBsB,KAAKC,MAAMpB,KAAKJ,WAAW,GAAKI,KAAKY,IAAIC,KAAKhB,aAI5G,MAAMwB,kBAAoBb,iBAAiBM,QAAUK,KAAKG,IAAIH,KAAKC,MAAMD,KAAKI,KAAKf,MAAMb,KAAKK,KAAKe,WAAY,GAC1DP,MAAMgB,WAM3D,GAJAxB,KAAKyB,iBAAmBN,KAAKO,IAAIL,kBAAmB,GACpDrB,KAAK2B,mBAAqBR,KAAKO,IAAIL,kBAAqC,EAAjBrB,KAAKH,YAAe,GAC3EG,KAAKwB,YAAcH,kBAAoBrB,KAAKJ,WAAa,EAAEI,KAAKH,aAAeG,KAAKF,OAAS,EAEzFE,KAAKwB,WAAW,GAAG,EACnB,MAAM,IAAII,8EAA8E5B,KAAKwB,qCAAqCd,cAGtIV,KAAK6B,YAAc,IAAIC,MAAM9B,KAAKL,OAAOoC,IAAIC,GAAK,IAAIC,QAG1DvC,OACIM,KAAK6B,QAAQK,QAAQC,SAEjBA,OAAOC,YAAc,IAAIN,MAAM9B,KAAKe,WAAWgB,IAAIM,oBACpC,IAAIP,MAAM9B,KAAKJ,aAAamC,IAAIO,YAActC,KAAKY,IAAI2B,cAAcvC,KAAKJ,WAAYI,KAAKwC,iBAG1GL,OAAOM,kBAAoB,IAAIX,MAAM9B,KAAKwB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM9B,KAAKwB,aAAaO,IAAIY,GAAK,IAC3GR,OAAOS,aAAe,IAAId,MAAM9B,KAAKwB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM9B,KAAKwB,aAAaO,IAAIY,GAAK,IACtGR,OAAOU,KAAO,EAEU,GAApB7C,KAAKY,IAAIkC,UACTX,OAAOY,WAAaZ,OAAOM,cAAcV,IAAIW,KAAOA,IAAIX,IAAIY,IAAK,KAGrER,OAAOa,MACHC,SAAUjD,KAAKY,IAAIqC,SACnBlD,WAAYC,KAAKC,gBAAkBD,KAAKY,IAAIsC,iBAC5CC,SAAUnD,KAAKY,IAAIuC,aAK/BzD,UAEI,MAAMuB,YAAcb,QAAQgD,eAAepD,KAAKW,WAEhD,IAAK,IAAI0C,QAAQ,EAAGA,QAAQrD,KAAKL,KAAM0D,UAAW,CAE9C,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAE5BlB,OAAOmB,OAASlD,QAAQmD,UACpBC,MAAOvC,YACPpB,YAAaG,KAAKH,YAClBuC,QAASD,OAAOC,QAChBrB,SAAUf,KAAKe,SACfjB,OAAQE,KAAKF,OACb+C,KAAMV,OAAOU,OAGjB,IAAK,IAAIY,KAAK,EAAGA,KAAKtB,OAAOmB,OAAOpC,OAAQuC,OACxC,IAAK,IAAIC,KAAK,EAAGA,KAAKvB,OAAOmB,OAAOpC,OAAQwC,OACxB,YAAZ1D,KAAKO,OAAqB4B,OAAOY,aAAeZ,OAAOY,WAAWU,MAAMC,MAAQvC,KAAKwC,SAAW3D,KAAKY,IAAIkC,SACzGX,OAAOM,cAAcgB,MAAMC,MAAQ,EAC5B1D,KAAKD,WACZoC,OAAOM,cAAcgB,MAAMC,MAAQ1D,KAAKD,WAAWoC,OAAOmB,OAAOG,MAAMC,OAAO,EAAOvB,SAAWnC,KAAKY,IAAIkC,SAAS,GAElHX,OAAOM,cAAcgB,MAAMC,MAAQvB,OAAOmB,OAAOG,MAAMC,OAO3EhE,WAGI,GAAIM,KAAKS,qBAAqBK,QAG1B,IAAK,IAAIuC,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAAW,CAExD,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAE5B,IAAK,IAAIO,IAAI,EAAGA,IAAIzB,OAAOS,SAAS1B,OAAQ0C,MACxC,IAAK,IAAIC,IAAI,EAAGA,IAAI1B,OAAOS,SAAS1B,OAAQ2C,MAAO,CAE/C,MAAMC,YAAcT,QAAUrD,KAAKwB,YAAY,EAAIoC,IAAMzB,OAAOS,SAAS1B,OAAS2C,IAElF,IAAK,IAAIE,QAAQ,EAAGA,QAAQ/D,KAAKS,UAAUuD,QAAQ9C,OAAQ6C,UAAW,CAElE,MAAME,OAASjE,KAAKS,UAAUuD,QAAQD,SACtC5B,OAAOS,SAASgB,KAAKC,MAAQI,OAAOC,MAAQD,OAAO7B,QAAQ0B,oBAMxE,GAAI9D,KAAKS,qBAAqBhB,UAEjC,IAAK,IAAI4D,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAC7CjD,QAAQ+D,kBAAkBnE,KAAKS,UAAWT,KAAK6B,QAAQwB,SAAST,SAAUS,cAK9E,IAAK,IAAIA,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAAW,CAExD,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAE5B,IAAK,IAAIX,IAAI,EAAGA,IAAIP,OAAOS,SAAS1B,OAAQwB,MACxC,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOS,SAAS1B,OAAQkD,MACxCjC,OAAOS,SAASF,KAAK0B,KAAOpE,KAAKS,UAAU4D,OAAOhB,SAASX,KAAK0B,KAOhF,IAAK,IAAIf,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAAW,CAExD,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAE5B,IAAK,IAAIX,IAAI,EAAGA,IAAIP,OAAOS,SAAS1B,OAAQwB,MACxC,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOS,SAAS,GAAG1B,OAAQkD,MAEvCjC,OAAOY,YAAcZ,OAAOY,WAAWL,KAAK0B,KAC5CjC,OAAOS,SAASF,KAAK0B,KAAO,EACrBpE,KAAKD,aACZoC,OAAOS,SAASF,KAAK0B,MAAQpE,KAAKD,WAAWoC,OAAOmB,OAAOZ,KAAK0B,MAAM,EAAMjC,SAO5F/B,QAAQkE,kBAAkBtE,MAG9BN,oBACI,IAAK,IAAI2D,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAAW,CAExD,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAC5BlB,OAAOoC,UAAY,EAEnB,IAAK,IAAIC,QAAQ,EAAGA,QAAQrC,OAAOsC,aAAavD,OAAQsD,UACpD,IAAK,IAAI9B,IAAI,EAAGA,IAAIP,OAAOsC,aAAa,GAAGvD,OAAQwB,MAC/C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOsC,aAAa,GAAG,GAAGvD,OAAQkD,MAClDjC,OAAOsC,aAAaD,SAAS9B,KAAK0B,KAAO,EAKrD,IAAK,IAAI1B,IAAI,EAAGA,IAAIP,OAAOS,SAAS1B,OAAQwB,MACxC,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOS,SAAS1B,OAAQkD,MACxCjC,OAAOS,SAASF,KAAK0B,KAAO,EAIpC,GAAIjC,OAAOY,WACP,IAAK,IAAIL,IAAI,EAAGA,IAAIP,OAAOY,WAAW7B,OAAQwB,MAC1C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOY,WAAW,GAAG7B,OAAQkD,MAC7CjC,OAAOY,WAAWL,KAAK0B,MAAO,GAOlD1E,oBACI,IAAK,IAAI2D,QAAQ,EAAGA,QAAQrD,KAAK6B,QAAQX,OAAQmC,UAAW,CAExD,MAAMlB,OAASnC,KAAK6B,QAAQwB,SAE5B,IAAK,IAAImB,QAAQ,EAAGA,QAAQrC,OAAOsC,aAAavD,OAAQsD,UACpD,IAAK,IAAI9B,IAAI,EAAGA,IAAIP,OAAOsC,aAAa,GAAGvD,OAAQwB,MAC/C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOsC,aAAa,GAAG,GAAGvD,OAAQkD,MAAO,MAEnClE,GAAlBF,KAAKY,IAAI8D,UAAoB1E,KAAKY,IAAI8D,SAAW,GAAM1E,KAAKY,IAAI+D,GAAKxC,OAAOC,QAAQoC,SAAS9B,KAAK0B,MAAM,QACtFlE,GAAlBF,KAAKY,IAAIgE,UAAoB5E,KAAKY,IAAIgE,SAAW5E,KAAKY,IAAIiE,GAAK1D,KAAK2D,IAAI3C,OAAOC,QAAQoC,SAAS9B,KAAK0B,OAEzG,MAAMW,aAAe5C,OAAOsC,aAAaD,SAAS9B,KAAK0B,KACjDpE,KAAKY,IAAI+D,GAAKxC,OAAOC,QAAQoC,SAAS9B,KAAK0B,KAC3CpE,KAAKY,IAAIiE,IAAM1C,OAAOC,QAAQoC,SAAS9B,KAAK0B,KAAO,EAAI,GAAK,IAAMpE,KAAKY,IAAIoE,cAEjF7C,OAAOC,QAAQoC,SAAS9B,KAAK0B,KAAOpE,KAAKY,IAAIqE,eAAe3E,KAAKN,KAAKY,IAAKuB,OAAOC,QAAQoC,SAAS9B,KAAK0B,KAChEW,YAAa5C,QAASqC,QAAS9B,IAAK0B,KADxCpE,QAGdE,GAAlBF,KAAKY,IAAIsE,UAAoBlF,KAAKY,IAAIuE,cAAgBhD,OAAOC,QAAQoC,SAAS9B,KAAK0B,MAAM,GAKzGjC,OAAOU,KAAO7C,KAAKY,IAAIqE,eAAe3E,KAAKN,KAAKY,IAAKuB,OAAOU,KAAMV,OAAOoC,UAAWpC,OAAtEnC,IAItBN,mBACI,IAAK,IAAIsC,EAAE,EAAGA,EAAEhC,KAAK6B,QAAQX,OAAQc,IAAK,CACtC,MAAMG,OAASnC,KAAK6B,QAAQG,GAE5BG,OAAOiD,eAAiBjD,OAAOU,KAC/BV,OAAOkD,qBAEP,IAAK,IAAIC,GAAG,EAAGA,GAAGnD,OAAOC,QAAQlB,OAAQoE,KAAM,CAC3C,MAAMd,WACN,IAAK,IAAIe,GAAG,EAAGA,GAAGpD,OAAOC,QAAQkD,IAAIpE,OAAQqE,KACzCf,QAAQe,IAAMpD,OAAOC,QAAQkD,IAAIC,IAAIC,MAAM,GAE/CrD,OAAOkD,kBAAkBC,IAAMd,UAK3C9E,oBACI,IAAK,IAAIsC,EAAE,EAAGA,EAAEhC,KAAK6B,QAAQX,OAAQc,IAAK,CACtC,MAAMG,OAASnC,KAAK6B,QAAQG,GAE5BG,OAAOU,KAAOV,OAAOiD,eAErB,IAAK,IAAIE,GAAG,EAAGA,GAAGnD,OAAOC,QAAQlB,OAAQoE,KACrC,IAAK,IAAIC,GAAG,EAAGA,GAAGpD,OAAOC,QAAQkD,IAAIpE,OAAQqE,KACzCpD,OAAOC,QAAQkD,IAAIC,IAAMpD,OAAOkD,kBAAkBC,IAAIC,IAAIC,MAAM,IAMhF9F,SACI,OACI0C,QAASpC,KAAK6B,QAAQE,IAAII,UAElBU,KAAMV,OAAOU,KACbT,QAASD,OAAOC,YAMhC1C,SAAU+F,KAAM/E,YACZV,KAAK6B,QAAQK,QAAQ,CAACC,OAAQuD,MAE1B,GAAID,KAAKrD,QAAQsD,IAAItD,QAAQlB,QAAUiB,OAAOC,QAAQlB,OAClD,MAAM,IAAIU,0CAA0C6D,KAAKrD,QAAQsD,IAAItD,QAAQlB,oBAAoBiB,OAAOC,QAAQlB,sBAAsBR,wBAAwBgF,OAGlK,GAAID,KAAKrD,QAAQsD,IAAItD,QAAQ,GAAGlB,QAAUiB,OAAOC,QAAQ,GAAGlB,OACxD,MAAM,IAAIU,yCAAyC6D,KAAKrD,QAAQsD,IAAItD,QAAQ,GAAGlB,oBAAoBiB,OAAOC,QAAQ,GAAGlB,sBAAsBR,wBAAwBgF,OAGvKvD,OAAOU,KAAO4C,KAAKrD,QAAQsD,IAAI7C,KAC/BV,OAAOC,QAAUqD,KAAKrD,QAAQsD,IAAItD,UAK1C1C,cAEI,IAAIC,KAAO,EAEX,IAAK,IAAIqC,EAAE,EAAGA,EAAEhC,KAAK6B,QAAQX,OAAQc,IAAK,CAEtC,MAAMG,OAASnC,KAAK6B,QAAQG,GAE5B,IAAK,IAAI2D,EAAE,EAAGA,EAAExD,OAAOC,QAAQlB,OAAQyE,IACnC,IAAK,IAAIC,EAAE,EAAGA,EAAEzD,OAAOC,QAAQuD,GAAGzE,OAAQ0E,IACtCjG,MAAQwC,OAAOC,QAAQuD,GAAGC,GAAG1E,OAIrCvB,MAAQ,EAGZ,OAAOA,KAGXD,QAEI,MAAM+F,QAEN,IAAK,IAAIzD,EAAE,EAAGA,EAAEhC,KAAK6B,QAAQX,OAAQc,IAAK,CACtC,MAAMG,OAASnC,KAAK6B,QAAQG,GAE5ByD,KAAKI,KAAK1D,OAAOU,MAEjB,IAAK,IAAI8C,EAAE,EAAGA,EAAExD,OAAOC,QAAQlB,OAAQyE,IACnC,IAAK,IAAIC,EAAE,EAAGA,EAAEzD,OAAOC,QAAQuD,GAAGzE,OAAQ0E,IACtC,IAAK,IAAIjD,EAAE,EAAGA,EAAER,OAAOC,QAAQuD,GAAGC,GAAG1E,OAAQyB,IACzC8C,KAAKI,KAAK1D,OAAOC,QAAQuD,GAAGC,GAAGjD,IAM/C,OAAO8C,KAGX/F,QAAS+F,MAEL,IAAIK,KAAO,EAEX,IAAK,IAAI9D,EAAE,EAAGA,EAAEhC,KAAK6B,QAAQX,OAAQc,IAAK,CAEtC,MAAMG,OAASnC,KAAK6B,QAAQG,GAC5BG,OAAOU,KAAO4C,KAAKK,MACnBA,OAEA,IAAK,IAAIH,EAAE,EAAGA,EAAExD,OAAOC,QAAQlB,OAAQyE,IACnC,IAAK,IAAIC,EAAE,EAAGA,EAAEzD,OAAOC,QAAQuD,GAAGzE,OAAQ0E,IACtC,IAAK,IAAIjD,EAAE,EAAGA,EAAER,OAAOC,QAAQuD,GAAGC,GAAG1E,OAAQyB,IACzCR,OAAOC,QAAQuD,GAAGC,GAAGjD,GAAK8C,KAAKK,MAC/BA,SAUT,oBAARC,SAAwBA,OAAOC,QAAUD,OAAOC,aAExC,oBAARD,SAAwBA,OAAOtG,UAAYA,WAClDuG,QAAQvG,UAAYA,gBAGdqB,QAEFpB,YAAaC,MAAMI,WAACA,gBAChBC,KAAKL,KAAOA,KACZK,KAAKgE,YAAc,IAAIlC,MAAMnC,OAAOoC,IAAIkE,GAAK,IAAIC,QACjDlG,KAAKO,MAAQ,uBAEGL,GAAZH,aAIIC,KAAKD,aAHc,kBAAZA,aAA0BA,cAGI,mBAAZA,WAAyBA,WAAaI,QAAQC,QAAQC,OAAON,aAAaO,KAAKN,QAKpHN,WAAYc,OACRR,KAAKS,UAAYD,MAGrBd,WAAYc,MAAOE,YACfV,KAAKW,UAAYH,MACjBR,KAAKU,WAAaA,WAGtBhB,OACIM,KAAKgE,QAAQ9B,QAAQ+B,SAEjB,IAAIkC,aAEJ,QAAQ,GACJ,KAAKnG,KAAKW,qBAAqBG,QAC3BqF,aAAenG,KAAKW,UAAUhB,KAC9B,MAEJ,KAAKK,KAAKW,qBAAqBlB,UAC3B0G,aAAenG,KAAKW,UAAUkB,QAAQX,OAASlB,KAAKW,UAAUa,YAAY,EAC1E,MAEJ,KAAKxB,KAAKW,qBAAqBK,UAC3BmF,aAAenG,KAAKW,UAAUM,YAAYC,OAASlB,KAAKW,UAAUa,YAAY,EAItFyC,OAAO7B,QAAUpC,KAAKY,IAAI2B,cAAc4D,aAAcnG,KAAKwC,eAC3DyB,OAAOpB,KAAO,EAEdoB,OAAOjB,MACHC,SAAUjD,KAAKY,IAAIqC,SACnBC,iBAAkBlD,KAAKY,IAAIsC,iBAC3BC,SAAUnD,KAAKY,IAAIuC,aAK/BzD,UACIM,KAAKgE,QAAQ9B,QAAQ,CAAC+B,OAAQmC,MAC1B,GAAgB,YAAZpG,KAAKO,QAAsB0D,OAAOoC,QAAUlF,KAAKwC,SAAW3D,KAAKY,IAAIkC,SACrEmB,OAAOlE,WAAa,MACjB,CACHkE,OAAOqC,IAAMrC,OAAOpB,KAEpB,MAAM5B,YAAcb,QAAQgD,eAAepD,KAAKW,WAEhD,IAAK,IAAI4F,GAAG,EAAGA,GAAGtF,YAAYC,OAAQqF,KAClCtC,OAAOqC,KAAOrF,YAAYsF,IAAMtC,OAAO7B,QAAQmE,IAGnDtC,OAAOlE,YAAcC,KAAKD,WAAaC,KAAKD,WAAWkE,OAAOqC,KAAK,EAAOrC,QAAUA,OAAOqC,MAAQtG,KAAKY,IAAIkC,SAAS,MAKjIpD,SAAU2E,QACNrE,KAAKgE,QAAQ9B,QAAQ,CAAC+B,OAAQmC,MAE1B,GAAInC,OAAOoC,QACPpC,OAAOC,MAAQ,EACfD,OAAOM,WAAa,MACjB,MACmB,IAAXF,OACPJ,OAAOC,MAAQG,OAAO+B,KAEtBnC,OAAOuC,WAAaxG,KAAKD,WAAaC,KAAKD,WAAWkE,OAAOqC,KAAK,EAAMrC,QAAU,EAClFA,OAAOC,MAAQD,OAAOuC,WAAaxG,KAAKS,UAAUuD,QAAQjC,IAAIkE,GAAKA,EAAE/B,OAAS+B,EAAE7D,QAAQgE,KAAK,IACnCK,OAAO,CAACC,EAAEf,IAAMe,EAAEf,EAAG,IAGnF,MAAM1E,YAAcb,QAAQgD,eAAepD,KAAKW,WAEhD,IAAK,IAAIgG,GAAG,EAAGA,GAAG1C,OAAO7B,QAAQlB,OAAQyF,KACrC1C,OAAOQ,aAAakC,KAAQ1C,OAAOC,MAAQjD,YAAY0F,IAG3D1C,OAAOM,WAAaN,OAAOC,SAKvCxE,oBACI,IAAK,IAAIuG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CAEtCjG,KAAKgE,QAAQiC,GAAG1B,UAAY,EAE5B,IAAK,IAAIqC,IAAI,EAAGA,IAAI5G,KAAKgE,QAAQiC,GAAGxB,aAAavD,OAAQ0F,MACrD5G,KAAKgE,QAAQiC,GAAGxB,aAAamC,KAAO,GAKhDlH,oBACI,IAAK,IAAIuG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CAEtC,MAAMhC,OAASjE,KAAKgE,QAAQiC,GAE5B,IAAK,IAAIW,IAAI,EAAGA,IAAI5G,KAAKgE,QAAQiC,GAAGxB,aAAavD,OAAQ0F,MAAO,MAEtC1G,GAAlBF,KAAKY,IAAI8D,UAAoB1E,KAAKY,IAAI8D,SAAW,GAAM1E,KAAKY,IAAI+D,GAAKV,OAAO7B,QAAQwE,MAAM,QACxE1G,GAAlBF,KAAKY,IAAIgE,UAAoB5E,KAAKY,IAAIgE,SAAW5E,KAAKY,IAAIiE,GAAK1D,KAAK2D,IAAIb,OAAO7B,QAAQwE,OAE3F,MAAM7B,aAAed,OAAOQ,aAAamC,KACnC5G,KAAKY,IAAI+D,GAAKV,OAAO7B,QAAQwE,KAC7B5G,KAAKY,IAAIiE,IAAMZ,OAAO7B,QAAQwE,KAAO,EAAI,GAAK,IAAM5G,KAAKY,IAAIoE,cAEnEf,OAAO7B,QAAQwE,KAAO5G,KAAKY,IAAIqE,eAAe3E,KAAKN,KAAKY,IAAKqD,OAAO7B,QAAQwE,KAAM7B,YAAad,OAAQ2C,IAAjF5G,QAEAE,GAAlBF,KAAKY,IAAIsE,UAAoBlF,KAAKY,IAAIuE,cAAgBlB,OAAO7B,QAAQwE,MAAM,GAGnF3C,OAAOpB,KAAO7C,KAAKY,IAAIqE,eAAe3E,KAAKN,KAAKY,IAAKqD,OAAOpB,KAAMoB,OAAOM,UAAWN,OAAtEjE,IAItBN,mBACI,IAAK,IAAIuG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CACtC,MAAMhC,OAASjE,KAAKgE,QAAQiC,GAC5BhC,OAAOmB,eAAiBnB,OAAOpB,KAC/BoB,OAAOoB,kBAAoBpB,OAAO7B,QAAQoD,MAAM,IAIxD9F,oBACI,IAAK,IAAIuG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CACtC,MAAMhC,OAASjE,KAAKgE,QAAQiC,GAC5BhC,OAAOpB,KAAOoB,OAAOmB,eACrBnB,OAAO7B,QAAU6B,OAAOoB,kBAAkBG,MAAM,IAIxD9F,SACI,OACI0C,QAASpC,KAAKgE,QAAQjC,IAAIkC,UAElBpB,KAAMoB,OAAOpB,KACbT,QAAS6B,OAAO7B,YAMhC1C,SAAU+F,KAAM/E,YACZV,KAAKgE,QAAQ9B,QAAQ,CAAC+B,OAAQmC,MAE1B,GAAIX,KAAKrD,QAAQgE,IAAIhE,QAAQlB,QAAQ+C,OAAO7B,QAAQlB,OAChD,MAAM,IAAIU,0CAA0C6D,KAAKrD,QAAQgE,IAAIhE,QAAQlB,oBAAoB+C,OAAO7B,QAAQlB,qBAAqBR,wBAAwB0F,OAGjKnC,OAAOpB,KAAO4C,KAAKrD,QAAQgE,IAAIvD,KAC/BoB,OAAO7B,QAAUqD,KAAKrD,QAAQgE,IAAIhE,UAK1C1C,cAEI,IAAIC,KAAO,EAEX,IAAK,IAAIsG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IACjCtG,MAAQK,KAAKgE,QAAQiC,GAAG7D,QAAQlB,OAAS,EAG7C,OAAOvB,KAGXD,QACI,MAAM+F,QAEN,IAAK,IAAIQ,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CACtCR,KAAKI,KAAK7F,KAAKgE,QAAQiC,GAAGpD,MAE1B,IAAK,IAAIgE,EAAE,EAAGA,EAAE7G,KAAKgE,QAAQiC,GAAG7D,QAAQlB,OAAQ2F,IAC5CpB,KAAKI,KAAK7F,KAAKgE,QAAQiC,GAAG7D,QAAQyE,IAI1C,OAAOpB,KAGX/F,QAAS+F,MAEL,IAAIK,KAAO,EAEX,IAAK,IAAIG,EAAE,EAAGA,EAAEjG,KAAKgE,QAAQ9C,OAAQ+E,IAAK,CAEtC,MAAMhC,OAASjE,KAAKgE,QAAQiC,GAC5BhC,OAAOpB,KAAO4C,KAAKK,MACnBA,OAEA,IAAK,IAAIe,EAAE,EAAGA,EAAE5C,OAAO7B,QAAQlB,OAAQ2F,IACnC5C,OAAO7B,QAAQyE,GAAKpB,KAAKK,MACzBA,SAMhB,MAAMgB,MAAQhG,QAGC,oBAARiF,SAAwBA,OAAOjF,QAAUiF,OAAOe,MAAQhG,SAC/DkF,QAAQlF,QAAUkF,QAAQc,MAAQhG,cAG5BmB,OAEFvC,eAEAA,MAAMuD,SAACA,SAAQlD,WAAEA,WAAUoD,SAAEA,cAKzB,OAHAnD,KAAKyE,aAAezE,KAAKoC,QAAQL,IAAIyC,SAAWA,QAAQzC,IAAIgF,MAAQA,KAAKhF,IAAI8E,GAAK,KAClF7G,KAAKuE,UAAY,EAETtB,UAEJ,IAAK,OACDjD,KAAKgH,SAAW,EAChBhH,KAAKiH,YAAcjH,KAAKoC,QAAQL,IAAIyC,SAAWA,QAAQzC,IAAIgF,MAAQA,KAAKhF,IAAI8E,GAAK,KACjF7G,KAAKkH,cAAgB,GAAE1C,QAAS9B,IAAKyE,UAAYnH,KAAKiH,YAAYzC,SAAS9B,KAAKyE,SAChFnH,KAAKoH,cAAgB,GAAE5C,QAAS9B,IAAKyE,QAASxE,IAAM3C,KAAKiH,YAAYzC,SAAS9B,KAAKyE,QAAUxE,GAC7F,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACL,IAAK,WACD3C,KAAKqH,UAAY,EACjBrH,KAAKsH,aAAetH,KAAKoC,QAAQL,IAAIyC,SAAWA,QAAQzC,IAAIgF,MAAQA,KAAKhF,IAAI8E,GAAK,KAClF7G,KAAKuH,gBAAkB,GAAE/C,QAAS9B,IAAKyE,UAAYnH,KAAKsH,aAAa9C,SAAS9B,KAAKyE,SACnFnH,KAAKwH,gBAAkB,GAAEhD,QAAS9B,IAAKyE,QAASxE,IAAM3C,KAAKsH,aAAa9C,SAAS9B,KAAKyE,QAAUxE,GAElF,YAAVM,WACAjD,KAAKyH,kBAAoB,EACzBzH,KAAK0H,cAAgB1H,KAAKoC,QAAQL,IAAIyC,SAAWA,QAAQzC,IAAIgF,MAAQA,KAAKhF,IAAI8E,GAAK,KACnF7G,KAAK2H,iBAAmB,GAAEnD,QAAS9B,IAAKyE,UAAYnH,KAAK0H,cAAclD,SAAS9B,KAAKyE,SACrFnH,KAAK4H,iBAAmB,GAAEpD,QAAS9B,IAAKyE,QAASxE,IAAM3C,KAAK0H,cAAclD,SAAS9B,KAAKyE,QAAUxE,IAEtG,MAEJ,IAAK,OACD3C,KAAK6H,EAAI,EACT7H,KAAK2C,EAAI,EAID,SAAZ5C,WACAC,KAAK8H,WAA6B,KAAhB3G,KAAKwC,SAEJ,OAAZ5D,aACPC,KAAKmD,SAAWA,UAIxBzD,WAAY8E,QAAS9B,IAAKyE,SACtB,OAAOnH,KAAKoC,QAAQoC,SAAS9B,KAAKyE,QAGtCzH,WAAY8E,QAAS9B,IAAKyE,QAASxE,GAC/B3C,KAAKoC,QAAQoC,SAAS9B,KAAKyE,QAAUxE,EAGzCjD,gBAAiB8E,QAAS9B,IAAKyE,SAC3B,OAAOnH,KAAKyE,aAAaD,SAAS9B,KAAKyE,QAG3CzH,gBAAiB8E,QAAS9B,IAAKyE,QAASxE,GACpC3C,KAAKyE,aAAaD,SAAS9B,KAAKyE,QAAUxE,GAKnC,oBAARoD,SAAwBA,OAAO9D,OAASA,QAC/C+D,QAAQ/D,OAASA,aAGX8F,mBAAmBjH,QACrBpB,YAAaC,MAAMqI,KAACA,KAAK,OACrBC,MAAMtI,KAAOqI,KAAKA,OAKX,oBAARjC,SAAwBA,OAAOgC,WAAaA,YACnD/B,QAAQ+B,WAAaA,iBAIf5H,QAGFT,eAAgBwI,MAAOC,OACnB,MAAMC,IAAM,GAAG,EAAEjH,KAAKkH,KAAKH,QAC3B,OAAOC,MAAQC,KAAK,EAAEA,KACPA,IAGnB1I,YAAawI,MAAOC,OAChB,MAAME,IAAMlH,KAAKkH,IAAI,EAAEH,OACvB,OAAOC,MAAQ,EAAEhH,KAAKO,IAAIP,KAAKkH,IAAIH,OAAO/G,KAAKkH,KAAKH,OAAQ,IAAM,OAClDG,IAAI,IAAIA,IAAI,IAAM,MAGtC3I,YAAawI,MAAOC,OAChB,OAAOA,MAAQD,MAAQ,EAAI,EAAI,EAChB/G,KAAKG,IAAI4G,MAAO,GAGnCxI,aAAcwI,MAAOC,OACjB,OAAOA,MAAQD,MAAQ,EAAI,EAAKlI,KAAKsI,aAAe,KACrCnH,KAAKG,KAAKtB,KAAKsI,aAAe,MAAQnH,KAAK2D,IAAIoD,OAAQA,OAG1ExI,aAAcwI,MAAOC,MAAOlE,QACxB,OAAOkE,MAAQD,MAAQ,EAAI,EAAIjE,OAAO6D,WACvB3G,KAAKG,IAAI2C,OAAO6D,WAAYI,OAG/CxI,iBAAkBwI,MAAOC,OACrB,OAAOA,MAAQ,QAAUhH,KAAKO,IAAIvB,QAAQoI,KAAM,EAAE,EAAKL,OAAQ,GAChD,OAAS/H,QAAQqI,KAAM,EAAE,EAAKN,OAGjDxI,WAAYwI,MAAOC,MAAOlE,QACtB,OAAOkE,MAAQD,OAAQ,EAAI,EAAI/H,QAAQsI,IAAIP,OAAO,EAAOjE,QAAUA,OAAOd,SAC3D+E,OAAQ,EAAIA,MAAQjE,OAAOd,UAAYhC,KAAKkH,IAAIH,OAAS,GAI5ExI,oBAAqBgJ,OAAQC,QACzB,OAAOA,OAAO5G,IAAI,CAACmG,MAAOU,KAAOF,OAAOE,IAAMzH,KAAK0H,IAAIX,MAAM,QAAW,EAAEQ,OAAOE,KAAOzH,KAAK0H,IAAK,EAAE,MAAOX,QAC7FzB,OAAO,CAACC,EAAEf,IAAMe,EAAEf,EAAG,GAGvCjG,wBAAyBoJ,WAAYC,SACjC,OAAOD,WAAW/G,IAAI,CAAC4G,OAAQK,QAAU7H,KAAKO,IAAIiH,OAASI,QAAQC,OAAQ,IACzDvC,OAAO,CAACwC,KAAMC,OAASD,KAAKC,KAAM,GAAKJ,WAAW5H,OAGxExB,4BAA6BoJ,WAAYC,SACrC,OAAO5H,KAAKI,KAAKpB,QAAQgJ,iBAAiBL,WAAYC,UAI1DrJ,kBAAmBwI,MAAOkB,YACtB,OAAOlB,MAAQlI,KAAKqJ,aAAeD,WAGvC1J,YAAawI,MAAOkB,WAAYnF,OAAQqF,SAEpC,MAAMC,OAASrB,MAAQlI,KAAKqJ,aAAeD,YAAuB,MAATE,QAAgBrF,OAAO+C,SAAW/C,OAAOiD,cAAcoC,UAgBhH,OAdIC,QAAQ,GAAKrB,MAAM,GAAKqB,QAAQ,GAAKrB,MAAM,EAC9B,MAAToB,QACArF,OAAOmD,cAAckC,QAASnI,KAAKG,IAAkC,IAA9B2C,OAAOiD,cAAcoC,SAAe,KAE3ErF,OAAO+C,SAAW7F,KAAKG,IAAoB,IAAhB2C,OAAO+C,SAAe,IAGxC,MAATsC,QACArF,OAAOmD,cAAckC,QAASnI,KAAKqI,IAAIvF,OAAOiD,cAAcoC,SAAS,IAAM,IAE3ErF,OAAO+C,SAAW7F,KAAKqI,IAAIvF,OAAO+C,SAAS,IAAM,GAIlDuC,OAGX7J,eAAgBwI,MAAOkB,WAAYnF,OAAQqF,SAQvC,OANa,MAATA,QACArF,OAAOuD,gBAAgB8B,QAASrF,OAAOsD,gBAAgB+B,SAAWnI,KAAKO,IAAI0H,WAAY,IAEvFnF,OAAOoD,WAAalG,KAAKO,IAAI0H,WAAY,GAGtClB,MAAQlI,KAAKqJ,aAAeD,YAAc,KAAOjI,KAAKI,KAAc,MAAT+H,QAAgBrF,OAAOsD,gBAAgB+B,SACvBrF,OAAOoD,YAG7F3H,eAAgBwI,MAAOkB,WAAYnF,OAAQqF,SAQvC,OANa,MAATA,QACArF,OAAOuD,gBAAgB8B,QAAStJ,KAAKyJ,SAAWxF,OAAOsD,gBAAgB+B,UAAY,EAAItJ,KAAKyJ,UAAYtI,KAAKO,IAAI0H,WAAY,IAE7HnF,OAAOoD,UAAYrH,KAAKyJ,SAAWxF,OAAOoD,WAAa,EAAIrH,KAAKyJ,UAAYtI,KAAKO,IAAI0H,WAAY,GAG9FlB,MAAQlI,KAAKqJ,aAAeD,YAAc,KAAOjI,KAAKI,KAAc,MAAT+H,QAAgBrF,OAAOsD,gBAAgB+B,SACvBrF,OAAOoD,YAG7F3H,YAAawI,MAAOkB,WAAYnF,QAE5BA,OAAO4D,EAAI,GAAI5D,OAAO4D,GAAK,EAAE,IAAOuB,WACpC,MAAMM,GAAKzF,OAAO4D,GAAK,EAAE1G,KAAKO,IAAI,GAAK1B,KAAK2J,WAAa,IAEzD1F,OAAOtB,EAAI,KAAMsB,OAAOtB,GAAK,EAAE,MAASxB,KAAKO,IAAI0H,WAAY,GAC7D,MAAMQ,GAAK3F,OAAOtB,GAAK,EAAExB,KAAKO,IAAI,KAAO1B,KAAK2J,WAAa,IAE3D,OAAOzB,MAAQlI,KAAKqJ,aAAeK,IAAMvI,KAAKI,KAAKqI,IAAM,MAG7DlK,gBAAiBwI,MAAOkB,WAAYnF,OAAQqF,SAExC,GAAa,MAATA,QAAe,CACfrF,OAAOuD,gBAAgB8B,QAAStJ,KAAK6J,IAAM5F,OAAOsD,gBAAgB+B,UAAY,EAAEtJ,KAAK6J,KAAO1I,KAAKO,IAAI0H,WAAY,IACjH,MAAMG,OAASrB,MAAQ/G,KAAKI,MAAM0C,OAAO0D,iBAAiB2B,SAAW,OAAOrF,OAAOsD,gBAAgB+B,SAAW,OAASF,WAEvH,OADAnF,OAAO2D,iBAAiB0B,QAAStJ,KAAK6J,IAAM5F,OAAO0D,iBAAiB2B,UAAY,EAAEtJ,KAAK6J,KAAO1I,KAAKO,IAAI0H,WAAY,IAC5GG,OAEJ,CACHtF,OAAOoD,UAAYrH,KAAK6J,IAAM5F,OAAOoD,WAAa,EAAErH,KAAK6J,KAAO1I,KAAKO,IAAI0H,WAAY,GACrF,MAAMG,OAASrB,MAAQ/G,KAAKI,MAAM0C,OAAOwD,kBAAoB,OAAOxD,OAAOoD,UAAY,OAAS+B,WAEhG,OADAnF,OAAOwD,kBAAoBzH,KAAK6J,IAAM5F,OAAOwD,mBAAqB,EAAEzH,KAAK6J,KAAO1I,KAAKO,IAAI0H,WAAY,GAC9FG,QAIf7J,gBAAiBwI,MAAOkB,WAAYnF,OAAQqF,SAExC,IAAI3G,EAUJ,OARa,MAAT2G,SACA3G,EAAI3C,KAAK8J,SAAY7F,OAAOsD,gBAAgB+B,SAAYtJ,KAAKqJ,aAAeD,WAC5EnF,OAAOuD,gBAAgB8B,QAAS3G,KAEhCA,EAAI3C,KAAK8J,SAAY7F,OAAgB,UAAIjE,KAAKqJ,aAAeD,WAC7DnF,OAAOoD,UAAY1E,GAGhBuF,MAAQvF,EAInBjD,eAAgBC,MAAMoK,MAACA,QACnB,MAAMC,UAEN,IAAK,IAAIC,EAAE,EAAGA,EAAEtK,KAAMsK,IAClBD,OAAOnE,KAAmB,EAAd1E,KAAKwC,SAAWoG,MAAMA,OAGtC,OAAOC,OAGXtK,gBAAiBC,MAAMuK,KAACA,KAAIC,aAAEA,eAC1B,MAAMH,UAGN,IAAK,IAAIC,EAAE,EAAGA,EAAEtK,KAAMsK,IAAK,CACvB,IAAIG,GAAIC,GAAIzE,EAEZ,GAGIA,GAFAwE,GAAK,EAAIjJ,KAAKwC,SAAU,IAEhB,GADR0G,GAAK,EAAIlJ,KAAKwC,SAAU,IACR,QACXiC,GAAK,IAAMA,GAEpBoE,OAAOnE,KAAKqE,KAAQE,GAAMjJ,KAAKI,MAAM,EAAIJ,KAAK0H,IAAIjD,GAAKA,GAAOuE,cAGlE,OAAOH,OAGXtK,oBAAqBC,MAAM2K,MAACA,MAAKC,OAAEA,SAC/B,OAAOA,QAAkB,GAARA,OAAYpK,QAAQqK,SAAS7K,MAAOuK,KAAM,EAAGC,aAAchJ,KAAKI,KAAK,GAAG+I,MAAMC,WAClEpK,QAAQsK,YAAY9K,MAAO2K,MAAAA,QAG5D5K,qBAAsBC,MAAM2K,MAACA,MAAKC,OAAEA,SAChC,OAAOA,QAAkB,GAARA,OAAYpK,QAAQuK,QAAQ/K,MAAOoK,MAAO5I,KAAKI,KAAK,GAAG+I,MAAMC,WACjDpK,QAAQwK,aAAahL,MAAO2K,MAAAA,QAG7D5K,mBAAoBC,MAAM2K,MAACA,QACvB,OAAOnK,QAAQqK,SAAS7K,MAAOuK,KAAM,EAAGC,aAAchJ,KAAKI,KAAK,EAAE+I,SAGtE5K,oBAAqBC,MAAM2K,MAACA,QACxB,OAAOnK,QAAQuK,QAAQ/K,MAAOoK,MAAO5I,KAAKI,KAAK,EAAE+I,SAIrD5K,eAAgBc,MAAOgE,SAEnB,MAAMvD,YAAcb,QAAQgD,eAAe5C,MAAMG,UAAW6D,QAAShE,MAAMiB,kBAE3E,IAAK,IAAIiB,IAAI,EAAGA,IAAIlC,MAAMgB,WAAYkB,MAClC,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMgB,WAAY4C,MAAO,CAEzC,MAAMwG,SAAWlI,IAAMlC,MAAMV,OACvB+K,SAAWzG,IAAM5D,MAAMV,OAG7B,IAAIC,WAAakB,YAAY2J,SAASpK,MAAMa,kBAAoBwJ,UAEhE,IAAK,IAAIC,UAAU,EAAGA,UAAUtK,MAAMb,KAAMmL,YACxC,IAAK,IAAIC,UAAU,EAAGA,UAAUvK,MAAMb,KAAMoL,YAAa,CAErD,MAAM7C,MAAQjH,aAAe2J,SAASE,WAAatK,MAAMa,mBAAsBwJ,SAASE,YAEpF7C,MAAQnI,aACRA,WAAamI,MACb1H,MAAMwK,QAAQxG,SAAS9B,KAAK0B,MAAQ0G,UAAWC,YAK3DvK,MAAMS,YAAYuD,SAAS9B,KAAK0B,KAAOrE,YAMnDL,eAAgBiD,GAEZ,MAAMqH,OAASrH,EAAE6C,MAAM,GACvB,IAAIyF,SAAWjB,OAAO,GAEtB,IAAK,IAAIC,EAAE,EAAGA,EAAED,OAAO9I,OAAQ+I,IACvBD,OAAOC,GAAKgB,WACZA,SAAWjB,OAAOC,IAK1B,MAAMiB,aAAe,IAAIpJ,MAAMkI,OAAO9I,QACtC,IAAIiK,gBAAkB,EAEtB,IAAK,IAAIlB,EAAE,EAAGA,EAAED,OAAO9I,OAAQ+I,IAAK,CAChC,IAAImB,EAAIjK,KAAKkH,IAAI2B,OAAOC,GAAKgB,UAC7BE,iBAAmBC,EACnBF,aAAajB,GAAKmB,EAGtB,IAAK,IAAInB,EAAE,EAAGA,EAAED,OAAO9I,OAAQ+I,IAC3BiB,aAAajB,IAAMkB,gBACnBnB,OAAOC,GAAKiB,aAAajB,GAG7B,OAAOD,OAGXtK,YAAawI,OACT,OAAQ,EAAE/G,KAAKkH,KAAKH,QAAS,EAAE/G,KAAKkH,KAAK,EAAEH,QAG/CxI,yBAA0B2L,KACtB,MAAMC,IAAMD,IAAI5E,OAAO,CAACC,EAAEf,IAAMe,EAAEf,GAAK0F,IAAInK,OACrCqK,MAAQF,IAAItJ,IAAIY,GAAKA,EAAI2I,KAAKvJ,IAAIY,GAAKA,GAAG,GAChD,OAAOxB,KAAKI,KAAKgK,MAAM9E,OAAO,CAACC,EAAEf,IAAMe,EAAEf,GAAK4F,MAAMrK,QAGxDxB,iBAEI,GAAIM,KAAKmF,aAAenF,KAAKkF,QAAS,CAElC,MAAMsG,WAAaxL,KAAKkF,SAAW,MAAQlF,KAAKmF,cAEhDnF,KAAKyL,OAAOvJ,QAAQ,CAAC1B,MAAOkL,MACxBA,IAAMlL,MAAMwD,QAAQ9B,QAAQ+B,SACxBA,OAAO7B,QAAQF,QAAQ,CAAC2E,EAAGF,KAAO1C,OAAO0H,UAAUhF,GAAI1C,OAAO2H,UAAUjF,IAAM6E,iBAK1FxL,KAAKmF,aAAe,GAKb,oBAARY,SAAwBA,OAAO5F,QAAUA,SAChD6F,QAAQ7F,QAAUA,cAGZC,QAEFV,cAAewI,MAAO2D,KAAK,UACvB,QAAQ,GAEJ,IAAW,UAANA,MAAgC,iBAAP3D,MAC1BA,MAAQA,MAAM4D,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAW,QAANF,MAA8B,iBAAP3D,MACxB,MAAM8D,KAAO,IAAIC,KAAK/D,OAChBgE,aAEFhE,MAAQ,IACRgE,UAAUrG,QAAQmG,KAAKG,uBAEhBjE,MAAQ,IACfgE,UAAUrG,QAAQmG,KAAKI,gBAAgBJ,KAAKG,uBAIxCjE,OAAS,MAASgE,UAAUrG,QAAQmG,KAAKK,eAE7CH,UAAUrG,QAAQmG,KAAKM,iBACvBJ,UAAUrG,QAAQmG,KAAKI,kBAG3BlE,MAAQgE,UAAUK,KAAK,KAI/B,OAAOrE,MAGXxI,eAAgB2L,KACZ,IAAK,IAAIpB,EAAEoB,IAAInK,OAAQ+I,EAAGA,IAAK,CAC3B,MAAMuC,EAAIrL,KAAKC,MAAMD,KAAKwC,SAAWsG,GAC/BwC,EAAIpB,IAAIpB,EAAE,GAChBoB,IAAIpB,EAAE,GAAKoB,IAAImB,GACfnB,IAAImB,GAAKC,GAIjB/M,sBAAuBqC,IAAK2K,IAExB,MAAMjH,QAEN,IAAK,IAAI/C,IAAI,EAAGA,IAAIX,IAAIb,OAAQwB,MAC5B+C,KAAKI,KAAK9D,IAAIW,KAAK8C,MAAM,IAG7B,MAAMmH,aAEN,IAAK,IAAI1C,EAAE,EAAGA,EAAExE,KAAKvE,OAAO,EAAEwL,GAAIzC,IAC9B0C,UAAU9G,KAAK,GAGnB,IAAK,IAAIzB,IAAI,EAAGA,IAAIqB,KAAKvE,OAAQkD,MAC7B,IAAK,IAAI6F,EAAE,EAAGA,EAAEyC,GAAIzC,IAChBxE,KAAKrB,KAAKwI,OAAO,EAAG,EAAG,GACvBnH,KAAKrB,KAAKwI,OAAOnH,KAAKrB,KAAKlD,OAAO,EAAGuE,KAAKrB,KAAKlD,OAAQ,GAI/D,IAAK,IAAI+I,EAAE,EAAGA,EAAEyC,GAAIzC,IAChBxE,KAAKmH,OAAO,EAAG,EAAGD,UAAUnH,MAAM,IAClCC,KAAKmH,OAAOnH,KAAKvE,OAAQuE,KAAKvE,OAAO,EAAGyL,UAAUnH,MAAM,IAG5D,OAAOC,KAGX/F,kBAAmB2L,IAAK1L,MACpB,MAAMoC,OAEN,IAAK,IAAIkI,EAAE,EAAGA,EAAEtK,KAAMsK,IAAK,CACvBlI,IAAIkI,MAEJ,IAAK,IAAIuC,EAAE,EAAGA,EAAE7M,KAAM6M,IAClBzK,IAAIkI,GAAGuC,GAAKnB,IAAIpB,EAAEtK,KAAK6M,GAI/B,OAAOzK,IAGXrC,qBAAsB2L,IAAKtK,UAEvB,MAAM8L,OACAlN,KAAOwB,KAAKI,KAAK8J,IAAInK,OAAOH,UAC5B+L,UAAYnN,MAAM,EAExB,IAAK,IAAIoN,EAAE,EAAGA,EAAE5L,KAAKC,MAAMiK,IAAInK,OAAO4L,WAAYC,IAAK,CAEnD,MAAMhL,OAEN,IAAK,IAAIkI,EAAE,EAAGA,EAAEtK,KAAMsK,IAAK,CACvBlI,IAAIkI,MAEJ,IAAK,IAAIuC,EAAE,EAAGA,EAAE7M,KAAM6M,IAClBzK,IAAIkI,GAAGuC,GAAKnB,IAAI0B,EAAED,UAAa7C,EAAEtK,KAAK6M,GAI9CK,IAAIE,GAAKhL,IAGb,OAAO8K,IAGXnN,iBAAiB8D,MAACA,MAAK3D,YAAEA,YAAWuC,QAAEA,QAAOrB,SAAEA,SAAQjB,OAAEA,OAAM+C,KAAEA,OAE7D,MAAMmK,SAAW5M,QAAQ6M,cAAczJ,MAAOzC,UACxCmM,aAEAC,aAAeH,SAAS,GAAG9L,OAAqB,EAAZrB,YACpCuN,SAAWjM,KAAKC,MAAMgB,QAAQ,GAAGlB,OAAS,GAGhD,IAAK,IAAImM,GAAG,EAAGA,GAAGtM,SAAUsM,KAAM,CAC9BL,SAASK,IAAMjN,QAAQkN,eAAeN,SAASK,IAAKxN,aAEpD,IAAK,IAAI0N,OAAOH,SAAUG,OAAOJ,aAAaC,SAAUG,QAAQzN,OAAQ,CACpEoN,WAAWK,OAAOH,UAAUtN,QAAUoN,WAAWK,OAAOH,UAAUtN,YAElE,IAAK,IAAI0N,OAAOJ,SAAUI,OAAOL,aAAaC,SAAUI,QAAQ1N,OAAQ,CACpE,IAAIwG,IAAM,EAEV,IAAK,IAAImH,SAAS,EAAGA,SAASrL,QAAQ,GAAGlB,OAAQuM,WAE7C,IAAK,IAAIC,SAAS,EAAGA,SAAStL,QAAQ,GAAGlB,OAAQwM,WAC7CpH,KAAO0G,SAASK,IAAIE,QAAQE,SAASL,WAAWI,QAAQE,SAASN,WAAahL,QAAQiL,IAAII,UAAUC,UAI5GR,WAAWK,OAAOH,UAAUtN,SAAS0N,OAAOJ,UAAUtN,SAAWoN,WAAWK,OAAOH,UAAUtN,SAAS0N,OAAOJ,UAAUtN,SAAS,GAAKwG,MAMjJ,IAAK,IAAIqH,KAAK,EAAGA,KAAKT,UAAUhM,OAAQyM,OACpC,IAAK,IAAIC,KAAK,EAAGA,KAAKV,UAAUhM,OAAQ0M,OACpCV,UAAUS,MAAMC,OAAS/K,KAIjC,OAAOqK,UAGXxN,yBAA0Be,UAAWmC,SAAUS,SAG3C,MAAMxD,YAAcY,UAAUZ,YACxBsN,aAAevK,SAAS1B,OAAqB,EAAZrB,YACjCuN,SAAWjM,KAAKC,MAAMX,UAAUb,WAAa,GAG7CiO,aAEN,IAAK,IAAIzF,IAAI,EAAGA,IAAI+E,aAAc/E,MAC9ByF,UAAUhI,KAAK,GAGnB,IAAK,IAAInD,IAAI,EAAGA,IAAIyK,aAAczK,MAC9BE,SAASF,KAAOmL,UAAUrI,MAAM,GAIpC,IAAK,IAAIsI,UAAU,EAAGA,UAAUrN,UAAUd,KAAMmO,YAAa,CAEzD,MAAM1L,QAAU3B,UAAUoB,QAAQiM,WAAW1L,QAAQiB,SAC/C0K,OAAStN,UAAUoB,QAAQiM,WAAWlL,SAG5C,IAAK,IAAI2K,OAAOH,SAAUG,OAAOJ,aAAeC,SAAUG,QAAQ9M,UAAUX,OACxE,IAAK,IAAI0N,OAAOJ,SAAUI,OAAOL,aAAeC,SAAUI,QAAQ/M,UAAUX,OAExE,IAAK,IAAI2N,SAAS,EAAGA,SAAShN,UAAUb,WAAY6N,WAChD,IAAK,IAAIC,SAAS,EAAGA,SAASjN,UAAUb,WAAY8N,WAChD9K,SAAS2K,QAAQE,SAASL,WAAWI,QAAQE,SAASN,YAAchL,QAAQqL,UAAUC,UAChFK,QAAQR,OAAOH,UAAU3M,UAAUX,SAAS0N,OAAOJ,UAAU3M,UAAUX,QAQjG8C,SAASgK,OAAO,EAAG/M,aACnB+C,SAASgK,OAAOhK,SAAS1B,OAAOrB,YAAa+C,SAAS1B,QAGtD,IAAK,IAAI8M,KAAK,EAAGA,KAAKpL,SAAS1B,OAAQ8M,OACnCpL,SAASoL,MAAQpL,SAASoL,MAAMpB,OAAO/M,YAAa+C,SAASoL,MAAM9M,OAAqB,EAAZrB,aAIpFH,yBAA0Bc,OAEtB,MAAM2F,aAAe3F,MAAMqB,QAAQ,GAAGO,QAAQ,GAAGlB,OAC3CkM,SAAWjM,KAAKC,MAAM+E,aAAe,GACrC8H,cAAgBzN,MAAMqB,QAAQ,GAAGO,QAAQlB,OAG/C,IAAK,IAAImC,QAAQ,EAAGA,QAAQ7C,MAAMqB,QAAQX,OAAQmC,UAAW,CAEzD,MAAMlB,OAAS3B,MAAMqB,QAAQwB,SAG7B,IAAK,IAAI6K,SAAS,EAAGA,SAASD,cAAeC,WAAY,CAErD,MAAMC,YAAc/N,QAAQgD,eAAe5C,MAAMG,UAAWuN,SAAU1N,MAAMiB,kBACtE2M,SAAWhO,QAAQkN,eAAelN,QAAQiO,WAAWF,YAAahN,KAAKI,KAAKf,MAAMiB,mBAAoBjB,MAAMX,aAGlH,IAAK,IAAI0N,OAAOH,SAAUG,OAAOa,SAASlN,OAAOkM,SAAUG,QAAQ/M,MAAMV,OACrE,IAAK,IAAI0N,OAAOJ,SAAUI,OAAOY,SAASlN,OAAOkM,SAAUI,QAAQhN,MAAMV,OAAQ,CAE7E,MAAMoE,MAAQ/B,OAAOS,UAAU2K,OAAOH,UAAU5M,MAAMV,SAAS0N,OAAOJ,UAAU5M,MAAMV,QAGtF,IAAK,IAAI2N,SAAS,EAAGA,SAAStH,aAAcsH,WACxC,IAAK,IAAIC,SAAS,EAAGA,SAASvH,aAAcuH,WAAY,CACpD,MAAM3N,WAAaqO,SAASb,OAAOH,SAASK,UAAUD,OAAOJ,SAASM,UACtEvL,OAAOsC,aAAayJ,UAAUT,UAAUC,WAAa3N,WAAamE,QAQtF,IAAK,IAAIoK,GAAG,EAAGA,GAAGnM,OAAOS,SAAS1B,OAAQoN,KACtC,IAAK,IAAIC,GAAG,EAAGA,GAAGpM,OAAOS,SAAS1B,OAAQqN,KACtCpM,OAAOoC,WAAapC,OAAOS,SAAS0L,IAAIC,KAMxD7O,sBAAuBc,MAAOgO,UAAWC,SAErC,MAAMC,aAEN,GAAsB,GAAlBC,UAAUzN,OAEV,GAAIV,iBAAiBM,QAEjB,IAAK,IAAIsF,GAAG,EAAGA,GAAG5F,MAAMwD,QAAQ9C,OAAQkF,KACpCsI,UAAU7I,KAAKrF,MAAMwD,QAAQoC,IAAIrG,iBAGlC,GAAIS,iBAAiBf,UAExB,IAAK,IAAIiG,GAAG,EAAGA,GAAGlF,MAAMqB,QAAQX,OAAQwE,KACpC,IAAK,IAAIkJ,KAAK,EAAGA,KAAKpO,MAAMqB,QAAQ6D,IAAIjD,cAAcvB,OAAQ0N,OAC1D,IAAK,IAAIC,KAAK,EAAGA,KAAKrO,MAAMqB,QAAQ6D,IAAIjD,cAAcmM,MAAM1N,OAAQ2N,OAChEH,UAAU7I,KAAKrF,MAAMqB,QAAQ6D,IAAIjD,cAAcmM,MAAMC,YAOjE,IAAK,IAAIrK,QAAQ,EAAGA,QAAQhE,MAAMS,YAAYC,OAAQsD,UAClD,IAAK,IAAI9B,IAAI,EAAGA,IAAIlC,MAAMS,YAAY,GAAGC,OAAQwB,MAC7C,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMS,YAAY,GAAGC,OAAQkD,MAC7CsK,UAAU7I,KAAKrF,MAAMS,YAAYuD,SAAS9B,KAAK0B,WAQ/D,GAAI5D,iBAAiBM,QAEjB,IAAK,IAAImJ,EAAEuE,UAAUC,QAASxE,GAAGuE,UAAU,GAAGC,QAASxE,IACnDyE,UAAU7I,KAAKrF,MAAMwD,QAAQiG,GAAGlK,iBAGjC,GAAIS,iBAAiBf,UAExB,IAAK,IAAIiD,IAAI,EAAGA,IAAIlC,MAAMqB,QAAQ2M,WAAW/L,cAAcvB,OAAQwB,MAC/D,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMqB,QAAQ2M,WAAW/L,cAAcC,KAAKxB,OAAQkD,MACpEsK,UAAU7I,KAAKrF,MAAMqB,QAAQ2M,WAAW/L,cAAcC,KAAK0B,WAMnE,IAAK,IAAI1B,IAAI,EAAGA,IAAIlC,MAAMS,YAAYuN,WAAWtN,OAAQwB,MACrD,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMS,YAAYuN,WAAWtN,OAAQkD,MACrDsK,UAAU7I,KAAKrF,MAAMS,YAAYuN,WAAW9L,KAAK0B,MAMjE,OAAOsK,UAGXhP,iBAAkB+F,MAAMqJ,SAACA,SAAS,GAAGC,WAAEA,WAAW,IAAIC,KAAEA,KAAK,SAEzD,MAAMC,OACFH,YACAC,cACAC,SAIJ,IAAK,IAAI/E,EAAE,EAAGA,EAAExE,KAAKvE,OAAQ+I,IAAK,CAC9B,IAAIwC,EAAItL,KAAKwC,SAET8I,EAAI,EAAEqC,SACNG,MAAMH,SAASjJ,KAAKJ,KAAKwE,IAGrBwC,EAAEsC,WACFE,MAAMF,WAAWlJ,KAAKJ,KAAKwE,IAE3BgF,MAAMD,KAAKnJ,KAAKJ,KAAKwE,IAMjC,OAAOgF,MAGXvP,iBAAkB+F,MACd,IAAIyJ,OAASC,EAAAA,EACTC,QAAUD,EAAAA,EAEd,IAAK,IAAIlF,EAAE,EAAGA,EAAExE,KAAKvE,OAAQ+I,IACrBxE,KAAKwE,GAAKiF,SACVA,OAASzJ,KAAKwE,IAEdxE,KAAKwE,GAAKmF,SACVA,OAAS3J,KAAKwE,IAItB,IAAM,EAAEiF,OAASE,QAAW,EACxB,IAAK,IAAInF,EAAE,EAAGA,EAAExE,KAAKvE,OAAQ+I,IACzBxE,KAAKwE,IAAMxE,KAAKwE,IAAM,EAAEiF,UAAY,EAAEA,OAASE,aAGnD,IAAK,IAAInF,EAAE,EAAGA,EAAExE,KAAKvE,OAAQ+I,IACzBxE,KAAKwE,GAAK,GAIlB,OAAQiF,OAAAA,OAAQE,OAAAA,QAGpB1P,2BAA4B2P,cACxB,IAAIC,MAAQ,EACRC,aAAe,EACnB,MAAM9J,QAEN,IAAK,IAAIG,EAAE,EAAGA,EAAEyJ,aAAanO,OAAQ0E,IAAK,CACtC,MAAMlD,OACN,IAAK,IAAIiD,EAAE,EAAGA,EAAE0J,aAAazJ,GAAG1E,OAAQyE,IACpCjD,IAAImD,KAAKwJ,aAAazJ,GAAGD,IAE7BF,KAAKI,KAAKnD,KAId,IAAK,IAAIkD,EAAE,EAAGA,EAAEH,KAAKvE,OAAQ0E,IACzB,IAAK,IAAID,EAAE,EAAGA,EAAEF,KAAKG,GAAG1E,OAAQyE,IAC5B2J,OAAS7J,KAAKG,GAAGD,GAIzB,IAAK,IAAIC,EAAE,EAAGA,EAAEH,KAAKvE,OAAQ0E,IAAK,CAE9B,IAAI4J,SAAW,EACfD,cAAgB9J,KAAKG,GAAGA,GAExB,IAAK,IAAID,EAAE,EAAGA,EAAEF,KAAKG,GAAG1E,OAAQyE,IAC5B6J,UAAY/J,KAAKG,GAAGD,GACpBF,KAAKG,GAAGD,IAAM8J,MAAOhK,KAAKG,GAAGD,GAAI+J,QAAUjK,KAAKG,GAAGD,GAAK2J,MAAQ,KAAM,GAG1E,MAAMK,eAAiBlK,KAAKG,GAAGA,GAAG6J,MAAQD,SAAW,IAErD/J,KAAKG,GAAG0J,OACJM,QAAUD,gBAAgB,EAC1BE,MAAQ,IAAMF,gBAAiB,GAKvC,MAAMG,aAEN,IAAK,IAAInK,EAAE,EAAGA,EAAEF,KAAK,GAAGvE,OAAQyE,IAAK,CAEjC,IAAIoK,YAAc,EAElB,IAAK,IAAInK,EAAE,EAAGA,EAAEH,KAAKvE,OAAQ0E,IACzBmK,aAAetK,KAAKG,GAAGD,GAAG8J,MAG9B,MAAME,eAAiBlK,KAAKE,GAAGA,GAAG8J,MAAQM,YAAc,IAExDD,UAAUjK,MACN+J,QAAS,gBAAkB,EAC3BC,MAAQ,IAAMF,gBAAiB,IAYvC,OARAlK,KAAK6J,MAAQQ,UAGbrK,KAAK6J,MAAMA,OACPM,QAAUL,aAAeD,MAAQ,KAAM,EACvCO,MAAQ,IAAON,aAAeD,MAAQ,KAAO,GAG1C7J,KAIX/F,4BAA6B+F,MACzB,GAAmB,oBAARM,OAAqB,CAE5B,IAAK,IAAIH,EAAE,EAAGA,EAAEH,KAAKvE,OAAQ0E,IAAK,CAC9B,IAAK,IAAID,EAAE,EAAGA,EAAEF,KAAKG,GAAG1E,OAAQyE,IAC5BF,KAAKG,GAAGD,MAAQF,KAAKG,GAAGD,GAAG8J,UAAUhK,KAAKG,GAAGD,GAAG+J,QAAQM,QAAQ,OAEpEvK,KAAKG,GAAG0J,SAAW7J,KAAKG,GAAG0J,MAAMM,QAAQI,QAAQ,SAASvK,KAAKG,GAAG0J,MAAMO,MAAMG,QAAQ,MACtFvK,KAAK6J,MAAM1J,MAAQH,KAAK6J,MAAM1J,GAAGgK,QAAQI,QAAQ,SAASvK,KAAK6J,MAAM1J,GAAGiK,MAAMG,QAAQ,MAM1F,OAHAvK,KAAK6J,MAAMA,SAAW7J,KAAK6J,MAAMA,MAAMM,QAAQI,QAAQ,SAASvK,KAAK6J,MAAMA,MAAMO,MAAMG,QAAQ,WAE/FC,QAAQC,MAAMzK,MAKlB,MAAM0K,OAAS,CAACC,IAAKV,WACjBU,IAAMV,QAAUU,IAAIJ,QAAQ,GAAK,IAAMI,IAAIC,WAC3C,MAAMC,QAAUnP,KAAKG,IAAIH,KAAKC,OAAO,EAAQgP,IAAIlP,QAAU,GAAI,GACzDqP,SAAWpP,KAAKG,IAAI,GAAS8O,IAAIlP,OAASoP,SAAU,GAC1D,MAAO,IAAIE,OAAOF,SAASF,IAAI,IAAII,OAAOD,WAG9C,IAAIE,WACAC,iBAGJC,QAAQC,OAAOC,MAAM,UAErB,IAAK,IAAIjL,EAAE,EAAGA,EAAEH,KAAKvE,OAAQ0E,IAAK,CAG9B6K,WAAa,YAGb,IAAK,IAAI9K,EAAE,EAAGA,EAAEF,KAAKG,GAAG1E,OAAQyE,IAC5B+K,iBAAoB9K,GAAGD,EAAI,QAAa,QACxCgL,QAAQC,OAAOC,SAASJ,aAAaC,uBAA0BP,OAAO1K,KAAKG,GAAGD,GAAG8J,eAIrFgB,WAAa,YACbC,iBAAmB,QACnBC,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO1K,KAAKG,GAAG0J,MAAMM,SAAS,MAGtFa,WAAa,YACbE,QAAQC,OAAOC,SAASJ,gBAGxB,IAAK,IAAI9K,EAAE,EAAGA,EAAEF,KAAKG,GAAG1E,OAAQyE,IAC5B+K,iBAAoB9K,GAAGD,EAAI,QAAa,QACxCgL,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO1K,KAAKG,GAAGD,GAAG+J,SAAS,MAIvFe,WAAa,YACbC,iBAAmB,QACnBC,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO1K,KAAKG,GAAG0J,MAAMO,OAAO,MAGpFc,QAAQC,OAAOC,MAAM,eAIzBJ,WAAa,aAGb,IAAK,MAAMrM,OAAOqB,KAAK6J,MACnBqB,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO/L,IAAIwL,SAAS,MAIhFc,iBAAmB,YACnBC,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO1K,KAAK6J,MAAMA,MAAMM,SAAS,QAGzFa,WAAa,aACbC,iBAAmB,QAGnB,IAAK,MAAMtM,OAAOqB,KAAK6J,MACnBqB,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO/L,IAAIyL,OAAO,MAI9EY,WAAa,YACbC,iBAAmB,QACnBC,QAAQC,OAAOC,SAASJ,aAAaC,mBAAmBP,OAAO1K,KAAK6J,MAAMA,MAAMO,OAAO,QAGvFc,QAAQC,OAAOC,MAAM,WAKd,oBAAR9K,SAAwBA,OAAO3F,QAAUA,SAChD4F,QAAQ5F,QAAUA,cAGZ0Q,QAEFpR,aAAa2J,aAACA,aAAYoC,OAAEA,UAASxI,SAAEA,SAAS,aAAYlD,WAAEA,WAAW,UAASgR,KAAEA,KAAK,mBAAkBjH,SAAEA,SAAS,GAAGL,SACrHA,SAAQI,IAAEA,IAAGvB,WAAEA,WAAUnF,SAAEA,SAAQL,QAAEA,QAAQ,EAAC6B,GAAEA,GAAEE,GAAEA,GAAEK,QAAEA,QAAO1C,cAAEA,cAAazB,SAAEA,SAAQF,KAAEA,KAAImQ,KAAEA,UA+ChG,OA7CAhR,KAAKO,MAAQ,cACbP,KAAKyL,UACLzL,KAAKa,QACLb,KAAKgR,QACLhR,KAAKiR,OAAS,EACdjR,KAAK2J,WAAa,EAClB3J,KAAKkR,YAAc,EACnBlR,KAAK8C,QAAmB,GAATA,QAAiB,EAAIA,QACpC9C,KAAKkE,MAAQ,EACbnE,WAAaK,QAAQC,OAAON,YAC5BkD,SAAW7C,QAAQC,OAAO4C,UAC1B8N,KAAO3Q,QAAQC,OAAO0Q,MACtB/Q,KAAK6E,GAAK,EACV7E,KAAK2E,GAAK,EAENE,KACA7E,KAAK6E,GAAgB,kBAAJA,GAAgB,KAAQA,GACzC7E,KAAK4E,QAAU,GAGfD,KACA3E,KAAK2E,GAAgB,kBAAJA,GAAgB,KAAQA,GACzC3E,KAAK0E,QAAU,GAGfQ,UACAlF,KAAKkF,QAA0B,kBAATA,SAAsBA,QAAU,IAAOA,QAC7DlF,KAAKmF,aAAe,GAGpBkE,eAAgBrJ,KAAKqJ,aAAeA,cACpCtI,WAAgBf,KAAKe,SAAWA,UAEhCF,YACqBX,GAAjBW,KAAKjB,aAA2BI,KAAKa,KAAKjB,WAAaiB,KAAKjB,iBAC1CM,GAAlBW,KAAKhB,cAA2BG,KAAKa,KAAKhB,YAAcgB,KAAKhB,kBAChDK,GAAbW,KAAKf,SAA2BE,KAAKa,KAAKf,OAASe,KAAKf,SAG5DkR,OACIA,KAAKrR,OAAWK,KAAKgR,KAAKrR,KAAOqR,KAAKrR,MACtCqR,KAAKlR,SAAWE,KAAKgR,KAAKlR,OAASkR,KAAKlR,SAIxCmD,UAEJ,IAAK,UACDjD,KAAKqJ,kBAAkCnJ,GAAnBF,KAAKqJ,aAA0B,KAAQrJ,KAAKqJ,aAChE,MAEJ,IAAK,OACDrJ,KAAKqJ,kBAAkCnJ,GAAnBF,KAAKqJ,aAA0B,IAAOrJ,KAAKqJ,aAC/D,MAEJ,IAAK,WACDrJ,KAAKqJ,kBAAkCnJ,GAAnBF,KAAKqJ,aAA0B,GAAMrJ,KAAKqJ,aAC9DrJ,KAAK8J,SAAWA,SAChB,MAEJ,IAAK,WACD9J,KAAK6J,IAAW,MAALA,IAAY,IAAOA,IAC9B,MAEJ,QAEI,QAAuB3J,GAAnBF,KAAKqJ,aAEL,OAAQtJ,YAEJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACDC,KAAKqJ,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACDrJ,KAAKqJ,aAAe,KACpB,MAEJ,QACIrJ,KAAKqJ,aAAe,IAwCxC,GAnCArJ,KAAKiD,WAAY,EAAO,UAAM/C,GAAWiR,SAASlO,UAAY,aAAeA,SAC7EjD,KAAKiF,eAAiB9E,QAAQH,KAAKiD,UACnCjD,KAAKD,WAAgC,mBAAZA,WAAyBA,WAAaI,QAAQJ,YAAYO,KAAKN,MACxFA,KAAKkD,iBAAmBnD,WACxBC,KAAK+Q,KAAoB,mBAANA,KAAmBA,KAAO5Q,QAAQ4Q,MAElC,WAAf/Q,KAAKiD,WACLjD,KAAKyJ,cAAqBvJ,GAAVuJ,SAAsB,IAAOA,UAGjDzJ,KAAKsI,gBAAyBpI,GAAZoI,YAAyB,KAASA,WACpDtI,KAAK8H,WAA6B,KAAhB3G,KAAKwC,SACvB3D,KAAKmD,cAAqBjD,GAAViD,SAAsB,EAAIA,SAG1CnD,KAAKwC,eAAiB4O,aAAc,sBAEflR,GAAjBsC,eAA8BA,cAAc4O,eAC5CpR,KAAKwC,cAAc4O,aAAehR,QAAQC,OAAOmC,cAAc4O,eAG5B,WAAnCpR,KAAKwC,cAAc4O,aACnBpR,KAAKwC,cAAcuH,MAAQvH,oBAAsCtC,GAArBsC,cAAcuH,MAAmBvH,cAAcuH,MAAQ,GAEzD,YAAnC/J,KAAKwC,cAAc4O,eAC1BpR,KAAKwC,cAAc0H,KAAO1H,cAAc0H,MAAQ,EAChDlK,KAAKwC,cAAc2H,aAAe3H,cAAc2H,cAAgB,KAGxB,mBAAjCnK,KAAKwC,cAAc4O,aAC1BpR,KAAKuC,cAAgBvC,KAAKwC,cAAc4O,aAExCpR,KAAKuC,cAAgBpC,QAAQH,KAAKwC,cAAc4O,cAGhD3F,OAAOvK,OAEP,QAAQ,GAEJ,KAAKuK,OAAO4F,MAAMC,MAAQC,OAAOC,UAAUF,OACvCtR,KAAKyL,OAASA,OAAO1J,IAAIpC,MAAQ,IAAImB,QAAQnB,OAC7CK,KAAKO,MAAQ,cACbP,KAAKyR,aACL,MAEJ,KAAKhG,OAAO4F,MAAM7Q,OAASA,iBAAiBM,SAAWN,iBAAiBf,WAAae,iBAAiBQ,WAClGhB,KAAKO,MAAQ,cACbP,KAAKyL,OAASA,OACdzL,KAAKyR,aACL,MAEJ,QACI,MAAM,IAAI7P,MAAM,0DAI5B5B,KAAK0R,iBAAmB5C,YAAcC,cAAgBC,SAG1DtP,WAAY8D,MAAOmO,UAEf,OAAQ3R,KAAKO,OAET,IAAK,cACD,OAEJ,IAAK,cACDP,KAAKyL,OAAO,GAAK,IAAI3K,QAAQ0C,OAC7BxD,KAAKyL,OAAO,GAAK,IAAI3K,QAAQK,KAAKyQ,KAAKpO,MAAMmO,SAAW,EAAIA,SAAYxQ,KAAK2D,IAAItB,MAAMmO,UAAW,EACtCnO,MAAQmO,WACpE3R,KAAKyL,OAAO,GAAK,IAAI3K,QAAQK,KAAKyQ,KAAKD,WAI/C3R,KAAKyL,OAAOvJ,QAAQlC,KAAK6R,UAAUvR,KAAKN,OAExC,MAAM8R,QAAU9R,KAAKyL,OAAOzL,KAAKyL,OAAOvK,OAAO,GAAGvB,KAClDK,KAAK+R,4BAA8B,IAAIjQ,MAAMgQ,UAAU/P,IAAI6D,OAAS,IAAI9D,MAAMgQ,UAAU/P,IAAIY,GAAK,IACjG3C,KAAKgS,wBAA0B,IAAIlQ,MAAMgQ,UAAU/P,IAAI6D,OAAS,IAAI9D,MAAMgQ,UAAU/P,IAAIY,GAAK,IAC7F3C,KAAKiS,8BAAgC,IAAInQ,MAAMgQ,UAAU/P,IAAI6D,OAAS,IAAI9D,MAAMgQ,UAAU/P,IAAIY,GAAK,IAEnG3C,KAAKO,MAAQ,cAGjBb,UAAWc,MAAOE,YAEdF,MAAMI,IAAMZ,KACZQ,MAAMT,gBAA+BG,GAAlBM,MAAMT,WAAwBC,KAAKD,WAAaS,MAAMT,WAEzES,MAAMgC,iBACN0P,OAAOC,OAAO3R,MAAMgC,cAAexC,KAAKwC,eAEpC9B,YACAV,KAAKyL,OAAO/K,WAAW,GAAG0R,WAAW5R,OACrCA,MAAM6R,WAAWrS,KAAKyL,OAAO/K,WAAW,GAAIA,YAE5CF,MAAMgC,cAAc8H,MAAQ9J,MAAMG,UAAUhB,KAExCe,WAAWV,KAAKyL,OAAOvK,OAAO,IAC9BV,MAAMgC,cAAc+H,OAASvK,KAAKyL,OAAO/K,WAAW,GAAGf,MAG3Da,MAAMwC,QAEChD,KAAKyL,OAAOvK,OAAS,IAC5BV,MAAMgC,cAAc+H,OAASvK,KAAKyL,OAAO,GAAG9L,MAGhDa,MAAMD,MAAQ,cAGlBb,QAAS+F,MAEL,GAAgB,eAAZzF,KAAKO,MACL,MAAM,IAAIqB,MAAM,iDAGpB,QAAa1B,IAATuF,MAA+B,OAATA,KACtB,MAAM,IAAI7D,MAAM,uCAIpB,GAAIE,MAAMwQ,QAAQ7M,KAAK,IAAK,CACxB,MAAM8M,QAEN,IAAK,IAAI5M,EAAE,EAAGA,EAAEF,KAAKvE,OAAQyE,IACzB,IAAK,IAAIC,EAAE,EAAGA,EAAEH,KAAK,GAAGvE,OAAQ0E,IAC5B,IAAK,IAAIjD,EAAE,EAAGA,EAAE8C,KAAK,GAAGvE,OAAQyB,IAC5B4P,KAAK1M,KAAKJ,KAAKE,GAAGC,GAAGjD,IAIjC8C,KAAO8M,KAUX,OAPI9M,KAAKvE,QAAUlB,KAAKyL,OAAO,GAAGzH,QAAQ9C,QACtC+O,QAAQuC,KAAK,8DAGjBxS,KAAKyL,OAAO,GAAGzH,QAAQ9B,QAAQ,CAAC+B,OAAQmC,KAAOnC,OAAOlE,WAAa0F,KAAKW,KACxEpG,KAAKyL,OAAOvJ,QAAQ,CAAC1B,MAAOkL,KAAOA,IAAMlL,MAAMiS,WAExCzS,KAAKyL,OAAOzL,KAAKyL,OAAOvK,OAAO,GAAG8C,QAAQjC,IAAIkE,GAAKA,EAAElG,YAGhEL,SAAU2E,QAEN,QAAenE,IAAXmE,OACA,MAAM,IAAIzC,MAAM,wCAGhByC,OAAOnD,QAAUlB,KAAKyL,OAAOzL,KAAKyL,OAAOvK,OAAO,GAAG8C,QAAQ9C,QAC3D+O,QAAQuC,KAAK,iEAAkEnO,QAGnFrE,KAAKyL,OAAOzL,KAAKyL,OAAOvK,OAAO,GAAGwR,SAASrO,QAE3C,IAAK,IAAI3D,WAAWV,KAAKyL,OAAOvK,OAAO,EAAGR,WAAW,EAAGA,aACpDV,KAAKyL,OAAO/K,YAAYgS,WAIhChT,MAAOiT,SAAS1B,OAACA,OAAO,EAAC2B,SAAEA,SAAQC,iBAAEA,iBAAiB,EAACC,cAAEA,cAAajK,IAAEA,KAAI,EAAI7D,cAAEA,cAAc,EAAC+N,QAAEA,SAAQ,EAAKhE,WAAEA,gBAK9G,OAHA/O,KAAKgF,cAAsC,kBAAfA,eAA4BA,cAAgB2N,QAAQ,GAAGhB,SAASzQ,OAAS8D,cACrGhF,KAAK+O,WAAaA,WAEX,IAAIiE,QAAQ,CAACC,QAASC,UAUzB,GARIH,SACA3S,QAAQ2S,QAAQJ,SAGhB9J,KACAoH,QAAQpH,iCAAiCoI,sBAAsBjR,KAAKgF,sBAGxD9E,IAAZyS,SAAqC,OAAZA,QACzB,YAAYO,OAAO,oBASvB,GANkB,eAAdlT,KAAKO,OACLP,KAAKyR,WAAWnR,KAAKN,KAAM2S,QAAQ,GAAGnP,MAAMtC,OAAQyR,QAAQ,GAAGhB,SAASzQ,OAAxElB,GAGJA,KAAKyL,OAAOvJ,QAAQ1B,OAASA,MAAMD,MAAQ,YAEvCP,KAAK+O,aACL/O,KAAK+O,WAAWoE,SAAWnT,KAAK+O,WAAWoE,UAAYR,QAAQzR,OAE3DlB,KAAK+O,WAAWqE,eAChB,OAAQpT,KAAK+O,WAAWqE,cAAcvH,MAClC,IAAK,YACD7L,KAAK+O,WAAWqE,cAAcC,UAAYrT,KAAK+O,WAAWqE,cAAcC,WAAa,IACrF,MACJ,IAAK,WACDrT,KAAK+O,WAAWqE,cAAcE,gBAAkB,EAChDtT,KAAK+O,WAAWqE,cAAcG,UAAYpE,EAAAA,EAC1CnP,KAAK+O,WAAWqE,cAAcI,SAAWxT,KAAK+O,WAAWqE,cAAcI,UAAY,GACnF,MACJ,IAAK,aACDxT,KAAK+O,WAAWqE,cAAc1D,QAAU1P,KAAK+O,WAAWqE,cAAc1D,SAAW,GACjF1P,KAAK+O,WAAWqE,cAAcG,UAAYpE,EAAAA,EAM1D,IAEIsE,QAFAC,eAAiB,EACjBC,cAAgB,EAEpB,MAAMC,UAAY3H,KAAK4H,MAEjBC,cAAgB,KAGlB,GAFA9T,KAAKyL,OAAOvJ,QAAQ1B,OAASA,MAAMD,MAAQ,eAEvCP,KAAK+O,YAAc/O,KAAK+O,WAAWqE,gBAAwD,YAAtCpT,KAAK+O,WAAWqE,cAAcvH,MAA4D,cAAtC7L,KAAK+O,WAAWqE,cAAcvH,MACvI,IAAK,IAAIkI,EAAE,EAAGA,EAAE/T,KAAKyL,OAAOvK,OAAQ6S,IAChC/T,KAAKyL,OAAOsI,GAAGC,oBAInBnL,KACAoH,QAAQpH,sCAAsCzI,QAAQC,OAAOoT,QAAS,oCAAoCrT,QAAQC,OAAOoT,QAAQC,eAAgB,WAErJT,WAGEgB,QAAU,KACZjU,KAAKiR,SACLjR,KAAKkE,MAAQ,EACblE,KAAKkU,gBAAkB,EACvBR,eAAiB,OAECxT,GAAdF,KAAK0E,UAAoB1E,KAAK0E,QAAU,QAC1BxE,GAAdF,KAAK4E,UAAoB5E,KAAK4E,QAAU,GAE5CuP,eAGEA,YAAcC,UAEhB,IAAKzB,QAAQe,gBAAgBW,eAAe,WAAa1B,QAAQe,gBAAgBW,eAAe,YAC5F,YAAYnB,OAAO,wEAGvB,IAAIoB,cACAJ,gBAEJ,MAAM1Q,MAAQmP,QAAQe,gBAAgBlQ,MAChCmF,OAAS3I,KAAKyS,QAAQjP,OACtBkF,OAASiK,QAAQe,gBAAgB/B,SAEvC,IAAI4C,gBAAkBpF,EAAAA,EACtB,MAAM9K,UACN,IAAK,IAAI4B,EAAE,EAAGA,EAAE0C,OAAOzH,OAAQ+E,IAC3B5B,OAAO4B,IAAiB,GAAXyC,OAAOzC,GAAQ,EAAI,GAAK0C,OAAO1C,GAC5CsO,eAAiBpT,KAAKG,IAAIiT,eAAgB5L,OAAO1C,IAQrD,GALIjG,KAAK+R,wBAAwBrJ,OAAO8L,QAAQ,KAC5CxU,KAAK+R,wBAAwBrJ,OAAO8L,QAAQ,IAAI7L,OAAO6L,QAAQD,mBAI/DvU,KAAK+O,YAAc2E,gBAAkBA,eAAe1T,KAAK+O,WAAWoE,UAAU,IAE9Ee,sBAAwBlU,KAAKyU,SAASzU,KAAK+O,WAAWtJ,MAElDzF,KAAK+O,WAAWqE,eAAiBpT,KAAK0U,mBAAmBrQ,SAEzD,OADAwE,KAAOoH,QAAQpH,IAAI,kBACZiL,gBAoCf,GAhCA9T,KAAK0S,SAASrO,UAERqP,eAAe1T,KAAKgF,eAAe,GACrChF,KAAK2U,oBACL3U,KAAK4U,qBACElB,gBAAkBf,QAAQzR,QACjClB,KAAK2U,oBAGTL,cAAgBtU,KAAK+Q,KAAKrI,OAAQC,QAClC3I,KAAKkE,OAASoQ,cACdtU,KAAK2J,aAEL8J,QAAUxH,KAAK4H,MAAQD,UAEnBd,gBACA9S,KAAK0R,gBAAgB5C,SAASjJ,KAAKyO,eAE/BJ,iBACAlU,KAAK0R,gBAAgB3C,WAAWlJ,KAAKqO,kBAIxCR,eAAeb,kBAAoB,IAAKqB,iBAAqC,mBAAVtB,UACpEA,UACIjJ,WAAY3J,KAAK2J,WACjBuH,YAAalR,KAAKkR,YAClBgD,gBAAAA,gBAAiBI,cAAAA,cACjBb,QAAAA,QAASjQ,MAAAA,QAIbkQ,eAAiBf,QAAQzR,OAErBwS,eAAeb,kBAAoB,EACnCgC,WAAWV,YAAY7T,KAAKN,MAAO,GAEnCmU,kBAGD,CAGH,GAFAR,gBAEI9K,IAAK,CACL,IAAIiM,eAAiB9U,KAAKiR,2BAA2BjR,KAAKkE,MAAMwP,iBAE5D3E,aACA+F,6BAA+B9U,KAAKkU,wBAGtBhU,GAAdF,KAAK0E,UACLoQ,qBAAuB9U,KAAK0E,QAAQgP,kBAGxCoB,oBAAsB1U,QAAQC,OAAOoT,QAAS,6BAA6BrT,QAAQC,OAAOoT,QAAQE,cAAe,UACjH1D,QAAQpH,IAAIiM,MAGZnB,cAAgB1C,OAChBgD,UAEAH,kBAKZ9T,KAAK4U,oBACLX,YAIRvU,SAAU+F,MACN,OAAO,IAAIuN,QAAQ,CAACC,QAASC,UACzB,IAAI6B,gBAAkB,EAClBC,sBAAwB,EAE5B,MAAMC,aAAgB3D,OAElB,MAAM3I,OAAS3I,KAAKyS,QAAQhN,KAAKsP,iBAAiBvR,OAC5CkF,OAASjD,KAAKsP,iBAAiBpD,SAErC,IAAI4C,gBAAkBpF,EAAAA,EACtB,IAAK,IAAIlF,EAAE,EAAGA,EAAEtB,OAAOzH,OAAQ+I,IAC3BsK,eAAiBpT,KAAKG,IAAIiT,eAAgB5L,OAAOsB,IAGjDjK,KAAKiS,0BAA0BvJ,OAAO8L,QAAQ,KAC9CxU,KAAKiS,0BAA0BvJ,OAAO8L,QAAQ,IAAI7L,OAAO6L,QAAQD,mBAGrEvU,KAAKkR,cACL8D,uBAAyBhV,KAAK+Q,KAAKrI,OAAQC,QAE3C3I,KAAKkU,gBAAkBc,uBAAyBD,gBAAgB,KAE1DA,gBAAgBtP,KAAKvE,OACvB2T,WAAW,IAAMI,aAAaF,iBAAkB,IAEhD/U,KAAKkV,oBAAsBF,sBAAwBvP,KAAKvE,OACxD+R,QAAQ+B,sBAAwBvP,KAAKvE,UAG7C+T,aAAaF,mBAIrBrV,mBAAoB2E,QAEhB,IAAI8Q,MAAO,EAEX,OAAQnV,KAAK+O,WAAWqE,cAAcvH,MAClC,IAAK,YASD,OARAsJ,KAAOnV,KAAKkV,qBAAuBlV,KAAK+O,WAAWqE,cAAcC,aAI7DrT,KAAK0S,SAASrO,QACdrE,KAAK2U,qBAGFQ,KAEX,IAAK,WACD,GAAInV,KAAKkV,oBAAsBlV,KAAK+O,WAAWqE,cAAcG,UAAW,CACpEvT,KAAK+O,WAAWqE,cAAcE,gBAAkB,EAChDtT,KAAK+O,WAAWqE,cAAcG,UAAYvT,KAAKkV,oBAE/C,IAAK,IAAInB,EAAE,EAAGA,EAAE/T,KAAKyL,OAAOvK,OAAQ6S,IAChC/T,KAAKyL,OAAOsI,GAAGqB,wBAInBpV,KAAK+O,WAAWqE,cAAcE,kBAC9B6B,KAAOnV,KAAK+O,WAAWqE,cAAcE,iBAAiBtT,KAAK+O,WAAWqE,cAAcI,SAExF,OAAO2B,KAEX,IAAK,aACD,GAAInV,KAAKkV,oBAAsBlV,KAAK+O,WAAWqE,cAAcG,UAAW,CACpEvT,KAAK+O,WAAWqE,cAAcG,UAAYvT,KAAKkV,oBAE/C,IAAK,IAAInB,EAAE,EAAGA,EAAE/T,KAAKyL,OAAOvK,OAAQ6S,IAChC/T,KAAKyL,OAAOsI,GAAGqB,wBAGnBD,KAAOnV,KAAKkV,oBAAsBlV,KAAK+O,WAAWqE,cAAcG,WAAc,EAAEvT,KAAK+O,WAAWqE,cAAc1D,QAAQ,IAG1H,OAAOyF,MAInBzV,KAAM2V,SAASxM,IAACA,KAAI,EAAI+J,SAAEA,SAAQE,cAAEA,mBAChC,OAAO,IAAIE,QAAQ,CAACC,QAASC,eAEThT,IAAZmV,SAAqC,OAAZA,SACzBnC,OAAO,oBAGPrK,KACAoH,QAAQpH,IAAI,mBAGhB,IAAIyM,WAAa,EACb5B,eAAiB,EACrB,MAAME,UAAY3H,KAAK4H,MAEjB0B,UAAY,KAEd,MAAM/R,MAAQ6R,QAAQ3B,gBAAgBlQ,MAChCmF,OAAS3I,KAAKyS,QAAQjP,OACtBkF,OAAS2M,QAAQ3B,gBAAgB/B,SACjC8B,QAAUxH,KAAK4H,MAAQD,UAE7B,IAAIW,gBAAkBpF,EAAAA,EACtB,IAAK,IAAIlF,EAAE,EAAGA,EAAEtB,OAAOzH,OAAQ+I,IAC3BsK,eAAiBpT,KAAKG,IAAIiT,eAAgB5L,OAAOsB,IAGjDjK,KAAKgS,oBAAoBtJ,OAAO8L,QAAQ,KACxCxU,KAAKgS,oBAAoBtJ,OAAO8L,QAAQ,IAAI7L,OAAO6L,QAAQD,mBAG/D,MAAMiB,eAAiBxV,KAAK+Q,KAAKrI,OAAQC,QACzC2M,YAAcE,eACd9B,iBAEIZ,eACA9S,KAAK0R,gBAAgB1C,KAAKnJ,KAAK2P,gBAGd,mBAAV5C,UACPA,UACIjJ,WAAY+J,eACZxP,MAAOsR,eACP/B,QAAAA,QAASjQ,MAAAA,QAIbkQ,eAAiB2B,QAAQnU,OACzB2T,WAAWU,UAAUjV,KAAKN,MAAO,IAI7B6I,KACAoH,QAAQpH,qCAAqCzI,QAAQC,OAAOoT,QAAS,oCAAoCrT,QAAQC,OAAOoT,QAAQC,eAAgB,WAGpJT,QAAQqC,WAAWD,QAAQnU,UAGnCqU,cAIR7V,oBACIM,KAAKyL,OAAOvJ,QAAQ,CAAC1B,MAAOkL,KAAOA,IAAMlL,MAAMoU,qBAGnDlV,oBAEIM,KAAKyL,OAAOvJ,QAAQ,CAAC1B,MAAOkL,KAAOA,IAAMlL,MAAMmU,0BAE7BzU,GAAdF,KAAKkF,UACLlF,KAAKmF,aAAehE,KAAKI,KAAKvB,KAAKmF,cACnChF,QAAQ+E,QAAQ5E,KAAKN,KAArBG,IAIRT,SACI,OACI+L,OAAQzL,KAAKyL,OAAO1J,IAAIvB,OAASA,MAAMiV,WAI/C/V,SAAU+F,MAEN,QAAavF,IAATuF,MAA+B,OAATA,KACtB,MAAM,IAAI7D,MAAM,iCAGpB,GAAI6D,KAAKgG,OAAOvK,QAAUlB,KAAKyL,OAAOvK,OAClC,MAAM,IAAIU,4BAA4B6D,KAAKgG,OAAOvK,qCAAqClB,KAAKyL,OAAOvK,sBAGvGlB,KAAK4U,oBACL5U,KAAKyL,OAAOvJ,QAAQ,CAAC1B,MAAOkL,KAAOA,IAAMlL,MAAMkV,SAASjQ,KAAKgG,OAAOC,IAAKA,KAG7EhM,MAAOiW,UAAWC,SAEd,IAAKD,UACD,MAAM,IAAI/T,MAAM,mFAGpB,MAAM6D,QAEN,IAAK,IAAIsO,EAAE,EAAGA,EAAE/T,KAAKyL,OAAOvK,OAAQ6S,IAAK,CAErC,MAAM8B,UAAY7V,KAAKyL,OAAOsI,GAAG+B,QACjC,IAAK,IAAInT,EAAE,EAAGA,EAAEkT,UAAU3U,OAAQyB,IAC9B8C,KAAKI,KAAKgQ,UAAUlT,IAI5B,OAAOgT,UAAUG,MAAMrQ,KAAMmQ,MAGjClW,QAASqW,QAASJ,UAAWC,SAEzB,IAAKD,UACD,MAAM,IAAI/T,MAAM,mFAIpB,MAAM6D,KAAOkQ,UAAUK,QAAQD,QAASH,MAExC,IAAK,IAAI7B,EAAE,EAAGA,EAAE/T,KAAKyL,OAAOvK,OAAQ6S,IAAK,CAErC,MAAMkC,UAAYjW,KAAKyL,OAAOsI,GAAGmC,cACjClW,KAAKyL,OAAOsI,GAAGiC,QAAQvQ,KAAKmH,OAAO,EAAGqJ,aAI9CvW,qBAAsBmM,MAClB,GAAIA,KACAzL,QAAQ+V,qBAAqB/V,QAAQgW,oBAAoBpW,QAAQ6L,6BAC9D,CAEH,MAAMpG,QAEN,IAAK,IAAIG,EAAE,EAAGA,EAAE5F,KAAK+R,wBAAwB7Q,OAAQ0E,IAAK,CACtD,MAAMlD,OACN,IAAK,IAAIiD,EAAE,EAAGA,EAAE3F,KAAK+R,wBAAwB7Q,OAAQyE,IACjDjD,IAAImD,KAAK7F,KAAK+R,wBAAwBnM,GAAGD,GAAK3F,KAAKgS,oBAAoBpM,GAAGD,GAAK3F,KAAKiS,0BAA0BrM,GAAGD,IAErHF,KAAKI,KAAKnD,KAEdtC,QAAQ+V,qBAAqB/V,QAAQgW,oBAAoB3Q,QAIjE4Q,qBACI,MAAO,SAKA,oBAARtQ,SAAwBA,OAAO+K,QAAUA,SAChD9K,QAAQ8K,QAAUA,cAGZ5K,OAEFxG,eAEAA,MAAMuD,SAACA,SAAQlD,WAAEA,WAAUoD,SAAEA,cAEzB,MAAMxD,KAAOK,KAAKoC,QAAQlB,OAG1B,OAFAlB,KAAKyE,aAAezE,KAAKoC,QAAQL,IAAIY,GAAK,GAElCM,UAEJ,IAAK,OACDjD,KAAKgH,SAAW,EAChBhH,KAAKiH,gBAAkB,IAAInF,MAAMnC,OAAOoC,IAAIY,GAAK,GACjD3C,KAAKkH,cAAgB+C,CAAAA,GAAKjK,KAAKiH,YAAYgD,IAC3CjK,KAAKoH,cAAgB,EAAC6C,EAAEtH,IAAM3C,KAAKiH,YAAYgD,GAAKtH,GACpD,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACL,IAAK,WACD3C,KAAKqH,UAAY,EACjBrH,KAAKsH,iBAAmB,IAAIxF,MAAMnC,OAAOoC,IAAIY,GAAK,GAClD3C,KAAKuH,gBAAkB0C,CAAAA,GAAKjK,KAAKsH,aAAa2C,IAC9CjK,KAAKwH,gBAAkB,EAACyC,EAAEtH,IAAM3C,KAAKsH,aAAa2C,GAAKtH,GAEzC,YAAVM,WACAjD,KAAKyH,kBAAoB,EACzBzH,KAAK0H,kBAAoB,IAAI5F,MAAMnC,OAAOoC,IAAIY,GAAK,GACnD3C,KAAK2H,iBAAmBsC,CAAAA,GAAKjK,KAAK0H,cAAcuC,IAChDjK,KAAK4H,iBAAmB,EAACqC,EAAEtH,IAAM3C,KAAK0H,cAAcuC,GAAKtH,IAE7D,MAEJ,IAAK,OACD3C,KAAK6H,EAAI,EACT7H,KAAK2C,EAAI,EAID,SAAZ5C,WACAC,KAAK8H,WAA6B,KAAhB3G,KAAKwC,SAEJ,OAAZ5D,aACPC,KAAKmD,SAAWA,UAIxBzD,UAAWuK,GACP,OAAOjK,KAAKoC,QAAQ6H,GAGxBvK,UAAWuK,EAAGtH,GACV3C,KAAKoC,QAAQ6H,GAAKtH,EAGtBjD,eAAgBuK,GACZ,OAAOjK,KAAKyE,aAAawF,GAG7BvK,eAAgBuK,EAAGtH,GACf3C,KAAKyE,aAAawF,GAAKtH,GAKhB,oBAARoD,SAAwBA,OAAOG,OAASA,QAC/CF,QAAQE,OAASA,aAGXoQ,oBAAoBxV,QAEtBpB,YAAaC,MAAMI,WAACA,WAAUwW,QAAEA,aAE5BtO,MAAMtI,MAAOI,WAAAA,aAETwW,UACAvW,KAAKuW,SAAU,GAIvB7W,UAII,GAFAuI,MAAMwK,UAEFzS,KAAKuW,QAAS,CAEd,MAAMA,QAAUpW,QAAQoW,QAAQvW,KAAKgE,QAAQjC,IAAIkE,GAAKA,EAAElG,aAExD,IAAK,IAAIyW,EAAE,EAAGA,EAAED,QAAQrV,OAAQsV,IAC5BxW,KAAKgE,QAAQwS,GAAGzW,WAAawW,QAAQC,KAOtC,oBAARzQ,SAAwBA,OAAOuQ,YAAcA,aACpDtQ,QAAQsQ,YAAcA,kBAIhBtV,UAEFtB,YAAaC,MAAMG,OAACA,OAAMC,WAAEA,gBAEpBJ,OAAQK,KAAKL,KAAOA,MACpBG,SAAQE,KAAKF,OAASA,QAGtBE,KAAKD,gBADOG,GAAZH,YAAqC,GAAZA,aACY,mBAAZA,WAAyBA,WAAaI,QAAQC,QAAQC,OAAON,aAAaO,KAAKN,OAMhHN,QAEAA,WAAYc,OACRR,KAAKS,UAAYD,MAGrBd,WAAYc,MAAOE,YAEfV,KAAKW,UAAYH,MACjBR,KAAKL,KAAOK,KAAKL,MAAQK,KAAKY,IAAIoQ,KAAKrR,MAAQ,EAC/CK,KAAKF,OAASE,KAAKF,QAAUE,KAAKY,IAAIoQ,KAAKlR,QAAUE,KAAKL,KAC1DK,KAAKU,WAAaA,WAElB,IAAIW,kBAAoBb,MAAMgB,WAE9B,OAAQhB,MAAMiW,YAAYC,MAEtB,IAAK,UACD1W,KAAKe,SAAWf,KAAKY,IAAIG,SACzBM,kBAAoBF,KAAKG,IAAIH,KAAKC,MAAMD,KAAKI,KAAKf,MAAMb,KAAKK,KAAKe,WAAY,GAC9E,MAEJ,IAAK,YACDf,KAAKe,SAAWP,MAAMb,KACtB,MAEJ,IAAK,YACDK,KAAKe,SAAWP,MAAMO,SAQ9B,GAJAf,KAAKqB,kBAAoBA,kBACzBrB,KAAKwB,YAAcH,kBAAoBrB,KAAKL,MAAQK,KAAKF,OAAS,EAClEE,KAAKyB,iBAAmBJ,mBAAqB,EAEzCrB,KAAKwB,WAAW,GAAK,EACrB,MAAM,IAAII,8EAA8E5B,KAAKwB,qCAAqCd,cAGtIV,KAAKiB,gBAAkB,IAAIa,MAAM9B,KAAKe,WAAWgB,IAAIyC,aACtC,IAAI1C,MAAM9B,KAAKwB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM9B,KAAKwB,aAAaO,IAAIY,GAAK,KAE/F3C,KAAKqE,WAAa,IAAIvC,MAAM9B,KAAKe,WAAWgB,IAAIyC,aACjC,IAAI1C,MAAMT,oBAAoBU,IAAIW,SAAW,IAAIZ,MAAMT,oBAAoBU,IAAIY,GAAK,KAEnG3C,KAAKgL,QAAUhL,KAAKiB,YAAYc,IAAIyC,SAAWA,QAAQzC,IAAIW,KAAOA,IAAIX,IAAIY,IAAM,EAAE,MAGtFjD,UACI,IAAK,IAAI8E,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UAKvC,GAHArE,QAAQwW,QAAQ3W,KAAMwE,SAGlBxE,KAAKD,WACL,IAAK,IAAI2C,IAAI,EAAGA,IAAI1C,KAAKwB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKwB,WAAY4C,MACjCpE,KAAKiB,YAAYuD,SAAS9B,KAAK0B,KAAOpE,KAAKD,WAAWC,KAAKiB,YAAYuD,SAAS9B,KAAK0B,MAAM,EAAOpE,KAAKY,KAO3HlB,WAGI,IAAK,IAAI8E,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UACvC,IAAK,IAAI9B,IAAI,EAAGA,IAAI1C,KAAKqE,OAAO,GAAGnD,OAAQwB,MACvC,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKqE,OAAO,GAAGnD,OAAQkD,MACvCpE,KAAKqE,OAAOG,SAAS9B,KAAK0B,KAAO,EAK7C,GAAIpE,KAAKS,qBAAqBK,QAE1B,IAAK,IAAI0D,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UACvC,IAAK,IAAI9B,IAAI,EAAGA,IAAI1C,KAAKwB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKwB,WAAY4C,MAAO,CAExC,MAAMwK,KAAO5O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAK1B,IAAM1C,KAAKF,OACvD+O,KAAO7O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAKA,IAAMpE,KAAKF,OACvDgE,YAAcU,QAAUxE,KAAKwB,YAAY,EAAIkB,IAAM1C,KAAKwB,WAAa4C,IAE3E,IAAK,IAAIH,OAAO,EAAGA,OAAOjE,KAAKS,UAAUuD,QAAQ9C,OAAQ+C,SACrDjE,KAAKqE,OAAOG,SAASoK,MAAMC,OAAS7O,KAAKS,UAAUuD,QAAQC,QAAQC,MAC7BlE,KAAKS,UAAUuD,QAAQC,QAAQ7B,QAAQ0B,kBAM1F,GAAI9D,KAAKS,qBAAqBhB,UAEjC,IAAK,IAAI+E,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UAAW,CAElD,MAAMoS,QAEN,IAAK,IAAIxS,IAAI,EAAGA,IAAIpE,KAAKwB,WAAY4C,MACjCwS,KAAKxS,KAAO,EAIhBhE,QAAQ+D,kBAAkBnE,KAAKS,UAAWmW,KAAMpS,SAEhD,IAAK,IAAI9B,IAAI,EAAGA,IAAI1C,KAAKwB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKwB,WAAY4C,MAAO,CAExC,MAAMwK,KAAO5O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAK1B,IAAM1C,KAAKF,OACvD+O,KAAO7O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAKA,IAAMpE,KAAKF,OAE7DE,KAAKqE,OAAOG,SAASoK,MAAMC,OAAS+H,KAAKlU,KAAK0B,WAO1D,IAAK,IAAII,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UACvC,IAAK,IAAI9B,IAAI,EAAGA,IAAI1C,KAAKwB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKwB,WAAY4C,MAAO,CAExC,MAAMwK,KAAO5O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAK1B,IAAM1C,KAAKF,OACvD+O,KAAO7O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAKA,IAAMpE,KAAKF,OAE7DE,KAAKqE,OAAOG,SAASoK,MAAMC,OAAS7O,KAAKS,UAAU4D,OAAOG,SAAS9B,KAAK0B,KAOxF,GAAIpE,KAAKD,WACL,IAAK,IAAIyE,QAAQ,EAAGA,QAAQxE,KAAKe,SAAUyD,UAEvC,IAAK,IAAI9B,IAAI,EAAGA,IAAI1C,KAAKgL,QAAQxG,SAAStD,OAAQwB,MAC9C,IAAK,IAAI0B,IAAI,EAAGA,IAAIpE,KAAKgL,QAAQxG,SAAStD,OAAQkD,MAAO,CAErD,MAAMwK,KAAO5O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAK1B,IAAM1C,KAAKF,OACvD+O,KAAO7O,KAAKgL,QAAQxG,SAAS9B,KAAK0B,KAAK,GAAKA,IAAMpE,KAAKF,OAE7DE,KAAKqE,OAAOG,SAASoK,MAAMC,OAAS7O,KAAKD,WAAWC,KAAKqE,OAAOG,SAASoK,MAAMC,OAAO,EAAM7O,KAAKY,MAOrHlB,qBAEAA,qBAEAA,oBAEAA,qBAEAA,SAAW,SAEXA,YAEAA,cAAgB,OAAO,EAEvBA,QAAU,SAEVA,YAIW,oBAARqG,SAAwBA,OAAO/E,UAAYA,WAClDgF,QAAQhF,UAAYA","file":"jsNetJS.min.js","sourcesContent":["\"use strict\"\r\n\r\nclass ConvLayer {\r\n\r\n    constructor (size, {filterSize, zeroPadding, stride, activation}={}) {\r\n\r\n        if (filterSize)     this.filterSize = filterSize\r\n        if (stride)         this.stride = stride\r\n        if (size)           this.size = size\r\n\r\n        this.zeroPadding = zeroPadding\r\n        this.activationName = activation\r\n\r\n        if (activation!=undefined) {\r\n\r\n            if (typeof activation==\"boolean\" && !activation) {\r\n                this.activation = false\r\n            } else {\r\n                this.activation = typeof activation==\"function\" ? activation : NetMath[NetUtil.format(activation)].bind(this)\r\n            }\r\n        }\r\n\r\n        this.state = \"not-initialised\"\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n\r\n        this.prevLayer = layer\r\n\r\n        this.layerIndex = layerIndex\r\n        this.size = this.size || 4\r\n        this.filterSize = this.filterSize || this.net.conv.filterSize || 3\r\n        this.stride = this.stride || this.net.conv.stride || 1\r\n\r\n        switch (true) {\r\n            case layer instanceof FCLayer:\r\n                this.channels = this.net.channels ||1\r\n                break\r\n\r\n            case layer instanceof ConvLayer:\r\n                this.channels = layer.size\r\n                break\r\n\r\n            case layer instanceof PoolLayer:\r\n                this.channels = layer.activations.length\r\n                break\r\n        }\r\n\r\n        if (this.zeroPadding==undefined) {\r\n            this.zeroPadding = this.net.conv.zeroPadding==undefined ? Math.floor(this.filterSize/2) : this.net.conv.zeroPadding\r\n        }\r\n\r\n        // Caching calculations\r\n        const prevLayerOutWidth = layer instanceof FCLayer ? Math.max(Math.floor(Math.sqrt(layer.size/this.channels)), 1)\r\n                                                           : layer.outMapSize\r\n\r\n        this.inMapValuesCount = Math.pow(prevLayerOutWidth, 2)\r\n        this.inZPMapValuesCount = Math.pow(prevLayerOutWidth + this.zeroPadding*2, 2)\r\n        this.outMapSize = (prevLayerOutWidth - this.filterSize + 2*this.zeroPadding) / this.stride + 1\r\n\r\n        if (this.outMapSize%1!=0) {\r\n            throw new Error(`Misconfigured hyperparameters. Activation volume dimensions would be ${this.outMapSize} in conv layer at index ${layerIndex}`)\r\n        }\r\n\r\n        this.filters = [...new Array(this.size)].map(f => new Filter())\r\n    }\r\n\r\n    init () {\r\n        this.filters.forEach(filter => {\r\n\r\n            filter.weights = [...new Array(this.channels)].map(channelWeights => {\r\n                return [...new Array(this.filterSize)].map(weightsRow => this.net.weightsInitFn(this.filterSize, this.weightsConfig))\r\n            })\r\n\r\n            filter.activationMap = [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n            filter.errorMap = [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n            filter.bias = 1\r\n\r\n            if (this.net.dropout != 1) {\r\n                filter.dropoutMap = filter.activationMap.map(row => row.map(v => false))\r\n            }\r\n\r\n            filter.init({\r\n                updateFn: this.net.updateFn,\r\n                activation: this.activationName || this.net.activationConfig,\r\n                eluAlpha: this.net.eluAlpha\r\n            })\r\n        })\r\n    }\r\n\r\n    forward () {\r\n\r\n        const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n        for (let filterI=0; filterI<this.size; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            filter.sumMap = NetUtil.convolve({\r\n                input: activations,\r\n                zeroPadding: this.zeroPadding,\r\n                weights: filter.weights,\r\n                channels: this.channels,\r\n                stride: this.stride,\r\n                bias: filter.bias\r\n            })\r\n\r\n            for (let sumY=0; sumY<filter.sumMap.length; sumY++) {\r\n                for (let sumX=0; sumX<filter.sumMap.length; sumX++) {\r\n                    if (this.state==\"training\" && filter.dropoutMap && (filter.dropoutMap[sumY][sumX] = Math.random() > this.net.dropout)) {\r\n                        filter.activationMap[sumY][sumX] = 0\r\n                    } else if (this.activation) {\r\n                        filter.activationMap[sumY][sumX] = this.activation(filter.sumMap[sumY][sumX], false, filter) / (this.net.dropout||1)\r\n                    } else {\r\n                        filter.activationMap[sumY][sumX] = filter.sumMap[sumY][sumX]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    backward () {\r\n\r\n        // First, get the filters' error maps\r\n        if (this.nextLayer instanceof FCLayer) {\r\n\r\n            // For each filter, build the errorMap from the weighted neuron errors in the next FCLayer corresponding to each value in the activation map\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n                const filter = this.filters[filterI]\r\n\r\n                for (let emY=0; emY<filter.errorMap.length; emY++) {\r\n                    for (let emX=0; emX<filter.errorMap.length; emX++) {\r\n\r\n                        const weightIndex = filterI * this.outMapSize**2 + emY * filter.errorMap.length + emX\r\n\r\n                        for (let neuronI=0; neuronI<this.nextLayer.neurons.length; neuronI++) {\r\n\r\n                            const neuron = this.nextLayer.neurons[neuronI]\r\n                            filter.errorMap[emY][emX] += neuron.error * neuron.weights[weightIndex]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else if (this.nextLayer instanceof ConvLayer) {\r\n\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n                NetUtil.buildConvErrorMap(this.nextLayer, this.filters[filterI].errorMap, filterI)\r\n            }\r\n\r\n        } else {\r\n\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n                const filter = this.filters[filterI]\r\n\r\n                for (let row=0; row<filter.errorMap.length; row++) {\r\n                    for (let col=0; col<filter.errorMap.length; col++) {\r\n                        filter.errorMap[row][col] = this.nextLayer.errors[filterI][row][col]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Apply derivative to each error value\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            for (let row=0; row<filter.errorMap.length; row++) {\r\n                for (let col=0; col<filter.errorMap[0].length; col++) {\r\n\r\n                    if (filter.dropoutMap && filter.dropoutMap[row][col]) {\r\n                        filter.errorMap[row][col] = 0\r\n                    } else if (this.activation){\r\n                        filter.errorMap[row][col] *= this.activation(filter.sumMap[row][col], true, filter)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Then use the error map values to build the delta weights\r\n        NetUtil.buildConvDWeights(this)\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n            filter.deltaBias = 0\r\n\r\n            for (let channel=0; channel<filter.deltaWeights.length; channel++) {\r\n                for (let row=0; row<filter.deltaWeights[0].length; row++) {\r\n                    for (let col=0; col<filter.deltaWeights[0][0].length; col++) {\r\n                        filter.deltaWeights[channel][row][col] = 0\r\n                    }\r\n                }\r\n            }\r\n\r\n            for (let row=0; row<filter.errorMap.length; row++) {\r\n                for (let col=0; col<filter.errorMap.length; col++) {\r\n                    filter.errorMap[row][col] = 0\r\n                }\r\n            }\r\n\r\n            if (filter.dropoutMap) {\r\n                for (let row=0; row<filter.dropoutMap.length; row++) {\r\n                    for (let col=0; col<filter.dropoutMap[0].length; col++) {\r\n                        filter.dropoutMap[row][col] = false\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            for (let channel=0; channel<filter.deltaWeights.length; channel++) {\r\n                for (let row=0; row<filter.deltaWeights[0].length; row++) {\r\n                    for (let col=0; col<filter.deltaWeights[0][0].length; col++) {\r\n\r\n                        if (this.net.l2Error!=undefined) this.net.l2Error += 0.5 * this.net.l2 * filter.weights[channel][row][col]**2\r\n                        if (this.net.l1Error!=undefined) this.net.l1Error += this.net.l1 * Math.abs(filter.weights[channel][row][col])\r\n\r\n                        const regularized = (filter.deltaWeights[channel][row][col]\r\n                            + this.net.l2 * filter.weights[channel][row][col]\r\n                            + this.net.l1 * (filter.weights[channel][row][col] > 0 ? 1 : -1)) / this.net.miniBatchSize\r\n\r\n                        filter.weights[channel][row][col] = this.net.weightUpdateFn.bind(this.net, filter.weights[channel][row][col],\r\n                                                                regularized, filter, [channel, row, col])()\r\n\r\n                        if (this.net.maxNorm!=undefined) this.net.maxNormTotal += filter.weights[channel][row][col]**2\r\n                    }\r\n                }\r\n            }\r\n\r\n            filter.bias = this.net.weightUpdateFn.bind(this.net, filter.bias, filter.deltaBias, filter)()\r\n        }\r\n    }\r\n\r\n    backUpValidation () {\r\n        for (let f=0; f<this.filters.length; f++) {\r\n            const filter = this.filters[f]\r\n\r\n            filter.validationBias = filter.bias\r\n            filter.validationWeights = []\r\n\r\n            for (let wd=0; wd<filter.weights.length; wd++) {\r\n                const channel = []\r\n                for (let wy=0; wy<filter.weights[wd].length; wy++) {\r\n                    channel[wy] = filter.weights[wd][wy].slice(0)\r\n                }\r\n                filter.validationWeights[wd] = channel\r\n            }\r\n        }\r\n    }\r\n\r\n    restoreValidation () {\r\n        for (let f=0; f<this.filters.length; f++) {\r\n            const filter = this.filters[f]\r\n\r\n            filter.bias = filter.validationBias\r\n\r\n            for (let wd=0; wd<filter.weights.length; wd++) {\r\n                for (let wy=0; wy<filter.weights[wd].length; wy++) {\r\n                    filter.weights[wd][wy] = filter.validationWeights[wd][wy].slice(0)\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.filters.map(filter => {\r\n                return {\r\n                    bias: filter.bias,\r\n                    weights: filter.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n        this.filters.forEach((filter, fi) => {\r\n\r\n            if (data.weights[fi].weights.length != filter.weights.length) {\r\n                throw new Error(`Mismatched weights depth. Given: ${data.weights[fi].weights.length} Existing: ${filter.weights.length}. At: layers[${layerIndex}], filters[${fi}]`)\r\n            }\r\n\r\n            if (data.weights[fi].weights[0].length != filter.weights[0].length) {\r\n                throw new Error(`Mismatched weights size. Given: ${data.weights[fi].weights[0].length} Existing: ${filter.weights[0].length}. At: layers[${layerIndex}], filters[${fi}]`)\r\n            }\r\n\r\n            filter.bias = data.weights[fi].bias\r\n            filter.weights = data.weights[fi].weights\r\n        })\r\n    }\r\n\r\n    // Used for importing data\r\n    getDataSize () {\r\n\r\n        let size = 0\r\n\r\n        for (let f=0; f<this.filters.length; f++) {\r\n\r\n            const filter = this.filters[f]\r\n\r\n            for (let c=0; c<filter.weights.length; c++) {\r\n                for (let r=0; r<filter.weights[c].length; r++) {\r\n                    size += filter.weights[c][r].length\r\n                }\r\n            }\r\n\r\n            size += 1\r\n        }\r\n\r\n        return size\r\n    }\r\n\r\n    toIMG () {\r\n\r\n        const data = []\r\n\r\n        for (let f=0; f<this.filters.length; f++) {\r\n            const filter = this.filters[f]\r\n\r\n            data.push(filter.bias)\r\n\r\n            for (let c=0; c<filter.weights.length; c++) {\r\n                for (let r=0; r<filter.weights[c].length; r++) {\r\n                    for (let v=0; v<filter.weights[c][r].length; v++) {\r\n                        data.push(filter.weights[c][r][v])\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return data\r\n    }\r\n\r\n    fromIMG (data) {\r\n\r\n        let valI = 0\r\n\r\n        for (let f=0; f<this.filters.length; f++) {\r\n\r\n            const filter = this.filters[f]\r\n            filter.bias = data[valI]\r\n            valI++\r\n\r\n            for (let c=0; c<filter.weights.length; c++) {\r\n                for (let r=0; r<filter.weights[c].length; r++) {\r\n                    for (let v=0; v<filter.weights[c][r].length; v++) {\r\n                        filter.weights[c][r][v] = data[valI]\r\n                        valI++\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n// https://github.com/DanRuta/jsNet/issues/33\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.exports = window.exports || {})\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.ConvLayer = ConvLayer)\r\nexports.ConvLayer = ConvLayer\r\n\"use strict\"\r\n\r\nclass FCLayer {\r\n\r\n    constructor (size, {activation}={}) {\r\n        this.size = size\r\n        this.neurons = [...new Array(size)].map(n => new Neuron())\r\n        this.state = \"not-initialised\"\r\n\r\n        if (activation!=undefined) {\r\n            if (typeof activation==\"boolean\" && !activation) {\r\n                this.activation = false\r\n            } else {\r\n                this.activation = typeof activation==\"function\" ? activation : NetMath[NetUtil.format(activation)].bind(this)\r\n            }\r\n        }\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n        this.prevLayer = layer\r\n        this.layerIndex = layerIndex\r\n    }\r\n\r\n    init () {\r\n        this.neurons.forEach(neuron => {\r\n\r\n            let weightsCount\r\n\r\n            switch (true) {\r\n                case this.prevLayer instanceof FCLayer:\r\n                    weightsCount = this.prevLayer.size\r\n                    break\r\n\r\n                case this.prevLayer instanceof ConvLayer:\r\n                    weightsCount = this.prevLayer.filters.length * this.prevLayer.outMapSize**2\r\n                    break\r\n\r\n                case this.prevLayer instanceof PoolLayer:\r\n                    weightsCount = this.prevLayer.activations.length * this.prevLayer.outMapSize**2\r\n                    break\r\n            }\r\n\r\n            neuron.weights = this.net.weightsInitFn(weightsCount, this.weightsConfig)\r\n            neuron.bias = 1\r\n\r\n            neuron.init({\r\n                updateFn: this.net.updateFn,\r\n                activationConfig: this.net.activationConfig,\r\n                eluAlpha: this.net.eluAlpha\r\n            })\r\n        })\r\n    }\r\n\r\n    forward () {\r\n        this.neurons.forEach((neuron, ni) => {\r\n            if (this.state==\"training\" && (neuron.dropped = Math.random() > this.net.dropout)) {\r\n                neuron.activation = 0\r\n            } else {\r\n                neuron.sum = neuron.bias\r\n\r\n                const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n                for (let ai=0; ai<activations.length; ai++) {\r\n                    neuron.sum += activations[ai] * neuron.weights[ai]\r\n                }\r\n\r\n                neuron.activation = (this.activation ? this.activation(neuron.sum, false, neuron) : neuron.sum) / (this.net.dropout||1)\r\n            }\r\n        })\r\n    }\r\n\r\n    backward (errors) {\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (neuron.dropped) {\r\n                neuron.error = 0\r\n                neuron.deltaBias += 0\r\n            } else {\r\n                if (typeof errors !== \"undefined\") {\r\n                    neuron.error = errors[ni]\r\n                } else {\r\n                    neuron.derivative = this.activation ? this.activation(neuron.sum, true, neuron) : 1\r\n                    neuron.error = neuron.derivative * this.nextLayer.neurons.map(n => n.error * (n.weights[ni]||0))\r\n                                                                             .reduce((p,c) => p+c, 0)\r\n                }\r\n\r\n                const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n                for (let wi=0; wi<neuron.weights.length; wi++) {\r\n                    neuron.deltaWeights[wi] += (neuron.error * activations[wi])\r\n                }\r\n\r\n                neuron.deltaBias += neuron.error\r\n            }\r\n        })\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n\r\n            this.neurons[n].deltaBias = 0\r\n\r\n            for (let dwi=0; dwi<this.neurons[n].deltaWeights.length; dwi++) {\r\n                this.neurons[n].deltaWeights[dwi] = 0\r\n            }\r\n        }\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n\r\n            const neuron = this.neurons[n]\r\n\r\n            for (let dwi=0; dwi<this.neurons[n].deltaWeights.length; dwi++) {\r\n\r\n                if (this.net.l2Error!=undefined) this.net.l2Error += 0.5 * this.net.l2 * neuron.weights[dwi]**2\r\n                if (this.net.l1Error!=undefined) this.net.l1Error += this.net.l1 * Math.abs(neuron.weights[dwi])\r\n\r\n                const regularized = (neuron.deltaWeights[dwi]\r\n                    + this.net.l2 * neuron.weights[dwi]\r\n                    + this.net.l1 * (neuron.weights[dwi] > 0 ? 1 : -1)) / this.net.miniBatchSize\r\n\r\n                neuron.weights[dwi] = this.net.weightUpdateFn.bind(this.net, neuron.weights[dwi], regularized, neuron, dwi)()\r\n\r\n                if (this.net.maxNorm!=undefined) this.net.maxNormTotal += neuron.weights[dwi]**2\r\n            }\r\n\r\n            neuron.bias = this.net.weightUpdateFn.bind(this.net, neuron.bias, neuron.deltaBias, neuron)()\r\n        }\r\n    }\r\n\r\n    backUpValidation () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n            const neuron = this.neurons[n]\r\n            neuron.validationBias = neuron.bias\r\n            neuron.validationWeights = neuron.weights.slice(0)\r\n        }\r\n    }\r\n\r\n    restoreValidation () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n            const neuron = this.neurons[n]\r\n            neuron.bias = neuron.validationBias\r\n            neuron.weights = neuron.validationWeights.slice(0)\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.neurons.map(neuron => {\r\n                return {\r\n                    bias: neuron.bias,\r\n                    weights: neuron.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (data.weights[ni].weights.length!=neuron.weights.length) {\r\n                throw new Error(`Mismatched weights count. Given: ${data.weights[ni].weights.length} Existing: ${neuron.weights.length}. At layers[${layerIndex}], neurons[${ni}]`)\r\n            }\r\n\r\n            neuron.bias = data.weights[ni].bias\r\n            neuron.weights = data.weights[ni].weights\r\n        })\r\n    }\r\n\r\n    // Used for importing data\r\n    getDataSize () {\r\n\r\n        let size = 0\r\n\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n            size += this.neurons[n].weights.length + 1\r\n        }\r\n\r\n        return size\r\n    }\r\n\r\n    toIMG () {\r\n        const data = []\r\n\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n            data.push(this.neurons[n].bias)\r\n\r\n            for (let w=0; w<this.neurons[n].weights.length; w++) {\r\n                data.push(this.neurons[n].weights[w])\r\n            }\r\n        }\r\n\r\n        return data\r\n    }\r\n\r\n    fromIMG (data) {\r\n\r\n        let valI = 0\r\n\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n\r\n            const neuron = this.neurons[n]\r\n            neuron.bias = data[valI]\r\n            valI++\r\n\r\n            for (let w=0; w<neuron.weights.length; w++) {\r\n                neuron.weights[w] = data[valI]\r\n                valI++\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nconst Layer = FCLayer\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.FCLayer = window.Layer = FCLayer)\r\nexports.FCLayer = exports.Layer = FCLayer\r\n\"use strict\"\r\n\r\nclass Filter {\r\n\r\n    constructor () {}\r\n\r\n    init ({updateFn, activation, eluAlpha}={}) {\r\n\r\n        this.deltaWeights = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n        this.deltaBias = 0\r\n\r\n        switch (updateFn) {\r\n\r\n            case \"gain\":\r\n                this.biasGain = 1\r\n                this.weightGains = this.weights.map(channel => channel.map(wRow => wRow.map(w => 1)))\r\n                this.getWeightGain = ([channel, row, column]) => this.weightGains[channel][row][column]\r\n                this.setWeightGain = ([channel, row, column], v) => this.weightGains[channel][row][column] = v\r\n                break\r\n\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n            case \"momentum\":\r\n                this.biasCache = 0\r\n                this.weightsCache = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n                this.getWeightsCache = ([channel, row, column]) => this.weightsCache[channel][row][column]\r\n                this.setWeightsCache = ([channel, row, column], v) => this.weightsCache[channel][row][column] = v\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    this.adadeltaBiasCache = 0\r\n                    this.adadeltaCache = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n                    this.getAdadeltaCache = ([channel, row, column]) => this.adadeltaCache[channel][row][column]\r\n                    this.setAdadeltaCache = ([channel, row, column], v) => this.adadeltaCache[channel][row][column] = v\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                this.m = 0\r\n                this.v = 0\r\n                break\r\n        }\r\n\r\n        if (activation==\"rrelu\") {\r\n            this.rreluSlope = Math.random() * 0.001\r\n\r\n        } else if (activation==\"elu\") {\r\n            this.eluAlpha = eluAlpha\r\n        }\r\n    }\r\n\r\n    getWeight ([channel, row, column]) {\r\n        return this.weights[channel][row][column]\r\n    }\r\n\r\n    setWeight ([channel, row, column], v) {\r\n        this.weights[channel][row][column] = v\r\n    }\r\n\r\n    getDeltaWeight ([channel, row, column]) {\r\n        return this.deltaWeights[channel][row][column]\r\n    }\r\n\r\n    setDeltaWeight ([channel, row, column], v) {\r\n        this.deltaWeights[channel][row][column] = v\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.Filter = Filter)\r\nexports.Filter = Filter\r\n\"use strict\"\r\n\r\nclass InputLayer extends FCLayer {\r\n    constructor (size, {span=1}={}) {\r\n        super(size * span*span)\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.InputLayer = InputLayer)\r\nexports.InputLayer = InputLayer\r\n\r\n\"use strict\"\r\n\r\nclass NetMath {\r\n\r\n    // Activation functions\r\n    static sigmoid (value, prime) {\r\n        const val = 1/(1+Math.exp(-value))\r\n        return prime ? val*(1-val)\r\n                     : val\r\n    }\r\n\r\n    static tanh (value, prime) {\r\n        const exp = Math.exp(2*value)\r\n        return prime ? 4/Math.pow(Math.exp(value)+Math.exp(-value), 2) || 1e-18\r\n                     : (exp-1)/(exp+1) || 1e-18\r\n    }\r\n\r\n    static relu (value, prime) {\r\n        return prime ? value > 0 ? 1 : 0\r\n                     : Math.max(value, 0)\r\n    }\r\n\r\n    static lrelu (value, prime) {\r\n        return prime ? value > 0 ? 1 : (this.lreluSlope || -0.0005)\r\n                     : Math.max((this.lreluSlope || -0.0005)*Math.abs(value), value)\r\n    }\r\n\r\n    static rrelu (value, prime, neuron) {\r\n        return prime ? value > 0 ? 1 : neuron.rreluSlope\r\n                     : Math.max(neuron.rreluSlope, value)\r\n    }\r\n\r\n    static lecuntanh (value, prime) {\r\n        return prime ? 1.15333 * Math.pow(NetMath.sech((2/3) * value), 2)\r\n                     : 1.7159 * NetMath.tanh((2/3) * value)\r\n    }\r\n\r\n    static elu (value, prime, neuron) {\r\n        return prime ? value >=0 ? 1 : NetMath.elu(value, false, neuron) + neuron.eluAlpha\r\n                     : value >=0 ? value : neuron.eluAlpha * (Math.exp(value) - 1)\r\n    }\r\n\r\n    // Cost functions\r\n    static crossentropy (target, output) {\r\n        return output.map((value, vi) => target[vi] * Math.log(value+1e-15) + ((1-target[vi]) * Math.log((1+1e-15)-value)))\r\n                     .reduce((p,c) => p-c, 0)\r\n    }\r\n\r\n    static meansquarederror (calculated, desired) {\r\n        return calculated.map((output, index) => Math.pow(output - desired[index], 2))\r\n                         .reduce((prev, curr) => prev+curr, 0) / calculated.length\r\n    }\r\n\r\n    static rootmeansquarederror (calculated, desired) {\r\n        return Math.sqrt(NetMath.meansquarederror(calculated, desired))\r\n    }\r\n\r\n    // Weight updating functions\r\n    static vanillasgd (value, deltaValue) {\r\n        return value + this.learningRate * deltaValue\r\n    }\r\n\r\n    static gain (value, deltaValue, neuron, weightI) {\r\n\r\n        const newVal = value + this.learningRate * deltaValue * (weightI==null ? neuron.biasGain : neuron.getWeightGain(weightI))\r\n\r\n        if (newVal<=0 && value>0 || newVal>=0 && value<0){\r\n            if (weightI!=null) {\r\n                neuron.setWeightGain(weightI, Math.max(neuron.getWeightGain(weightI)*0.95, 0.5))\r\n            } else {\r\n                neuron.biasGain = Math.max(neuron.biasGain*0.95, 0.5)\r\n            }\r\n        } else {\r\n            if (weightI!=null) {\r\n                neuron.setWeightGain(weightI, Math.min(neuron.getWeightGain(weightI)+0.05, 5))\r\n            } else {\r\n                neuron.biasGain = Math.min(neuron.biasGain+0.05, 5)\r\n            }\r\n        }\r\n\r\n        return newVal\r\n    }\r\n\r\n    static adagrad (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, neuron.getWeightsCache(weightI) + Math.pow(deltaValue, 2))\r\n        } else {\r\n            neuron.biasCache += Math.pow(deltaValue, 2)\r\n        }\r\n\r\n        return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI!=null ? neuron.getWeightsCache(weightI)\r\n                                                                                        : neuron.biasCache))\r\n    }\r\n\r\n    static rmsprop (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, this.rmsDecay * neuron.getWeightsCache(weightI) + (1 - this.rmsDecay) * Math.pow(deltaValue, 2))\r\n        } else {\r\n            neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2)\r\n        }\r\n\r\n        return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI!=null ? neuron.getWeightsCache(weightI)\r\n                                                                                        : neuron.biasCache))\r\n    }\r\n\r\n    static adam (value, deltaValue, neuron) {\r\n\r\n        neuron.m = 0.9*neuron.m + (1-0.9) * deltaValue\r\n        const mt = neuron.m / (1-Math.pow(0.9, this.iterations + 1))\r\n\r\n        neuron.v = 0.999*neuron.v + (1-0.999) * Math.pow(deltaValue, 2)\r\n        const vt = neuron.v / (1-Math.pow(0.999, this.iterations + 1))\r\n\r\n        return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8)\r\n    }\r\n\r\n    static adadelta (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, this.rho * neuron.getWeightsCache(weightI) + (1-this.rho) * Math.pow(deltaValue, 2))\r\n            const newVal = value + Math.sqrt((neuron.getAdadeltaCache(weightI) + 1e-6)/(neuron.getWeightsCache(weightI) + 1e-6)) * deltaValue\r\n            neuron.setAdadeltaCache(weightI, this.rho * neuron.getAdadeltaCache(weightI) + (1-this.rho) * Math.pow(deltaValue, 2))\r\n            return newVal\r\n\r\n        } else {\r\n            neuron.biasCache = this.rho * neuron.biasCache + (1-this.rho) * Math.pow(deltaValue, 2)\r\n            const newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6)/(neuron.biasCache + 1e-6)) * deltaValue\r\n            neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1-this.rho) * Math.pow(deltaValue, 2)\r\n            return newVal\r\n        }\r\n    }\r\n\r\n    static momentum (value, deltaValue, neuron, weightI) {\r\n\r\n        let v\r\n\r\n        if (weightI!=null) {\r\n            v = this.momentum * (neuron.getWeightsCache(weightI)) - this.learningRate * deltaValue\r\n            neuron.setWeightsCache(weightI, v)\r\n        } else {\r\n            v = this.momentum * (neuron.biasCache) - this.learningRate * deltaValue\r\n            neuron.biasCache = v\r\n        }\r\n\r\n        return value - v\r\n    }\r\n\r\n    // Weights init\r\n    static uniform (size, {limit}) {\r\n        const values = []\r\n\r\n        for (let i=0; i<size; i++) {\r\n            values.push(Math.random()*2*limit-limit)\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static gaussian (size, {mean, stdDeviation}) {\r\n        const values = []\r\n\r\n        // Polar Box Muller\r\n        for (let i=0; i<size; i++) {\r\n            let x1, x2, r\r\n\r\n            do {\r\n                x1 = 2 * Math.random() -1\r\n                x2 = 2 * Math.random() -1\r\n                r = x1**2 + x2**2\r\n            } while (r >= 1 || !r)\r\n\r\n            values.push(mean + (x1 * (Math.sqrt(-2 * Math.log(r) / r))) * stdDeviation)\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static xaviernormal (size, {fanIn, fanOut}) {\r\n        return fanOut || fanOut==0 ? NetMath.gaussian(size, {mean: 0, stdDeviation: Math.sqrt(2/(fanIn+fanOut))})\r\n                                   : NetMath.lecunnormal(size, {fanIn})\r\n    }\r\n\r\n    static xavieruniform (size, {fanIn, fanOut}) {\r\n        return fanOut || fanOut==0 ? NetMath.uniform(size, {limit: Math.sqrt(6/(fanIn+fanOut))})\r\n                                   : NetMath.lecununiform(size, {fanIn})\r\n    }\r\n\r\n    static lecunnormal (size, {fanIn}) {\r\n        return NetMath.gaussian(size, {mean: 0, stdDeviation: Math.sqrt(1/fanIn)})\r\n    }\r\n\r\n    static lecununiform (size, {fanIn}) {\r\n        return NetMath.uniform(size, {limit: Math.sqrt(3/fanIn)})\r\n    }\r\n\r\n    // Pool\r\n    static maxPool (layer, channel) {\r\n\r\n        const activations = NetUtil.getActivations(layer.prevLayer, channel, layer.inMapValuesCount)\r\n\r\n        for (let row=0; row<layer.outMapSize; row++) {\r\n            for (let col=0; col<layer.outMapSize; col++) {\r\n\r\n                const rowStart = row * layer.stride\r\n                const colStart = col * layer.stride\r\n\r\n                // The first value\r\n                let activation = activations[rowStart*layer.prevLayerOutWidth + colStart]\r\n\r\n                for (let filterRow=0; filterRow<layer.size; filterRow++) {\r\n                    for (let filterCol=0; filterCol<layer.size; filterCol++) {\r\n\r\n                        const value = activations[ ((rowStart+filterRow) * layer.prevLayerOutWidth) + (colStart+filterCol) ]\r\n\r\n                        if (value > activation) {\r\n                            activation = value\r\n                            layer.indeces[channel][row][col] = [filterRow, filterCol]\r\n                        }\r\n                    }\r\n                }\r\n\r\n                layer.activations[channel][row][col] = activation\r\n            }\r\n        }\r\n    }\r\n\r\n    // Other\r\n    static softmax (v) {\r\n\r\n        const values = v.slice(0)\r\n        let maxValue = values[0]\r\n\r\n        for (let i=1; i<values.length; i++) {\r\n            if (values[i] > maxValue) {\r\n                maxValue = values[i]\r\n            }\r\n        }\r\n\r\n        // Exponentials\r\n        const exponentials = new Array(values.length)\r\n        let exponentialsSum = 0.0\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            let e = Math.exp(values[i] - maxValue)\r\n            exponentialsSum += e\r\n            exponentials[i] = e\r\n        }\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            exponentials[i] /= exponentialsSum\r\n            values[i] = exponentials[i]\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static sech (value) {\r\n        return (2*Math.exp(-value))/(1+Math.exp(-2*value))\r\n    }\r\n\r\n    static standardDeviation (arr) {\r\n        const avg = arr.reduce((p,c) => p+c) / arr.length\r\n        const diffs = arr.map(v => v - avg).map(v => v**2)\r\n        return Math.sqrt(diffs.reduce((p,c) => p+c) / diffs.length)\r\n    }\r\n\r\n    static maxNorm () {\r\n\r\n        if (this.maxNormTotal > this.maxNorm) {\r\n\r\n            const multiplier = this.maxNorm / (1e-18 + this.maxNormTotal)\r\n\r\n            this.layers.forEach((layer, li) => {\r\n                li && layer.neurons.forEach(neuron => {\r\n                    neuron.weights.forEach((w, wi) => neuron.setWeight(wi, neuron.getWeight(wi) * multiplier))\r\n                })\r\n            })\r\n        }\r\n\r\n        this.maxNormTotal = 0\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.NetMath = NetMath)\r\nexports.NetMath = NetMath\r\n\"use strict\"\r\n\r\nclass NetUtil {\r\n\r\n    static format (value, type=\"string\") {\r\n        switch (true) {\r\n\r\n            case type==\"string\" && typeof value==\"string\":\r\n                value = value.replace(/(_|\\s)/g, \"\").toLowerCase()\r\n                break\r\n\r\n            case type==\"time\" && typeof value==\"number\":\r\n                const date = new Date(value)\r\n                const formatted = []\r\n\r\n                if (value < 1000) {\r\n                    formatted.push(`${date.getMilliseconds()}ms`)\r\n\r\n                } else if (value < 60000) {\r\n                    formatted.push(`${date.getSeconds()}.${date.getMilliseconds()}s`)\r\n\r\n                } else {\r\n\r\n                    if (value >= 3600000) formatted.push(`${date.getHours()}h`)\r\n\r\n                    formatted.push(`${date.getMinutes()}m`)\r\n                    formatted.push(`${date.getSeconds()}s`)\r\n                }\r\n\r\n                value = formatted.join(\" \")\r\n                break\r\n        }\r\n\r\n        return value\r\n    }\r\n\r\n    static shuffle (arr) {\r\n        for (let i=arr.length; i; i--) {\r\n            const j = Math.floor(Math.random() * i)\r\n            const x = arr[i-1]\r\n            arr[i-1] = arr[j]\r\n            arr[j] = x\r\n        }\r\n    }\r\n\r\n    static addZeroPadding (map, zP) {\r\n\r\n        const data = []\r\n\r\n        for (let row=0; row<map.length; row++) {\r\n            data.push(map[row].slice(0))\r\n        }\r\n\r\n        const extraRows = []\r\n\r\n        for (let i=0; i<data.length+2*zP; i++) {\r\n            extraRows.push(0)\r\n        }\r\n\r\n        for (let col=0; col<data.length; col++) {\r\n            for (let i=0; i<zP; i++) {\r\n                data[col].splice(0, 0, 0)\r\n                data[col].splice(data[col].length+1, data[col].length, 0)\r\n            }\r\n        }\r\n\r\n        for (let i=0; i<zP; i++) {\r\n            data.splice(0, 0, extraRows.slice(0))\r\n            data.splice(data.length, data.length-1, extraRows.slice(0))\r\n        }\r\n\r\n        return data\r\n    }\r\n\r\n    static arrayToMap (arr, size) {\r\n        const map = []\r\n\r\n        for (let i=0; i<size; i++) {\r\n            map[i] = []\r\n\r\n            for (let j=0; j<size; j++) {\r\n                map[i][j] = arr[i*size+j]\r\n            }\r\n        }\r\n\r\n        return map\r\n    }\r\n\r\n    static arrayToVolume (arr, channels) {\r\n\r\n        const vol = []\r\n        const size = Math.sqrt(arr.length/channels)\r\n        const mapValues = size**2\r\n\r\n        for (let d=0; d<Math.floor(arr.length/mapValues); d++) {\r\n\r\n            const map = []\r\n\r\n            for (let i=0; i<size; i++) {\r\n                map[i] = []\r\n\r\n                for (let j=0; j<size; j++) {\r\n                    map[i][j] = arr[d*mapValues  + i*size+j]\r\n                }\r\n            }\r\n\r\n            vol[d] = map\r\n        }\r\n\r\n        return vol\r\n    }\r\n\r\n    static convolve ({input, zeroPadding, weights, channels, stride, bias}) {\r\n\r\n        const inputVol = NetUtil.arrayToVolume(input, channels)\r\n        const outputMap = []\r\n\r\n        const paddedLength = inputVol[0].length + zeroPadding*2\r\n        const fSSpread = Math.floor(weights[0].length / 2)\r\n\r\n        // For each input channel,\r\n        for (let di=0; di<channels; di++) {\r\n            inputVol[di] = NetUtil.addZeroPadding(inputVol[di], zeroPadding)\r\n            // For each inputY without ZP\r\n            for (let inputY=fSSpread; inputY<paddedLength-fSSpread; inputY+=stride) {\r\n                outputMap[(inputY-fSSpread)/stride] = outputMap[(inputY-fSSpread)/stride] || []\r\n                // For each inputX without zP\r\n                for (let inputX=fSSpread; inputX<paddedLength-fSSpread; inputX+=stride) {\r\n                    let sum = 0\r\n                    // For each weightsY on input\r\n                    for (let weightsY=0; weightsY<weights[0].length; weightsY++) {\r\n                        // For each weightsX on input\r\n                        for (let weightsX=0; weightsX<weights[0].length; weightsX++) {\r\n                            sum += inputVol[di][inputY+(weightsY-fSSpread)][inputX+(weightsX-fSSpread)] * weights[di][weightsY][weightsX]\r\n                        }\r\n                    }\r\n\r\n                    outputMap[(inputY-fSSpread)/stride][(inputX-fSSpread)/stride] = (outputMap[(inputY-fSSpread)/stride][(inputX-fSSpread)/stride]||0) + sum\r\n                }\r\n            }\r\n        }\r\n\r\n        // Then add bias\r\n        for (let outY=0; outY<outputMap.length; outY++) {\r\n            for (let outX=0; outX<outputMap.length; outX++) {\r\n                outputMap[outY][outX] += bias\r\n            }\r\n        }\r\n\r\n        return outputMap\r\n    }\r\n\r\n    static buildConvErrorMap (nextLayer, errorMap, filterI) {\r\n\r\n        // Cache / convenience\r\n        const zeroPadding = nextLayer.zeroPadding\r\n        const paddedLength = errorMap.length + zeroPadding*2\r\n        const fSSpread = Math.floor(nextLayer.filterSize / 2)\r\n\r\n        // Zero pad and clear the error map, to allow easy convoling\r\n        const paddedRow = []\r\n\r\n        for (let val=0; val<paddedLength; val++) {\r\n            paddedRow.push(0)\r\n        }\r\n\r\n        for (let row=0; row<paddedLength; row++) {\r\n            errorMap[row] = paddedRow.slice(0)\r\n        }\r\n\r\n        // For each channel in filter in the next layer which corresponds to this filter\r\n        for (let nlFilterI=0; nlFilterI<nextLayer.size; nlFilterI++) {\r\n\r\n            const weights = nextLayer.filters[nlFilterI].weights[filterI]\r\n            const errMap = nextLayer.filters[nlFilterI].errorMap\r\n\r\n            // Unconvolve their error map using the weights\r\n            for (let inputY=fSSpread; inputY<paddedLength - fSSpread; inputY+=nextLayer.stride) {\r\n                for (let inputX=fSSpread; inputX<paddedLength - fSSpread; inputX+=nextLayer.stride) {\r\n\r\n                    for (let weightsY=0; weightsY<nextLayer.filterSize; weightsY++) {\r\n                        for (let weightsX=0; weightsX<nextLayer.filterSize; weightsX++) {\r\n                            errorMap[inputY+(weightsY-fSSpread)][inputX+(weightsX-fSSpread)] += weights[weightsY][weightsX]\r\n                                * errMap[(inputY-fSSpread)/nextLayer.stride][(inputX-fSSpread)/nextLayer.stride]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Take out the zero padding. Rows:\r\n        errorMap.splice(0, zeroPadding)\r\n        errorMap.splice(errorMap.length-zeroPadding, errorMap.length)\r\n\r\n        // Columns:\r\n        for (let emYI=0; emYI<errorMap.length; emYI++) {\r\n            errorMap[emYI] = errorMap[emYI].splice(zeroPadding, errorMap[emYI].length - zeroPadding*2)\r\n        }\r\n    }\r\n\r\n    static buildConvDWeights (layer) {\r\n\r\n        const weightsCount = layer.filters[0].weights[0].length\r\n        const fSSpread = Math.floor(weightsCount / 2)\r\n        const channelsCount = layer.filters[0].weights.length\r\n\r\n        // For each filter\r\n        for (let filterI=0; filterI<layer.filters.length; filterI++) {\r\n\r\n            const filter = layer.filters[filterI]\r\n\r\n            // Each channel will take the error map and the corresponding inputMap from the input...\r\n            for (let channelI=0; channelI<channelsCount; channelI++) {\r\n\r\n                const inputValues = NetUtil.getActivations(layer.prevLayer, channelI, layer.inMapValuesCount)\r\n                const inputMap = NetUtil.addZeroPadding(NetUtil.arrayToMap(inputValues, Math.sqrt(layer.inMapValuesCount)), layer.zeroPadding)\r\n\r\n                // ...slide the filter with correct stride across the zero-padded inputMap...\r\n                for (let inputY=fSSpread; inputY<inputMap.length-fSSpread; inputY+=layer.stride) {\r\n                    for (let inputX=fSSpread; inputX<inputMap.length-fSSpread; inputX+=layer.stride) {\r\n\r\n                        const error = filter.errorMap[(inputY-fSSpread)/layer.stride][(inputX-fSSpread)/layer.stride]\r\n\r\n                        // ...and at each location...\r\n                        for (let weightsY=0; weightsY<weightsCount; weightsY++) {\r\n                            for (let weightsX=0; weightsX<weightsCount; weightsX++) {\r\n                                const activation = inputMap[inputY-fSSpread+weightsY][inputX-fSSpread+weightsX]\r\n                                filter.deltaWeights[channelI][weightsY][weightsX] += activation * error\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n            // Increment the deltaBias by the sum of all errors in the filter\r\n            for (let eY=0; eY<filter.errorMap.length; eY++) {\r\n                for (let eX=0; eX<filter.errorMap.length; eX++) {\r\n                    filter.deltaBias += filter.errorMap[eY][eX]\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    static getActivations (layer, mapStartI, mapSize) {\r\n\r\n        const returnArr = []\r\n\r\n        if (arguments.length==1) {\r\n\r\n            if (layer instanceof FCLayer) {\r\n\r\n                for (let ni=0; ni<layer.neurons.length; ni++) {\r\n                    returnArr.push(layer.neurons[ni].activation)\r\n                }\r\n\r\n            } else if (layer instanceof ConvLayer) {\r\n\r\n                for (let fi=0; fi<layer.filters.length; fi++) {\r\n                    for (let rowI=0; rowI<layer.filters[fi].activationMap.length; rowI++) {\r\n                        for (let colI=0; colI<layer.filters[fi].activationMap[rowI].length; colI++) {\r\n                            returnArr.push(layer.filters[fi].activationMap[rowI][colI])\r\n                        }\r\n                    }\r\n                }\r\n\r\n            } else {\r\n\r\n                for (let channel=0; channel<layer.activations.length; channel++) {\r\n                    for (let row=0; row<layer.activations[0].length; row++) {\r\n                        for (let col=0; col<layer.activations[0].length; col++) {\r\n                            returnArr.push(layer.activations[channel][row][col])\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else {\r\n\r\n            if (layer instanceof FCLayer) {\r\n\r\n                for (let i=mapStartI*mapSize; i<(mapStartI+1)*mapSize; i++) {\r\n                    returnArr.push(layer.neurons[i].activation)\r\n                }\r\n\r\n            } else if (layer instanceof ConvLayer) {\r\n\r\n                for (let row=0; row<layer.filters[mapStartI].activationMap.length; row++) {\r\n                    for (let col=0; col<layer.filters[mapStartI].activationMap[row].length; col++) {\r\n                        returnArr.push(layer.filters[mapStartI].activationMap[row][col])\r\n                    }\r\n                }\r\n\r\n            } else {\r\n\r\n                for (let row=0; row<layer.activations[mapStartI].length; row++) {\r\n                    for (let col=0; col<layer.activations[mapStartI].length; col++) {\r\n                        returnArr.push(layer.activations[mapStartI][row][col])\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return returnArr\r\n    }\r\n\r\n    static splitData (data, {training=0.7, validation=0.15, test=0.15}={}) {\r\n\r\n        const split = {\r\n            training: [],\r\n            validation: [],\r\n            test: []\r\n        }\r\n\r\n        // Define here splits, for returning at the end\r\n        for (let i=0; i<data.length; i++) {\r\n            let x = Math.random()\r\n\r\n            if (x > 1-training) {\r\n                split.training.push(data[i])\r\n            } else {\r\n\r\n                if (x<validation) {\r\n                    split.validation.push(data[i])\r\n                } else {\r\n                    split.test.push(data[i])\r\n                }\r\n\r\n            }\r\n        }\r\n\r\n        return split\r\n    }\r\n\r\n    static normalize (data) {\r\n        let minVal = Infinity\r\n        let maxVal = -Infinity\r\n\r\n        for (let i=0; i<data.length; i++) {\r\n            if (data[i] < minVal) {\r\n                minVal = data[i]\r\n            }\r\n            if (data[i] > maxVal) {\r\n                maxVal = data[i]\r\n            }\r\n        }\r\n\r\n        if ((-1*minVal + maxVal) != 0) {\r\n            for (let i=0; i<data.length; i++) {\r\n                data[i] = (data[i] + -1*minVal) / (-1*minVal + maxVal)\r\n            }\r\n        } else {\r\n            for (let i=0; i<data.length; i++) {\r\n                data[i] = 0.5\r\n            }\r\n        }\r\n\r\n        return {minVal, maxVal}\r\n    }\r\n\r\n    static makeConfusionMatrix (originalData) {\r\n        let total = 0\r\n        let totalCorrect = 0\r\n        const data = []\r\n\r\n        for (let r=0; r<originalData.length; r++) {\r\n            const row = []\r\n            for (let c=0; c<originalData[r].length; c++) {\r\n                row.push(originalData[r][c])\r\n            }\r\n            data.push(row)\r\n        }\r\n\r\n\r\n        for (let r=0; r<data.length; r++) {\r\n            for (let c=0; c<data[r].length; c++) {\r\n                total += data[r][c]\r\n            }\r\n        }\r\n\r\n        for (let r=0; r<data.length; r++) {\r\n\r\n            let rowTotal = 0\r\n            totalCorrect += data[r][r]\r\n\r\n            for (let c=0; c<data[r].length; c++) {\r\n                rowTotal += data[r][c]\r\n                data[r][c] = {count: data[r][c], percent: (data[r][c] / total * 100)||0}\r\n            }\r\n\r\n            const correctPercent = data[r][r].count / rowTotal * 100\r\n\r\n            data[r].total = {\r\n                correct: (correctPercent||0),\r\n                wrong: (100 - correctPercent)||0\r\n            }\r\n        }\r\n\r\n        // Collect bottom row percentages\r\n        const bottomRow = []\r\n\r\n        for (let c=0; c<data[0].length; c++) {\r\n\r\n            let columnTotal = 0\r\n\r\n            for (let r=0; r<data.length; r++) {\r\n                columnTotal += data[r][c].count\r\n            }\r\n\r\n            const correctPercent = data[c][c].count / columnTotal * 100\r\n\r\n            bottomRow.push({\r\n                correct: (correctPercent)||0,\r\n                wrong: (100 - correctPercent)||0\r\n            })\r\n        }\r\n\r\n        data.total = bottomRow\r\n\r\n        // Calculate final matrix percentage\r\n        data.total.total = {\r\n            correct: (totalCorrect / total * 100)||0,\r\n            wrong: (100 - (totalCorrect / total * 100))||0\r\n        }\r\n\r\n        return data\r\n    }\r\n\r\n    /* istanbul ignore next */\r\n    static printConfusionMatrix (data) {\r\n        if (typeof window!=\"undefined\") {\r\n\r\n            for (let r=0; r<data.length; r++) {\r\n                for (let c=0; c<data[r].length; c++) {\r\n                    data[r][c] = `${data[r][c].count} (${data[r][c].percent.toFixed(1)}%)`\r\n                }\r\n                data[r].total = `${data[r].total.correct.toFixed(1)}% / ${data[r].total.wrong.toFixed(1)}%`\r\n                data.total[r] = `${data.total[r].correct.toFixed(1)}% / ${data.total[r].wrong.toFixed(1)}%`\r\n            }\r\n\r\n            data.total.total = `${data.total.total.correct.toFixed(1)}% / ${data.total.total.wrong.toFixed(1)}%`\r\n\r\n            console.table(data)\r\n            return\r\n        }\r\n\r\n\r\n        const padNum = (num, percent) => {\r\n            num = percent ? num.toFixed(1) + \"%\" : num.toString()\r\n            const leftPad = Math.max(Math.floor((3*2+1 - num.length) / 2), 0)\r\n            const rightPad = Math.max(3*2+1 - (num.length + leftPad), 0)\r\n            return \" \".repeat(leftPad)+num+\" \".repeat(rightPad)\r\n        }\r\n\r\n        let colourText\r\n        let colourBackground\r\n\r\n        // Bright\r\n        process.stdout.write(\"\\n\\x1b[1m\")\r\n\r\n        for (let r=0; r<data.length; r++) {\r\n\r\n            // Bright white text\r\n            colourText = \"\\x1b[2m\\x1b[37m\"\r\n\r\n            // Count\r\n            for (let c=0; c<data[r].length; c++) {\r\n                colourBackground =  r==c ? \"\\x1b[42m\" : \"\\x1b[41m\"\r\n                process.stdout.write(`${colourText}${colourBackground}\\x1b[1m${padNum(data[r][c].count)}\\x1b[22m`)\r\n            }\r\n\r\n            // Dim green text on white background\r\n            colourText = \"\\x1b[2m\\x1b[32m\"\r\n            colourBackground = \"\\x1b[47m\"\r\n            process.stdout.write(`${colourText}${colourBackground}${padNum(data[r].total.correct, true)}`)\r\n\r\n            // Bright white text\r\n            colourText = \"\\x1b[2m\\x1b[37m\"\r\n            process.stdout.write(`${colourText}\\n`)\r\n\r\n            // Percent\r\n            for (let c=0; c<data[r].length; c++) {\r\n                colourBackground =  r==c ? \"\\x1b[42m\" : \"\\x1b[41m\"\r\n                process.stdout.write(`${colourText}${colourBackground}${padNum(data[r][c].percent, true)}`)\r\n            }\r\n\r\n            // Dim red\r\n            colourText = \"\\x1b[2m\\x1b[31m\"\r\n            colourBackground = \"\\x1b[47m\"\r\n            process.stdout.write(`${colourText}${colourBackground}${padNum(data[r].total.wrong, true)}`)\r\n\r\n            // Bright\r\n            process.stdout.write(\"\\x1b[1m\\x1b[30m\\n\")\r\n        }\r\n\r\n        // Dim green text\r\n        colourText = \"\\x1b[22m\\x1b[32m\"\r\n\r\n        // Bottom row correct percentages\r\n        for (const col of data.total) {\r\n            process.stdout.write(`${colourText}${colourBackground}${padNum(col.correct, true)}`)\r\n        }\r\n        // Total correct percentages\r\n        // Blue background\r\n        colourBackground = \"\\x1b[1m\\x1b[44m\"\r\n        process.stdout.write(`${colourText}${colourBackground}${padNum(data.total.total.correct, true)}\\n`)\r\n\r\n        // Dim red on white background\r\n        colourText = \"\\x1b[22m\\x1b[31m\"\r\n        colourBackground = \"\\x1b[47m\"\r\n\r\n        // Bottom row wrong percentages\r\n        for (const col of data.total) {\r\n            process.stdout.write(`${colourText}${colourBackground}${padNum(col.wrong, true)}`)\r\n        }\r\n\r\n        // Bright red on blue background\r\n        colourText = \"\\x1b[1m\\x1b[31m\"\r\n        colourBackground = \"\\x1b[44m\"\r\n        process.stdout.write(`${colourText}${colourBackground}${padNum(data.total.total.wrong, true)}\\n`)\r\n\r\n        // Reset\r\n        process.stdout.write(\"\\x1b[0m\\n\")\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.NetUtil = NetUtil)\r\nexports.NetUtil = NetUtil\r\n\"use strict\"\r\n\r\nclass Network {\r\n\r\n    constructor ({learningRate, layers=[], updateFn=\"vanillasgd\", activation=\"sigmoid\", cost=\"meansquarederror\", momentum=0.9,\r\n        rmsDecay, rho, lreluSlope, eluAlpha, dropout=1, l2, l1, maxNorm, weightsConfig, channels, conv, pool}={}) {\r\n\r\n        this.state = \"not-defined\"\r\n        this.layers = []\r\n        this.conv = {}\r\n        this.pool = {}\r\n        this.epochs = 0\r\n        this.iterations = 0\r\n        this.validations = 0\r\n        this.dropout = dropout==false ? 1 : dropout\r\n        this.error = 0\r\n        activation = NetUtil.format(activation)\r\n        updateFn = NetUtil.format(updateFn)\r\n        cost = NetUtil.format(cost)\r\n        this.l1 = 0\r\n        this.l2 = 0\r\n\r\n        if (l1) {\r\n            this.l1 = typeof l1==\"boolean\" ? 0.005 : l1\r\n            this.l1Error = 0\r\n        }\r\n\r\n        if (l2) {\r\n            this.l2 = typeof l2==\"boolean\" ? 0.001 : l2\r\n            this.l2Error = 0\r\n        }\r\n\r\n        if (maxNorm) {\r\n            this.maxNorm = typeof maxNorm==\"boolean\" && maxNorm ? 1000 : maxNorm\r\n            this.maxNormTotal = 0\r\n        }\r\n\r\n        if (learningRate)   this.learningRate = learningRate\r\n        if (channels)       this.channels = channels\r\n\r\n        if (conv) {\r\n            if (conv.filterSize!=undefined)     this.conv.filterSize = conv.filterSize\r\n            if (conv.zeroPadding!=undefined)    this.conv.zeroPadding = conv.zeroPadding\r\n            if (conv.stride!=undefined)         this.conv.stride = conv.stride\r\n        }\r\n\r\n        if (pool) {\r\n            if (pool.size)      this.pool.size = pool.size\r\n            if (pool.stride)    this.pool.stride = pool.stride\r\n        }\r\n\r\n        // Activation function / Learning Rate\r\n        switch (updateFn) {\r\n\r\n            case \"rmsprop\":\r\n                this.learningRate = this.learningRate==undefined ? 0.001 : this.learningRate\r\n                break\r\n\r\n            case \"adam\":\r\n                this.learningRate = this.learningRate==undefined ? 0.01 : this.learningRate\r\n                break\r\n\r\n            case \"momentum\":\r\n                this.learningRate = this.learningRate==undefined ? 0.2 : this.learningRate\r\n                this.momentum = momentum\r\n                break\r\n\r\n            case \"adadelta\":\r\n                this.rho = rho==null ? 0.95 : rho\r\n                break\r\n\r\n            default:\r\n\r\n                if (this.learningRate==undefined) {\r\n\r\n                    switch (activation) {\r\n\r\n                        case \"relu\":\r\n                        case \"lrelu\":\r\n                        case \"rrelu\":\r\n                        case \"elu\":\r\n                            this.learningRate = 0.01\r\n                            break\r\n\r\n                        case \"tanh\":\r\n                        case \"lecuntanh\":\r\n                            this.learningRate = 0.001\r\n                            break\r\n\r\n                        default:\r\n                            this.learningRate = 0.2\r\n                    }\r\n                }\r\n        }\r\n\r\n        this.updateFn = [false, null, undefined].includes(updateFn) ? \"vanillasgd\" : updateFn\r\n        this.weightUpdateFn = NetMath[this.updateFn]\r\n        this.activation = typeof activation==\"function\" ? activation : NetMath[activation].bind(this)\r\n        this.activationConfig = activation\r\n        this.cost = typeof cost==\"function\" ? cost : NetMath[cost]\r\n\r\n        if (this.updateFn==\"rmsprop\") {\r\n            this.rmsDecay = rmsDecay==undefined ? 0.99 : rmsDecay\r\n        }\r\n\r\n        this.lreluSlope = lreluSlope==undefined ? -0.0005 : lreluSlope\r\n        this.rreluSlope = Math.random() * 0.001\r\n        this.eluAlpha = eluAlpha==undefined ? 1 : eluAlpha\r\n\r\n        // Weights distributiom\r\n        this.weightsConfig = {distribution: \"xavieruniform\"}\r\n\r\n        if (weightsConfig != undefined && weightsConfig.distribution) {\r\n            this.weightsConfig.distribution = NetUtil.format(weightsConfig.distribution)\r\n        }\r\n\r\n        if (this.weightsConfig.distribution == \"uniform\") {\r\n            this.weightsConfig.limit = weightsConfig && weightsConfig.limit!=undefined ? weightsConfig.limit : 0.1\r\n\r\n        } else if (this.weightsConfig.distribution == \"gaussian\") {\r\n            this.weightsConfig.mean = weightsConfig.mean || 0\r\n            this.weightsConfig.stdDeviation = weightsConfig.stdDeviation || 0.05\r\n        }\r\n\r\n        if (typeof this.weightsConfig.distribution==\"function\") {\r\n            this.weightsInitFn = this.weightsConfig.distribution\r\n        } else {\r\n            this.weightsInitFn = NetMath[this.weightsConfig.distribution]\r\n        }\r\n\r\n        if (layers.length) {\r\n\r\n            switch (true) {\r\n\r\n                case layers.every(item => Number.isInteger(item)):\r\n                    this.layers = layers.map(size => new FCLayer(size))\r\n                    this.state = \"constructed\"\r\n                    this.initLayers()\r\n                    break\r\n\r\n                case layers.every(layer => layer instanceof FCLayer || layer instanceof ConvLayer || layer instanceof PoolLayer):\r\n                    this.state = \"constructed\"\r\n                    this.layers = layers\r\n                    this.initLayers()\r\n                    break\r\n\r\n                default:\r\n                    throw new Error(\"There was an error constructing from the layers given.\")\r\n            }\r\n        }\r\n\r\n        this.collectedErrors = {training: [], validation: [], test: []}\r\n    }\r\n\r\n    initLayers (input, expected) {\r\n\r\n        switch (this.state) {\r\n\r\n            case \"initialised\":\r\n                return\r\n\r\n            case \"not-defined\":\r\n                this.layers[0] = new FCLayer(input)\r\n                this.layers[1] = new FCLayer(Math.ceil(input/expected > 5 ? expected + (Math.abs(input-expected))/4\r\n                                                                          : input + expected))\r\n                this.layers[2] = new FCLayer(Math.ceil(expected))\r\n                break\r\n        }\r\n\r\n        this.layers.forEach(this.joinLayer.bind(this))\r\n\r\n        const outSize = this.layers[this.layers.length-1].size\r\n        this.trainingConfusionMatrix = [...new Array(outSize)].map(r => [...new Array(outSize)].map(v => 0))\r\n        this.testConfusionMatrix = [...new Array(outSize)].map(r => [...new Array(outSize)].map(v => 0))\r\n        this.validationConfusionMatrix = [...new Array(outSize)].map(r => [...new Array(outSize)].map(v => 0))\r\n\r\n        this.state = \"initialised\"\r\n    }\r\n\r\n    joinLayer (layer, layerIndex) {\r\n\r\n        layer.net = this\r\n        layer.activation = layer.activation==undefined ? this.activation : layer.activation\r\n\r\n        layer.weightsConfig = {}\r\n        Object.assign(layer.weightsConfig, this.weightsConfig)\r\n\r\n        if (layerIndex) {\r\n            this.layers[layerIndex-1].assignNext(layer)\r\n            layer.assignPrev(this.layers[layerIndex-1], layerIndex)\r\n\r\n            layer.weightsConfig.fanIn = layer.prevLayer.size\r\n\r\n            if (layerIndex<this.layers.length-1) {\r\n                layer.weightsConfig.fanOut = this.layers[layerIndex+1].size\r\n            }\r\n\r\n            layer.init()\r\n\r\n        } else if (this.layers.length > 1) {\r\n            layer.weightsConfig.fanOut = this.layers[1].size\r\n        }\r\n\r\n        layer.state = \"initialised\"\r\n    }\r\n\r\n    forward (data) {\r\n\r\n        if (this.state!=\"initialised\") {\r\n            throw new Error(\"The network layers have not been initialised.\")\r\n        }\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No data passed to Network.forward()\")\r\n        }\r\n\r\n        // Flatten volume inputs\r\n        if (Array.isArray(data[0])) {\r\n            const flat = []\r\n\r\n            for (let c=0; c<data.length; c++) {\r\n                for (let r=0; r<data[0].length; r++) {\r\n                    for (let v=0; v<data[0].length; v++) {\r\n                        flat.push(data[c][r][v])\r\n                    }\r\n                }\r\n            }\r\n            data = flat\r\n        }\r\n\r\n        if (data.length != this.layers[0].neurons.length) {\r\n            console.warn(\"Input data length did not match input layer neurons count.\")\r\n        }\r\n\r\n        this.layers[0].neurons.forEach((neuron, ni) => neuron.activation = data[ni])\r\n        this.layers.forEach((layer, li) => li && layer.forward())\r\n\r\n        return this.layers[this.layers.length-1].neurons.map(n => n.activation)\r\n    }\r\n\r\n    backward (errors) {\r\n\r\n        if (errors === undefined) {\r\n            throw new Error(\"No data passed to Network.backward()\")\r\n        }\r\n\r\n        if (errors.length != this.layers[this.layers.length-1].neurons.length) {\r\n            console.warn(\"Expected data length did not match output layer neurons count.\", errors)\r\n        }\r\n\r\n        this.layers[this.layers.length-1].backward(errors)\r\n\r\n        for (let layerIndex=this.layers.length-2; layerIndex>0; layerIndex--) {\r\n            this.layers[layerIndex].backward()\r\n        }\r\n    }\r\n\r\n    train (dataSet, {epochs=1, callback, callbackInterval=1, collectErrors, log=true, miniBatchSize=1, shuffle=false, validation}={}) {\r\n\r\n        this.miniBatchSize = typeof miniBatchSize==\"boolean\" && miniBatchSize ? dataSet[0].expected.length : miniBatchSize\r\n        this.validation = validation\r\n\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (shuffle) {\r\n                NetUtil.shuffle(dataSet)\r\n            }\r\n\r\n            if (log) {\r\n                console.log(`Training started. Epochs: ${epochs} Batch Size: ${this.miniBatchSize}`)\r\n            }\r\n\r\n            if (dataSet === undefined || dataSet === null) {\r\n                return void reject(\"No data provided\")\r\n            }\r\n\r\n            if (this.state != \"initialised\") {\r\n                this.initLayers.bind(this, dataSet[0].input.length, dataSet[0].expected.length)()\r\n            }\r\n\r\n            this.layers.forEach(layer => layer.state = \"training\")\r\n\r\n            if (this.validation) {\r\n                this.validation.interval = this.validation.interval || dataSet.length // Default to 1 epoch\r\n\r\n                if (this.validation.earlyStopping) {\r\n                    switch (this.validation.earlyStopping.type) {\r\n                        case \"threshold\":\r\n                            this.validation.earlyStopping.threshold = this.validation.earlyStopping.threshold || 0.01\r\n                            break\r\n                        case \"patience\":\r\n                            this.validation.earlyStopping.patienceCounter = 0\r\n                            this.validation.earlyStopping.bestError = Infinity\r\n                            this.validation.earlyStopping.patience = this.validation.earlyStopping.patience || 20\r\n                            break\r\n                        case \"divergence\":\r\n                            this.validation.earlyStopping.percent = this.validation.earlyStopping.percent || 30\r\n                            this.validation.earlyStopping.bestError = Infinity\r\n                            break\r\n                    }\r\n                }\r\n            }\r\n\r\n            let iterationIndex = 0\r\n            let epochsCounter = 0\r\n            let elapsed\r\n            const startTime = Date.now()\r\n\r\n            const logAndResolve = () => {\r\n                this.layers.forEach(layer => layer.state = \"initialised\")\r\n\r\n                if (this.validation && this.validation.earlyStopping && (this.validation.earlyStopping.type == \"patience\" || this.validation.earlyStopping.type == \"divergence\")) {\r\n                    for (let l=1; l<this.layers.length; l++) {\r\n                        this.layers[l].restoreValidation()\r\n                    }\r\n                }\r\n\r\n                if (log) {\r\n                    console.log(`Training finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/iterationIndex, \"time\")}`)\r\n                }\r\n                resolve()\r\n            }\r\n\r\n            const doEpoch = () => {\r\n                this.epochs++\r\n                this.error = 0\r\n                this.validationError = 0\r\n                iterationIndex = 0\r\n\r\n                if (this.l2Error!=undefined) this.l2Error = 0\r\n                if (this.l1Error!=undefined) this.l1Error = 0\r\n\r\n                doIteration()\r\n            }\r\n\r\n            const doIteration = async () => {\r\n\r\n                if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || !dataSet[iterationIndex].hasOwnProperty(\"expected\")) {\r\n                    return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected'\")\r\n                }\r\n\r\n                let trainingError\r\n                let validationError\r\n\r\n                const input = dataSet[iterationIndex].input\r\n                const output = this.forward(input)\r\n                const target = dataSet[iterationIndex].expected\r\n\r\n                let classification = -Infinity\r\n                const errors = []\r\n                for (let n=0; n<output.length; n++) {\r\n                    errors[n] = (target[n]==1 ? 1 : 0) - output[n]\r\n                    classification = Math.max(classification, output[n])\r\n                }\r\n\r\n                if (this.trainingConfusionMatrix[target.indexOf(1)]) {\r\n                    this.trainingConfusionMatrix[target.indexOf(1)][output.indexOf(classification)]++\r\n                }\r\n\r\n                // Do validation\r\n                if (this.validation && iterationIndex && iterationIndex%this.validation.interval==0) {\r\n\r\n                    validationError = await this.validate(this.validation.data)\r\n\r\n                    if (this.validation.earlyStopping && this.checkEarlyStopping(errors)) {\r\n                        log && console.log(\"Stopping early\")\r\n                        return logAndResolve()\r\n                    }\r\n                }\r\n\r\n                this.backward(errors)\r\n\r\n                if (++iterationIndex%this.miniBatchSize==0) {\r\n                    this.applyDeltaWeights()\r\n                    this.resetDeltaWeights()\r\n                } else if (iterationIndex >= dataSet.length) {\r\n                    this.applyDeltaWeights()\r\n                }\r\n\r\n                trainingError = this.cost(target, output)\r\n                this.error += trainingError\r\n                this.iterations++\r\n\r\n                elapsed = Date.now() - startTime\r\n\r\n                if (collectErrors) {\r\n                    this.collectedErrors.training.push(trainingError)\r\n\r\n                    if (validationError) {\r\n                        this.collectedErrors.validation.push(validationError)\r\n                    }\r\n                }\r\n\r\n                if ((iterationIndex%callbackInterval == 0 || validationError) && typeof callback==\"function\") {\r\n                    callback({\r\n                        iterations: this.iterations,\r\n                        validations: this.validations,\r\n                        validationError, trainingError,\r\n                        elapsed, input\r\n                    })\r\n                }\r\n\r\n                if (iterationIndex < dataSet.length) {\r\n\r\n                    if (iterationIndex%callbackInterval == 0) {\r\n                        setTimeout(doIteration.bind(this), 0)\r\n                    } else {\r\n                        doIteration()\r\n                    }\r\n\r\n                } else {\r\n                    epochsCounter++\r\n\r\n                    if (log) {\r\n                        let text = `Epoch: ${this.epochs}\\nTraining Error: ${this.error/iterationIndex}`\r\n\r\n                        if (validation) {\r\n                            text += `\\nValidation Error: ${this.validationError}`\r\n                        }\r\n\r\n                        if (this.l2Error!=undefined) {\r\n                            text += `\\nL2 Error: ${this.l2Error/iterationIndex}`\r\n                        }\r\n\r\n                        text += `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/epochsCounter, \"time\")}`\r\n                        console.log(text)\r\n                    }\r\n\r\n                    if (epochsCounter < epochs) {\r\n                        doEpoch()\r\n                    } else {\r\n                        logAndResolve()\r\n                    }\r\n                }\r\n            }\r\n\r\n            this.resetDeltaWeights()\r\n            doEpoch()\r\n        })\r\n    }\r\n\r\n    validate (data) {\r\n        return new Promise((resolve, reject) => {\r\n            let validationIndex = 0\r\n            let totalValidationErrors = 0\r\n\r\n            const validateItem = (item) => {\r\n\r\n                const output = this.forward(data[validationIndex].input)\r\n                const target = data[validationIndex].expected\r\n\r\n                let classification = -Infinity\r\n                for (let i=0; i<output.length; i++) {\r\n                    classification = Math.max(classification, output[i])\r\n                }\r\n\r\n                if (this.validationConfusionMatrix[target.indexOf(1)]) {\r\n                    this.validationConfusionMatrix[target.indexOf(1)][output.indexOf(classification)]++\r\n                }\r\n\r\n                this.validations++\r\n                totalValidationErrors += this.cost(target, output)\r\n                // maybe do this only once, as there's no callback anyway\r\n                this.validationError = totalValidationErrors / (validationIndex+1)\r\n\r\n                if (++validationIndex<data.length) {\r\n                    setTimeout(() => validateItem(validationIndex), 0)\r\n                } else {\r\n                    this.lastValidationError = totalValidationErrors / data.length\r\n                    resolve(totalValidationErrors / data.length)\r\n                }\r\n            }\r\n            validateItem(validationIndex)\r\n        })\r\n    }\r\n\r\n    checkEarlyStopping (errors) {\r\n\r\n        let stop = false\r\n\r\n        switch (this.validation.earlyStopping.type) {\r\n            case \"threshold\":\r\n                stop = this.lastValidationError <= this.validation.earlyStopping.threshold\r\n\r\n                // Do the last backward pass\r\n                if (stop) {\r\n                    this.backward(errors)\r\n                    this.applyDeltaWeights()\r\n                }\r\n\r\n                return stop\r\n\r\n            case \"patience\":\r\n                if (this.lastValidationError < this.validation.earlyStopping.bestError) {\r\n                    this.validation.earlyStopping.patienceCounter = 0\r\n                    this.validation.earlyStopping.bestError = this.lastValidationError\r\n\r\n                    for (let l=1; l<this.layers.length; l++) {\r\n                        this.layers[l].backUpValidation()\r\n                    }\r\n\r\n                } else {\r\n                    this.validation.earlyStopping.patienceCounter++\r\n                    stop = this.validation.earlyStopping.patienceCounter>=this.validation.earlyStopping.patience\r\n                }\r\n                return stop\r\n\r\n            case \"divergence\":\r\n                if (this.lastValidationError < this.validation.earlyStopping.bestError) {\r\n                    this.validation.earlyStopping.bestError = this.lastValidationError\r\n\r\n                    for (let l=1; l<this.layers.length; l++) {\r\n                        this.layers[l].backUpValidation()\r\n                    }\r\n                } else {\r\n                    stop = this.lastValidationError / this.validation.earlyStopping.bestError >= (1+this.validation.earlyStopping.percent/100)\r\n                }\r\n\r\n                return stop\r\n        }\r\n    }\r\n\r\n    test (testSet, {log=true, callback, collectErrors}={}) {\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (testSet === undefined || testSet === null) {\r\n                reject(\"No data provided\")\r\n            }\r\n\r\n            if (log) {\r\n                console.log(\"Testing started\")\r\n            }\r\n\r\n            let totalError = 0\r\n            let iterationIndex = 0\r\n            const startTime = Date.now()\r\n\r\n            const testInput = () => {\r\n\r\n                const input = testSet[iterationIndex].input\r\n                const output = this.forward(input)\r\n                const target = testSet[iterationIndex].expected\r\n                const elapsed = Date.now() - startTime\r\n\r\n                let classification = -Infinity\r\n                for (let i=0; i<output.length; i++) {\r\n                    classification = Math.max(classification, output[i])\r\n                }\r\n\r\n                if (this.testConfusionMatrix[target.indexOf(1)]) {\r\n                    this.testConfusionMatrix[target.indexOf(1)][output.indexOf(classification)]++\r\n                }\r\n\r\n                const iterationError = this.cost(target, output)\r\n                totalError += iterationError\r\n                iterationIndex++\r\n\r\n                if (collectErrors) {\r\n                    this.collectedErrors.test.push(iterationError)\r\n                }\r\n\r\n                if (typeof callback==\"function\") {\r\n                    callback({\r\n                        iterations: iterationIndex,\r\n                        error: iterationError,\r\n                        elapsed, input\r\n                    })\r\n                }\r\n\r\n                if (iterationIndex < testSet.length) {\r\n                    setTimeout(testInput.bind(this), 0)\r\n\r\n                } else {\r\n\r\n                    if (log) {\r\n                        console.log(`Testing finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/iterationIndex, \"time\")}`)\r\n                    }\r\n\r\n                    resolve(totalError/testSet.length)\r\n                }\r\n            }\r\n            testInput()\r\n        })\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        this.layers.forEach((layer, li) => li && layer.resetDeltaWeights())\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n\r\n        this.layers.forEach((layer, li) => li && layer.applyDeltaWeights())\r\n\r\n        if (this.maxNorm!=undefined) {\r\n            this.maxNormTotal = Math.sqrt(this.maxNormTotal)\r\n            NetMath.maxNorm.bind(this)()\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            layers: this.layers.map(layer => layer.toJSON())\r\n        }\r\n    }\r\n\r\n    fromJSON (data) {\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No JSON data given to import.\")\r\n        }\r\n\r\n        if (data.layers.length != this.layers.length) {\r\n            throw new Error(`Mismatched layers (${data.layers.length} layers in import data, but ${this.layers.length} configured)`)\r\n        }\r\n\r\n        this.resetDeltaWeights()\r\n        this.layers.forEach((layer, li) => li && layer.fromJSON(data.layers[li], li))\r\n    }\r\n\r\n    toIMG (IMGArrays, opts={}) {\r\n\r\n        if (!IMGArrays) {\r\n            throw new Error(\"The IMGArrays library must be provided. See the documentation for instructions.\")\r\n        }\r\n\r\n        const data = []\r\n\r\n        for (let l=1; l<this.layers.length; l++) {\r\n\r\n            const layerData = this.layers[l].toIMG()\r\n            for (let v=0; v<layerData.length; v++) {\r\n                data.push(layerData[v])\r\n            }\r\n        }\r\n\r\n        return IMGArrays.toIMG(data, opts)\r\n    }\r\n\r\n    fromIMG (rawData, IMGArrays, opts={}) {\r\n\r\n        if (!IMGArrays) {\r\n            throw new Error(\"The IMGArrays library must be provided. See the documentation for instructions.\")\r\n        }\r\n\r\n        let valI = 0\r\n        const data = IMGArrays.fromIMG(rawData, opts)\r\n\r\n        for (let l=1; l<this.layers.length; l++) {\r\n\r\n            const dataCount = this.layers[l].getDataSize()\r\n            this.layers[l].fromIMG(data.splice(0, dataCount))\r\n        }\r\n    }\r\n\r\n    printConfusionMatrix (type) {\r\n        if (type) {\r\n            NetUtil.printConfusionMatrix(NetUtil.makeConfusionMatrix(this[`${type}ConfusionMatrix`]))\r\n        } else {\r\n            // Total all data\r\n            const data = []\r\n\r\n            for (let r=0; r<this.trainingConfusionMatrix.length; r++) {\r\n                const row = []\r\n                for (let c=0; c<this.trainingConfusionMatrix.length; c++) {\r\n                    row.push(this.trainingConfusionMatrix[r][c] + this.testConfusionMatrix[r][c] + this.validationConfusionMatrix[r][c])\r\n                }\r\n                data.push(row)\r\n            }\r\n            NetUtil.printConfusionMatrix(NetUtil.makeConfusionMatrix(data))\r\n        }\r\n    }\r\n\r\n    static get version () {\r\n        return \"3.3.4\"\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.Network = Network)\r\nexports.Network = Network\r\n\"use strict\"\r\n\r\nclass Neuron {\r\n\r\n    constructor () {}\r\n\r\n    init ({updateFn, activation, eluAlpha}={}) {\r\n\r\n        const size = this.weights.length\r\n        this.deltaWeights = this.weights.map(v => 0)\r\n\r\n        switch (updateFn) {\r\n\r\n            case \"gain\":\r\n                this.biasGain = 1\r\n                this.weightGains = [...new Array(size)].map(v => 1)\r\n                this.getWeightGain = i => this.weightGains[i]\r\n                this.setWeightGain = (i,v) => this.weightGains[i] = v\r\n                break\r\n\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n            case \"momentum\":\r\n                this.biasCache = 0\r\n                this.weightsCache = [...new Array(size)].map(v => 0)\r\n                this.getWeightsCache = i => this.weightsCache[i]\r\n                this.setWeightsCache = (i,v) => this.weightsCache[i] = v\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    this.adadeltaBiasCache = 0\r\n                    this.adadeltaCache = [...new Array(size)].map(v => 0)\r\n                    this.getAdadeltaCache = i => this.adadeltaCache[i]\r\n                    this.setAdadeltaCache = (i,v) => this.adadeltaCache[i] = v\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                this.m = 0\r\n                this.v = 0\r\n                break\r\n        }\r\n\r\n        if (activation==\"rrelu\") {\r\n            this.rreluSlope = Math.random() * 0.001\r\n\r\n        } else if (activation==\"elu\") {\r\n            this.eluAlpha = eluAlpha\r\n        }\r\n    }\r\n\r\n    getWeight (i) {\r\n        return this.weights[i]\r\n    }\r\n\r\n    setWeight (i, v) {\r\n        this.weights[i] = v\r\n    }\r\n\r\n    getDeltaWeight (i) {\r\n        return this.deltaWeights[i]\r\n    }\r\n\r\n    setDeltaWeight (i, v) {\r\n        this.deltaWeights[i] = v\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.Neuron = Neuron)\r\nexports.Neuron = Neuron\r\n\"use strict\"\r\n\r\nclass OutputLayer extends FCLayer {\r\n\r\n    constructor (size, {activation, softmax}={}) {\r\n\r\n        super(size, {activation})\r\n\r\n        if (softmax) {\r\n            this.softmax = true\r\n        }\r\n    }\r\n\r\n    forward () {\r\n\r\n        super.forward()\r\n\r\n        if (this.softmax) {\r\n\r\n            const softmax = NetMath.softmax(this.neurons.map(n => n.activation))\r\n\r\n            for (let s=0; s<softmax.length; s++) {\r\n                this.neurons[s].activation = softmax[s]\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.OutputLayer = OutputLayer)\r\nexports.OutputLayer = OutputLayer\r\n\r\n\"use strict\"\r\n\r\nclass PoolLayer {\r\n\r\n    constructor (size, {stride, activation}={}) {\r\n\r\n        if (size)   this.size = size\r\n        if (stride) this.stride = stride\r\n\r\n        if (activation!=undefined && activation!=false) {\r\n            this.activation = typeof activation==\"function\" ? activation : NetMath[NetUtil.format(activation)].bind(this)\r\n        } else {\r\n            this.activation = false\r\n        }\r\n    }\r\n\r\n    init () {}\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n\r\n        this.prevLayer = layer\r\n        this.size = this.size || this.net.pool.size || 2\r\n        this.stride = this.stride || this.net.pool.stride || this.size\r\n        this.layerIndex = layerIndex\r\n\r\n        let prevLayerOutWidth = layer.outMapSize\r\n\r\n        switch (layer.constructor.name) {\r\n\r\n            case \"FCLayer\":\r\n                this.channels = this.net.channels\r\n                prevLayerOutWidth = Math.max(Math.floor(Math.sqrt(layer.size/this.channels)), 1)\r\n                break\r\n\r\n            case \"ConvLayer\":\r\n                this.channels = layer.size\r\n                break\r\n\r\n            case \"PoolLayer\":\r\n                this.channels = layer.channels\r\n                break\r\n        }\r\n\r\n        this.prevLayerOutWidth = prevLayerOutWidth\r\n        this.outMapSize = (prevLayerOutWidth - this.size) / this.stride + 1\r\n        this.inMapValuesCount = prevLayerOutWidth ** 2\r\n\r\n        if (this.outMapSize%1 != 0) {\r\n            throw new Error(`Misconfigured hyperparameters. Activation volume dimensions would be ${this.outMapSize} in pool layer at index ${layerIndex}`)\r\n        }\r\n\r\n        this.activations = [...new Array(this.channels)].map(channel => {\r\n            return [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n        })\r\n        this.errors = [...new Array(this.channels)].map(channel => {\r\n            return [...new Array(prevLayerOutWidth)].map(row => [...new Array(prevLayerOutWidth)].map(v => 0))\r\n        })\r\n        this.indeces = this.activations.map(channel => channel.map(row => row.map(v => [0,0])))\r\n    }\r\n\r\n    forward () {\r\n        for (let channel=0; channel<this.channels; channel++) {\r\n\r\n            NetMath.maxPool(this, channel)\r\n\r\n            // Apply activations\r\n            if (this.activation) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n                        this.activations[channel][row][col] = this.activation(this.activations[channel][row][col], false, this.net)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    backward () {\r\n\r\n        // Clear the existing error values, first\r\n        for (let channel=0; channel<this.channels; channel++) {\r\n            for (let row=0; row<this.errors[0].length; row++) {\r\n                for (let col=0; col<this.errors[0].length; col++) {\r\n                    this.errors[channel][row][col] = 0\r\n                }\r\n            }\r\n        }\r\n\r\n        if (this.nextLayer instanceof FCLayer) {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n                        const weightIndex = channel * this.outMapSize**2 + row * this.outMapSize + col\r\n\r\n                        for (let neuron=0; neuron<this.nextLayer.neurons.length; neuron++) {\r\n                            this.errors[channel][rowI][colI] += this.nextLayer.neurons[neuron].error\r\n                                                                * this.nextLayer.neurons[neuron].weights[weightIndex]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else if (this.nextLayer instanceof ConvLayer) {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n\r\n                const errs = []\r\n\r\n                for (let col=0; col<this.outMapSize; col++) {\r\n                    errs[col] = 0\r\n                }\r\n\r\n                // Convolve on the error map\r\n                NetUtil.buildConvErrorMap(this.nextLayer, errs, channel)\r\n\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] += errs[row][col]\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] += this.nextLayer.errors[channel][row][col]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Apply derivatives\r\n        if (this.activation) {\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n\r\n                for (let row=0; row<this.indeces[channel].length; row++) {\r\n                    for (let col=0; col<this.indeces[channel].length; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] *= this.activation(this.errors[channel][rowI][colI], true, this.net)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    resetDeltaWeights () {}\r\n\r\n    applyDeltaWeights () {}\r\n\r\n    backUpValidation () {}\r\n\r\n    restoreValidation () {}\r\n\r\n    toJSON () {return {}}\r\n\r\n    fromJSON () {}\r\n\r\n    getDataSize () {return 0}\r\n\r\n    toIMG () {return []}\r\n\r\n    fromIMG () {}\r\n}\r\n\r\n/* istanbul ignore next */\r\ntypeof window!=\"undefined\" && (window.PoolLayer = PoolLayer)\r\nexports.PoolLayer = PoolLayer\n//# sourceMappingURL=jsNetJS.concat.js.map"]}