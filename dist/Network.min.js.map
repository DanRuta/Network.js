{"version":3,"sources":["Network.min.js"],"names":["_toConsumableArray","arr","Array","isArray","i","arr2","length","from","_classCallCheck","instance","Constructor","TypeError","_createClass","defineProperties","target","props","descriptor","enumerable","configurable","writable","Object","defineProperty","key","protoProps","staticProps","prototype","FCLayer","size","importedData","this","neurons","concat","map","n","ni","Neuron","undefined","state","value","layer","nextLayer","_this","prevLayer","forEach","neuron","imported","weights","net","weightsInitFn","weightsConfig","bias","Math","random","init","adaptiveLR","activationConfig","eluAlpha","data","_this2","dropped","dropout","activation","sum","pNeuron","pni","expected","_this3","error","deltaBias","derivative","reduce","p","c","weight","wi","deltaWeights","l2","l1","miniBatchSize","dw","_this4","dwi","l2Error","pow","l1Error","abs","weightUpdateFn","bind","maxNorm","maxNormTotal","Layer","window","exports","NetMath","prime","val","exp","max","lreluSlope","rreluSlope","sech","tanh","elu","output","vi","log","calculated","desired","index","prev","curr","deltaValue","learningRate","weightI","newVal","biasGain","getWeightGain","setWeightGain","min","setWeightsCache","biasCache","sqrt","getWeightsCache","rmsDecay","m","mt","iterations","v","vt","rho","getAdadeltaCache","setAdadeltaCache","_newVal","adadeltaBiasCache","_ref","limit","_ref2","mean","stdDeviation","x1","x2","r","_ref3","fanIn","fanOut","gaussian","lecunnormal","_ref4","uniform","lecununiform","_ref5","_ref6","values","total","avg","diffs","multiplier","layers","li","w","setWeight","getWeight","NetUtil","type","arguments","replace","toLowerCase","date","Date","formatted","push","getMilliseconds","getHours","getMinutes","getSeconds","join","j","floor","x","zP","extraColumns","row","extraRows","slice","square","l","ri","_ri","_vi","fS","sumMap","_l","t","Network","_ref7","_ref7$layers","_ref7$adaptiveLR","_ref7$activation","_ref7$cost","cost","_ref7$dropout","_ref7$l","_ref7$l2","epochs","format","includes","distribution","every","item","Number","isInteger","initLayers","definedLayers","Error","input","_this5","hidden","round","ceil","joinLayer","layerIndex","assign","assignNext","assignPrev","console","warn","forward","backward","dataSet","_this6","_ref8","_ref8$epochs","callback","_ref8$log","_ref8$miniBatchSize","_ref8$shuffle","shuffle","Promise","resolve","reject","iterationIndex","epochsCounter","startTime","now","doEpoch","doIteration","hasOwnProperty","applyDeltaWeights","resetDeltaWeights","iterationError","elapsed","setTimeout","testSet","_this7","_ref9","_ref9$log","totalError","testInput","_this8","_ref10","weightGains","weightsCache","adadeltaCache"],"mappings":"AAAA,aAIA,SAASA,mBAAmBC,GAAO,GAAIC,MAAMC,QAAQF,GAAM,CAAE,IAAK,IAAIG,EAAI,EAAGC,EAAOH,MAAMD,EAAIK,QAASF,EAAIH,EAAIK,OAAQF,IAAOC,EAAKD,GAAKH,EAAIG,GAAM,OAAOC,EAAe,OAAOH,MAAMK,KAAKN,GAE1L,SAASO,gBAAgBC,EAAUC,GAAe,KAAMD,aAAoBC,GAAgB,MAAM,IAAIC,UAAU,qCAJhH,IAAIC,aAAe,WAAc,SAASC,EAAiBC,EAAQC,GAAS,IAAK,IAAIX,EAAI,EAAGA,EAAIW,EAAMT,OAAQF,IAAK,CAAE,IAAIY,EAAaD,EAAMX,GAAIY,EAAWC,WAAaD,EAAWC,aAAc,EAAOD,EAAWE,cAAe,EAAU,UAAWF,IAAYA,EAAWG,UAAW,GAAMC,OAAOC,eAAeP,EAAQE,EAAWM,IAAKN,IAAiB,OAAO,SAAUN,EAAaa,EAAYC,GAAiJ,OAA9HD,GAAYV,EAAiBH,EAAYe,UAAWF,GAAiBC,GAAaX,EAAiBH,EAAac,GAAqBd,MAM5hBgB,QAAU,WACV,SAASA,EAAQC,EAAMC,GACnBpB,gBAAgBqB,KAAMH,GAEtBG,KAAKF,KAAOA,EACZE,KAAKC,WAAaC,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUC,EAAGC,GAC3E,OAAO,IAAIC,OAAOP,EAAeA,EAAaM,QAAME,KAExDP,KAAKQ,MAAQ,kBA2GjB,OAxGAzB,aAAac,IACTJ,IAAK,aACLgB,MAAO,SAAoBC,GACvBV,KAAKW,UAAYD,KAGrBjB,IAAK,aACLgB,MAAO,SAAoBC,GACvB,IAAIE,EAAQZ,KAEZA,KAAKa,UAAYH,EACjBV,KAAKC,QAAQa,QAAQ,SAAUC,GAEtBA,EAAOC,WACRD,EAAOE,QAAUL,EAAMM,IAAIC,cAAcT,EAAMZ,KAAMc,EAAMQ,eAC3DL,EAAOM,KAAuB,GAAhBC,KAAKC,SAAiB,IAGxCR,EAAOS,KAAKd,EAAMZ,MACd2B,WAAYb,EAAMM,IAAIO,WACtBC,iBAAkBd,EAAMM,IAAIQ,iBAC5BC,SAAUf,EAAMM,IAAIS,aAG5B3B,KAAKQ,MAAQ,iBAGjBf,IAAK,UACLgB,MAAO,SAAiBmB,GACpB,IAAIC,EAAS7B,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAEf,YAAhBwB,EAAOrB,QAAwBO,EAAOe,QAAUR,KAAKC,SAAWM,EAAOX,IAAIa,SAC3EhB,EAAOiB,WAAa,GAEpBjB,EAAOkB,IAAMlB,EAAOM,KACpBQ,EAAOhB,UAAUZ,QAAQa,QAAQ,SAAUoB,EAASC,GAChD,OAAOpB,EAAOkB,KAAOC,EAAQF,WAAajB,EAAOE,QAAQkB,KAE7DpB,EAAOiB,WAAaH,EAAOG,WAAWjB,EAAOkB,KAAK,EAAOlB,IAAgC,EAArBc,EAAOX,IAAIa,eAK3FtC,IAAK,WACLgB,MAAO,SAAkB2B,GACrB,IAAIC,EAASrC,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAE/BU,EAAOe,SACPf,EAAOuB,MAAQ,EACfvB,EAAOwB,UAAY,SAEK,IAAbH,EACPrB,EAAOuB,MAAQF,EAAS/B,GAAMU,EAAOiB,YAErCjB,EAAOyB,WAAaH,EAAOL,WAAWjB,EAAOkB,KAAK,EAAMlB,GACxDA,EAAOuB,MAAQvB,EAAOyB,WAAaH,EAAO1B,UAAUV,QAAQE,IAAI,SAAUC,GACtE,OAAOA,EAAEkC,OAAyB,EAAhBlC,EAAEa,QAAQZ,MAC7BoC,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,IAGP5B,EAAOE,QAAQH,QAAQ,SAAU8B,EAAQC,GACrC9B,EAAO+B,aAAaD,IAAO9B,EAAOuB,MAAQD,EAAOxB,UAAUZ,QAAQ4C,GAAIb,YAAc,IAAMK,EAAOnB,IAAI6B,IAAM,IAAMV,EAAOnB,IAAI8B,IAAM,IAAMX,EAAOnB,IAAI+B,cAAgBlC,EAAO+B,aAAaD,MAG5L9B,EAAOwB,UAAYxB,EAAOuB,YAKtC7C,IAAK,oBACLgB,MAAO,WACHT,KAAKC,QAAQa,QAAQ,SAAUC,GAC3B,OAAOA,EAAO+B,aAAe/B,EAAOE,QAAQd,IAAI,SAAU+C,GACtD,OAAO,SAKnBzD,IAAK,oBACLgB,MAAO,WACH,IAAI0C,EAASnD,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,GAC3BA,EAAO+B,aAAahC,QAAQ,SAAUoC,EAAIE,QAEjB7C,GAAjB4C,EAAOjC,IAAI6B,KAAiBI,EAAOjC,IAAImC,SAAW,GAAMF,EAAOjC,IAAI6B,GAAKzB,KAAKgC,IAAIvC,EAAOE,QAAQmC,GAAM,SACrF7C,GAAjB4C,EAAOjC,IAAI8B,KAAiBG,EAAOjC,IAAIqC,SAAWJ,EAAOjC,IAAI8B,GAAK1B,KAAKkC,IAAIzC,EAAOE,QAAQmC,KAE9FrC,EAAOE,QAAQmC,GAAOD,EAAOjC,IAAIuC,eAAeC,KAAKP,EAAOjC,IAAKH,EAAOE,QAAQmC,GAAMF,EAAInC,EAAQqC,UAExE7C,GAAtB4C,EAAOjC,IAAIyC,UAAsBR,EAAOjC,IAAI0C,cAAgBtC,KAAKgC,IAAIvC,EAAOE,QAAQmC,GAAM,MAGlGrC,EAAOM,KAAO8B,EAAOjC,IAAIuC,eAAeC,KAAKP,EAAOjC,IAAKH,EAAOM,KAAMN,EAAOwB,UAAWxB,WAK7FlB,KAGPgE,MAAQhE,QAEK,oBAAViE,SAA0BC,QAAQlE,QAAUkE,QAAQF,MAAQhE,SAGnE,IAAImE,QAAU,WACV,SAASA,IACLrF,gBAAgBqB,KAAMgE,GAyQ1B,OAtQAjF,aAAaiF,EAAS,OAClBvE,IAAK,UAILgB,MAAO,SAAiBA,EAAOwD,GAC3B,IAAIC,EAAM,GAAK,EAAI5C,KAAK6C,KAAK1D,IAC7B,OAAOwD,EAAQC,GAAO,EAAIA,GAAOA,KAGrCzE,IAAK,OACLgB,MAAO,SAAcA,EAAOwD,GACxB,IAAIE,EAAM7C,KAAK6C,IAAI,EAAI1D,GACvB,OAAOwD,EAAQ,EAAI3C,KAAKgC,IAAIhC,KAAK6C,IAAI1D,GAASa,KAAK6C,KAAK1D,GAAQ,IAAM,OAAS0D,EAAM,IAAMA,EAAM,IAAM,SAG3G1E,IAAK,OACLgB,MAAO,SAAcA,EAAOwD,GACxB,OAAOA,EAAQxD,EAAQ,EAAI,EAAI,EAAIa,KAAK8C,IAAI3D,EAAO,MAGvDhB,IAAK,QACLgB,MAAO,SAAeA,EAAOwD,GACzB,OAAOA,EAAQxD,EAAQ,EAAI,EAAIT,KAAKqE,WAAa/C,KAAK8C,IAAIpE,KAAKqE,WAAa/C,KAAKkC,IAAI/C,GAAQA,MAGjGhB,IAAK,QACLgB,MAAO,SAAeA,EAAOwD,EAAOlD,GAChC,OAAOkD,EAAQxD,EAAQ,EAAI,EAAIM,EAAOuD,WAAahD,KAAK8C,IAAIrD,EAAOuD,WAAY7D,MAGnFhB,IAAK,YACLgB,MAAO,SAAmBA,EAAOwD,GAC7B,OAAOA,EAAQ,QAAU3C,KAAKgC,IAAIU,EAAQO,KAAK,EAAI,EAAI9D,GAAQ,GAAK,OAASuD,EAAQQ,KAAK,EAAI,EAAI/D,MAGtGhB,IAAK,MACLgB,MAAO,SAAaA,EAAOwD,EAAOlD,GAC9B,OAAOkD,EAAQxD,GAAS,EAAI,EAAIuD,EAAQS,IAAIhE,GAAO,EAAOM,GAAUA,EAAOY,SAAWlB,GAAS,EAAIA,EAAQM,EAAOY,UAAYL,KAAK6C,IAAI1D,GAAS,MAMpJhB,IAAK,eACLgB,MAAO,SAAsBxB,EAAQyF,GACjC,OAAOA,EAAOvE,IAAI,SAAUM,EAAOkE,GAC/B,OAAO1F,EAAO0F,GAAMrD,KAAKsD,IAAInE,EAAQ,QAAU,EAAIxB,EAAO0F,IAAOrD,KAAKsD,IAAI,EAAI,MAAQnE,KACvFgC,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,MAGPlD,IAAK,mBACLgB,MAAO,SAA0BoE,EAAYC,GACzC,OAAOD,EAAW1E,IAAI,SAAUuE,EAAQK,GACpC,OAAOzD,KAAKgC,IAAIoB,EAASI,EAAQC,GAAQ,KAC1CtC,OAAO,SAAUuC,EAAMC,GACtB,OAAOD,EAAOC,GACf,GAAKJ,EAAWpG,UAMvBgB,IAAK,eACLgB,MAAO,SAAsBA,EAAOyE,GAChC,OAAOzE,EAAQT,KAAKmF,aAAeD,KAGvCzF,IAAK,OACLgB,MAAO,SAAcA,EAAOyE,EAAYnE,EAAQqE,GAE5C,IAAIC,EAAS5E,EAAQT,KAAKmF,aAAeD,GAAyB,MAAXE,EAAkBrE,EAAOuE,SAAWvE,EAAOwE,cAAcH,IAgBhH,OAdIC,GAAU,GAAK5E,EAAQ,GAAK4E,GAAU,GAAK5E,EAAQ,EACpC,MAAX2E,EACArE,EAAOyE,cAAcJ,EAAS9D,KAAK8C,IAAoC,IAAhCrD,EAAOwE,cAAcH,GAAiB,KAE7ErE,EAAOuE,SAAWhE,KAAK8C,IAAsB,IAAlBrD,EAAOuE,SAAiB,IAGxC,MAAXF,EACArE,EAAOyE,cAAcJ,EAAS9D,KAAKmE,IAAI1E,EAAOwE,cAAcH,GAAW,IAAM,IAE7ErE,EAAOuE,SAAWhE,KAAKmE,IAAI1E,EAAOuE,SAAW,IAAM,GAIpDD,KAGX5F,IAAK,UACLgB,MAAO,SAAiBA,EAAOyE,EAAYnE,EAAQqE,GAQ/C,OANe,MAAXA,EACArE,EAAO2E,gBAAgBN,EAASA,EAAU9D,KAAKgC,IAAI4B,EAAY,IAE/DnE,EAAO4E,WAAarE,KAAKgC,IAAI4B,EAAY,GAGtCzE,EAAQT,KAAKmF,aAAeD,GAAc,KAAO5D,KAAKsE,KAAgB,MAAXR,EAAkBrE,EAAO8E,gBAAgBT,GAAWrE,EAAO4E,eAGjIlG,IAAK,UACLgB,MAAO,SAAiBA,EAAOyE,EAAYnE,EAAQqE,GAS/C,OAPe,MAAXA,EAEArE,EAAO2E,gBAAgBN,EAASpF,KAAK8F,SAAW/E,EAAO8E,gBAAgBT,IAAY,EAAIpF,KAAK8F,UAAYxE,KAAKgC,IAAI4B,EAAY,IAE7HnE,EAAO4E,UAAY3F,KAAK8F,SAAW/E,EAAO4E,WAAa,EAAI3F,KAAK8F,UAAYxE,KAAKgC,IAAI4B,EAAY,GAG9FzE,EAAQT,KAAKmF,aAAeD,GAAc,KAAO5D,KAAKsE,KAAgB,MAAXR,EAAkBrE,EAAO8E,gBAAgBT,GAAWrE,EAAO4E,eAGjIlG,IAAK,OACLgB,MAAO,SAAcA,EAAOyE,EAAYnE,GAEpCA,EAAOgF,EAAI,GAAMhF,EAAOgF,GAAK,EAAI,IAAOb,EACxC,IAAIc,EAAKjF,EAAOgF,GAAK,EAAIzE,KAAKgC,IAAI,GAAKtD,KAAKiG,WAAa,IAEzDlF,EAAOmF,EAAI,KAAQnF,EAAOmF,GAAK,EAAI,MAAS5E,KAAKgC,IAAI4B,EAAY,GACjE,IAAIiB,EAAKpF,EAAOmF,GAAK,EAAI5E,KAAKgC,IAAI,KAAOtD,KAAKiG,WAAa,IAE3D,OAAOxF,EAAQT,KAAKmF,aAAea,GAAM1E,KAAKsE,KAAKO,GAAM,SAG7D1G,IAAK,WACLgB,MAAO,SAAkBA,EAAOyE,EAAYnE,EAAQqE,GAEhD,GAAe,MAAXA,EAAiB,CACjBrE,EAAO2E,gBAAgBN,EAASpF,KAAKoG,IAAMrF,EAAO8E,gBAAgBT,IAAY,EAAIpF,KAAKoG,KAAO9E,KAAKgC,IAAI4B,EAAY,IACnH,IAAIG,EAAS5E,EAAQa,KAAKsE,MAAM7E,EAAOsF,iBAAiBjB,GAAW,OAASrE,EAAO8E,gBAAgBT,GAAW,OAASF,EAEvH,OADAnE,EAAOuF,iBAAiBlB,EAASpF,KAAKoG,IAAMrF,EAAOsF,iBAAiBjB,IAAY,EAAIpF,KAAKoG,KAAO9E,KAAKgC,IAAI4B,EAAY,IAC9GG,EAEPtE,EAAO4E,UAAY3F,KAAKoG,IAAMrF,EAAO4E,WAAa,EAAI3F,KAAKoG,KAAO9E,KAAKgC,IAAI4B,EAAY,GACvF,IAAIqB,EAAU9F,EAAQa,KAAKsE,MAAM7E,EAAOyF,kBAAoB,OAASzF,EAAO4E,UAAY,OAAST,EAEjG,OADAnE,EAAOyF,kBAAoBxG,KAAKoG,IAAMrF,EAAOyF,mBAAqB,EAAIxG,KAAKoG,KAAO9E,KAAKgC,IAAI4B,EAAY,GAChGqB,KAOf9G,IAAK,UACLgB,MAAO,SAAiBX,EAAM2G,GAC1B,IAAIC,EAAQD,EAAKC,MAEjB,SAAUxG,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU+F,GAChE,OAAuB,EAAhB5E,KAAKC,SAAemF,EAAQA,OAI3CjH,IAAK,WACLgB,MAAO,SAAkBX,EAAM6G,GAC3B,IAAIC,EAAOD,EAAMC,KACbC,EAAeF,EAAME,aAEzB,SAAU3G,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,WAEtD,IAAI2G,OAAK,EACLC,OAAK,EACLC,OAAI,EAGR,GACIF,EAAK,EAAIxF,KAAKC,SAAW,EACzBwF,EAAK,EAAIzF,KAAKC,SAAW,EACzByF,EAAI1F,KAAKgC,IAAIwD,EAAI,GAAKxF,KAAKgC,IAAIyD,EAAI,SAC9BC,GAAK,IAAMA,GAEpB,OAAOJ,EAAOE,EAAKxF,KAAKsE,MAAM,EAAItE,KAAKsD,IAAIoC,GAAKA,GAAKH,OAI7DpH,IAAK,eACLgB,MAAO,SAAsBX,EAAMmH,GAC/B,IAAIC,EAAQD,EAAMC,MACdC,EAASF,EAAME,OAEnB,OAAOA,GAAoB,GAAVA,EAAcnD,EAAQoD,SAAStH,GAAQ8G,KAAM,EAAGC,aAAcvF,KAAKsE,KAAK,GAAKsB,EAAQC,MAAcnD,EAAQqD,YAAYvH,GAAQoH,MAAOA,OAG3JzH,IAAK,gBACLgB,MAAO,SAAuBX,EAAMwH,GAChC,IAAIJ,EAAQI,EAAMJ,MACdC,EAASG,EAAMH,OAEnB,OAAOA,GAAoB,GAAVA,EAAcnD,EAAQuD,QAAQzH,GAAQ4G,MAAOpF,KAAKsE,KAAK,GAAKsB,EAAQC,MAAcnD,EAAQwD,aAAa1H,GAAQoH,MAAOA,OAG3IzH,IAAK,cACLgB,MAAO,SAAqBX,EAAM2H,GAC9B,IAAIP,EAAQO,EAAMP,MAElB,OAAOlD,EAAQoD,SAAStH,GAAQ8G,KAAM,EAAGC,aAAcvF,KAAKsE,KAAK,EAAIsB,QAGzEzH,IAAK,eACLgB,MAAO,SAAsBX,EAAM4H,GAC/B,IAAIR,EAAQQ,EAAMR,MAElB,OAAOlD,EAAQuD,QAAQzH,GAAQ4G,MAAOpF,KAAKsE,KAAK,EAAIsB,QAMxDzH,IAAK,UACLgB,MAAO,SAAiBkH,GACpB,IAAIC,EAAQD,EAAOlF,OAAO,SAAUuC,EAAMC,GACtC,OAAOD,EAAOC,GACf,GACH,OAAO0C,EAAOxH,IAAI,SAAUM,GACxB,OAAOA,EAAQmH,OAIvBnI,IAAK,OACLgB,MAAO,SAAcA,GACjB,OAAO,EAAIa,KAAK6C,KAAK1D,IAAU,EAAIa,KAAK6C,KAAK,EAAI1D,OAGrDhB,IAAK,oBACLgB,MAAO,SAA2BrC,GAC9B,IAAIyJ,EAAMzJ,EAAIqE,OAAO,SAAUC,EAAGC,GAC9B,OAAOD,EAAIC,IACVvE,EAAIK,OACLqJ,EAAQ1J,EAAI+B,IAAI,SAAU+F,GAC1B,OAAOA,EAAI2B,IACZ1H,IAAI,SAAU+F,GACb,OAAO5E,KAAKgC,IAAI4C,EAAG,KAEvB,OAAO5E,KAAKsE,KAAKkC,EAAMrF,OAAO,SAAUC,EAAGC,GACvC,OAAOD,EAAIC,IACVmF,EAAMrJ,WAGfgB,IAAK,UACLgB,MAAO,WAEH,GAAIT,KAAK4D,aAAe5D,KAAK2D,QAAS,CAElC,IAAIoE,EAAa/H,KAAK2D,SAAW,MAAQ3D,KAAK4D,cAE9C5D,KAAKgI,OAAOlH,QAAQ,SAAUJ,EAAOuH,GACjCA,GAAMvH,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAOE,QAAQH,QAAQ,SAAUoH,EAAGrF,GAChC,OAAO9B,EAAOoH,UAAUtF,EAAI9B,EAAOqH,UAAUvF,GAAMkF,SAMnE/H,KAAK4D,aAAe,MAIrBI,KAGM,oBAAVF,SAA0BC,QAAQC,QAAUA,SAGnD,IAAIqE,QAAU,WACV,SAASA,IACL1J,gBAAgBqB,KAAMqI,GAkH1B,OA/GAtJ,aAAasJ,EAAS,OAClB5I,IAAK,SACLgB,MAAO,SAAgBA,GACnB,IAAI6H,EAAOC,UAAU9J,OAAS,QAAsB8B,IAAjBgI,UAAU,GAAmBA,UAAU,GAAK,SAE/E,QAAQ,GAEJ,IAAa,UAARD,GAAoC,iBAAT7H,EAC5BA,EAAQA,EAAM+H,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAa,QAARH,GAAkC,iBAAT7H,EAC1B,IAAIiI,EAAO,IAAIC,KAAKlI,GAChBmI,KAEAnI,EAAQ,IACRmI,EAAUC,KAAKH,EAAKI,kBAAoB,OAGpCrI,GAAS,MAASmI,EAAUC,KAAKH,EAAKK,WAAa,KACnDtI,GAAS,KAAOmI,EAAUC,KAAKH,EAAKM,aAAe,KAEvDJ,EAAUC,KAAKH,EAAKO,aAAe,MAGvCxI,EAAQmI,EAAUM,KAAK,KAI/B,OAAOzI,KAGXhB,IAAK,UACLgB,MAAO,SAAiBrC,GACpB,IAAK,IAAIG,EAAIH,EAAIK,OAAQF,EAAGA,IAAK,CAC7B,IAAI4K,EAAI7H,KAAK8H,MAAM9H,KAAKC,SAAWhD,GAC/B8K,EAAIjL,EAAIG,EAAI,GAChBH,EAAIG,EAAI,GAAKH,EAAI+K,GACjB/K,EAAI+K,GAAKE,MAIjB5J,IAAK,iBACLgB,MAAO,SAAwBN,EAAKmJ,GAChC,IAAIC,KAAkBrJ,OAAO/B,mBAAmB,IAAIE,MAAMiL,KAAMnJ,IAAI,SAAU+F,GAC1E,OAAO,IAEX/F,EAAMA,EAAIA,IAAI,SAAUqJ,GACpB,SAAUtJ,OAAO/B,mBAAmBoL,GAAepL,mBAAmBqL,GAAMrL,mBAAmBoL,MAGnG,IAAIE,KAAevJ,OAAO/B,mBAAmB,IAAIE,MAAMiL,KAAMnJ,IAAI,SAAU6G,GACvE,SAAU9G,OAAO/B,mBAAmB,IAAIE,MAAM8B,EAAI1B,OAAc,EAAL6K,KAAUnJ,IAAI,SAAUkJ,GAC/E,OAAO,MAGf,SAAUnJ,OAAO/B,mBAAmBsL,EAAUC,MAAM,IAAKvL,mBAAmBgC,GAAMhC,mBAAmBsL,EAAUC,MAAM,QAMzHjK,IAAK,aACLgB,MAAO,SAAoBkJ,GASvB,IAAK,IAPDC,EAAID,EAAOlL,OACX0B,KAASD,OAAO/B,mBAAmB,IAAIE,MAAMuL,EAAI,KAAKzJ,IAAI,SAAUqJ,GACpE,SAAUtJ,OAAO/B,mBAAmB,IAAIE,MAAMuL,EAAI,KAAKzJ,IAAI,SAAU+F,GACjE,OAAO,MAIN2D,EAAK,EAAGA,GAAMD,EAAGC,IACtB,IAAK,IAAIlF,EAAK,EAAGA,GAAMiF,EAAGjF,IACtBxE,EAAI0J,GAAIlF,GAAMxE,EAAI0J,EAAK,GAAGlF,GAAMgF,EAAOE,EAAK,GAAGlF,EAAK,GAI5D,IAAK,IAAImF,EAAM,EAAGA,GAAOF,EAAGE,IACxB,IAAK,IAAIC,EAAM,EAAGA,GAAOH,EAAGG,IACxB5J,EAAI2J,GAAKC,IAAQ5J,EAAI2J,GAAKC,EAAM,GAIxC,OAAO5J,KAGXV,IAAK,WACLgB,MAAO,SAAkBN,EAAKmJ,EAAIU,GAS9B,IAAK,IAPDJ,EAAIzJ,EAAI1B,OACRwL,KAAY/J,OAAO/B,mBAAmB,IAAIE,MAAMuL,EAAI,EAAS,EAALN,KAAUnJ,IAAI,SAAUqJ,GAChF,SAAUtJ,OAAO/B,mBAAmB,IAAIE,MAAMuL,EAAI,EAAS,EAALN,KAAUnJ,IAAI,SAAU+F,GAC1E,OAAO,MAIN2D,EAAKD,EAAIN,EAAIO,EAAKP,EAAK,EAAGO,IAC/B,IAAK,IAAI3D,EAAI0D,EAAIN,EAAIpD,EAAIoD,EAAK,EAAGpD,IAAK,CAElC,IAAIgE,EAAKhE,EAAI8D,EACTG,EAAIN,EAAKG,EAEbC,EAAOJ,EAAKvI,KAAK8H,MAAMY,IAAK9D,EAAI5E,KAAK8H,MAAMY,IAAO7J,EAAI0J,GAAI3D,GAAK/F,EAAI0J,GAAIK,GAAM/J,EAAIgK,GAAGjE,GAAK/F,EAAIgK,GAAGD,GAIxG,OAAOD,MAIR5B,KAGM,oBAAVvE,SAA0BC,QAAQsE,QAAUA,SAGnD,IAAI+B,QAAU,WACV,SAASA,IACL,IAAIC,EAAQ9B,UAAU9J,OAAS,QAAsB8B,IAAjBgI,UAAU,GAAmBA,UAAU,MACvEpD,EAAekF,EAAMlF,aACrBmF,EAAeD,EAAMrC,OACrBA,OAA0BzH,IAAjB+J,KAAkCA,EAC3CC,EAAmBF,EAAM5I,WACzBA,OAAkClB,IAArBgK,EAAiC,eAAiBA,EAC/DC,EAAmBH,EAAMrI,WACzBA,OAAkCzB,IAArBiK,EAAiC,UAAYA,EAC1DC,EAAaJ,EAAMK,KACnBA,OAAsBnK,IAAfkK,EAA2B,mBAAqBA,EACvD3E,EAAWuE,EAAMvE,SACjBM,EAAMiE,EAAMjE,IACZ/B,EAAagG,EAAMhG,WACnB1C,EAAW0I,EAAM1I,SACjBgJ,EAAgBN,EAAMtI,QACtBA,OAA4BxB,IAAlBoK,EAA8B,EAAIA,EAC5CC,EAAUP,EAAMtH,GAChBA,OAAiBxC,IAAZqK,GAA+BA,EACpCC,EAAWR,EAAMrH,GACjBA,OAAkBzC,IAAbsK,GAAgCA,EACrClH,EAAU0G,EAAM1G,QAChBvC,EAAgBiJ,EAAMjJ,cAkC1B,OAhCAzC,gBAAgBqB,KAAMoK,GAEtBpK,KAAKQ,MAAQ,cACbR,KAAKgI,UACLhI,KAAK8K,OAAS,EACd9K,KAAKiG,WAAa,EAClBjG,KAAK+B,QAAqB,GAAXA,EAAmB,EAAIA,EACtC/B,KAAKsC,MAAQ,EACbN,EAAaqG,QAAQ0C,OAAO/I,GAC5BP,EAAa4G,QAAQ0C,OAAOtJ,GAC5BiJ,EAAOrC,QAAQ0C,OAAOL,GAEF,MAAhBvF,IACAnF,KAAKmF,aAAeA,GAGpBpC,IACA/C,KAAK+C,GAAkB,kBAANA,EAAkB,KAAQA,EAC3C/C,KAAKqD,QAAU,GAGfL,IACAhD,KAAKgD,GAAkB,kBAANA,EAAkB,KAAQA,EAC3ChD,KAAKuD,QAAU,GAGfI,IACA3D,KAAK2D,QAA4B,kBAAXA,GAAwBA,EAAU,IAAOA,EAC/D3D,KAAK4D,aAAe,GAIhBnC,GAEJ,IAAK,UACDzB,KAAKmF,kBAAoC5E,GAArBP,KAAKmF,aAA4B,KAAQnF,KAAKmF,aAClE,MAEJ,IAAK,OACDnF,KAAKmF,kBAAoC5E,GAArBP,KAAKmF,aAA4B,IAAOnF,KAAKmF,aACjE,MAEJ,IAAK,WACDnF,KAAKoG,IAAa,MAAPA,EAAc,IAAOA,EAChC,MAEJ,QAEI,QAAyB7F,GAArBP,KAAKmF,aAEL,OAAQnD,GAEJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACDhC,KAAKmF,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACDnF,KAAKmF,aAAe,KACpB,MAEJ,QACInF,KAAKmF,aAAe,IA0CxC,GArCAnF,KAAKyB,aAAc,EAAO,UAAMlB,GAAWyK,SAASvJ,GAAc,eAAiBA,EACnFzB,KAAKyD,eAAiBO,QAAQhE,KAAKyB,YACnCzB,KAAKgC,WAAkC,mBAAdA,EAA2BA,EAAagC,QAAQhC,GAAY0B,KAAK1D,MAC1FA,KAAK0B,iBAAmBM,EACxBhC,KAAK0K,KAAsB,mBAARA,EAAqBA,EAAO1G,QAAQ0G,GAEhC,WAAnB1K,KAAKyB,aACLzB,KAAK8F,cAAuBvF,GAAZuF,EAAwB,IAAOA,GAGjC,SAAd9D,EACAhC,KAAKqE,gBAA2B9D,GAAd8D,GAA2B,KAASA,EACjC,OAAdrC,IACPhC,KAAK2B,cAAuBpB,GAAZoB,EAAwB,EAAIA,GAIhD3B,KAAKoB,eAAkB6J,aAAc,sBAEhB1K,GAAjBa,GAA8BA,EAAc6J,eAC5CjL,KAAKoB,cAAc6J,aAAe5C,QAAQ0C,OAAO3J,EAAc6J,eAG5B,WAAnCjL,KAAKoB,cAAc6J,aACnBjL,KAAKoB,cAAcsF,MAAQtF,QAAwCb,GAAvBa,EAAcsF,MAAqBtF,EAAcsF,MAAQ,GAC3D,YAAnC1G,KAAKoB,cAAc6J,eAC1BjL,KAAKoB,cAAcwF,KAAOxF,EAAcwF,MAAQ,EAChD5G,KAAKoB,cAAcyF,aAAezF,EAAcyF,cAAgB,KAGtB,mBAAnC7G,KAAKoB,cAAc6J,aAC1BjL,KAAKmB,cAAgBnB,KAAKoB,cAAc6J,aAExCjL,KAAKmB,cAAgB6C,QAAQhE,KAAKoB,cAAc6J,cAIhDjD,EAAOvJ,OAEP,QAAQ,GAEJ,KAAKuJ,EAAOkD,MAAM,SAAUC,GACxB,OAAOC,OAAOC,UAAUF,KAExBnL,KAAKgI,OAASA,EAAO7H,IAAI,SAAUL,GAC/B,OAAO,IAAI+D,MAAM/D,KAErBE,KAAKQ,MAAQ,cACbR,KAAKsL,aACL,MAEJ,KAAKtD,EAAOkD,MAAM,SAAUC,GACxB,OAAOA,aAAgBtH,OAASsH,aAAgBtL,UAEhDG,KAAKQ,MAAQ,cACbR,KAAKgI,OAASA,EACdhI,KAAKsL,aACL,MAEJ,KAAKtD,EAAOkD,MAAM,SAAUC,GACxB,OAAOA,IAAStH,OAASsH,IAAStL,UAElCG,KAAKQ,MAAQ,UACbR,KAAKuL,cAAgBvD,EACrB,MAEJ,QACI,MAAM,IAAIwD,MAAM,2DAoUhC,OA/TAzM,aAAaqL,IACT3K,IAAK,aACLgB,MAAO,SAAoBgL,EAAOrJ,GAC9B,IAAIsJ,EAAS1L,KAEb,OAAQA,KAAKQ,OAET,IAAK,cACD,OAEJ,IAAK,UACDR,KAAKgI,OAAShI,KAAKuL,cAAcpL,IAAI,SAAUO,EAAOuH,GAElD,IAAKA,EAAI,OAAO,IAAIvH,EAAM+K,GAE1B,GAAIxD,GAAMyD,EAAOH,cAAc9M,OAAS,EAAG,OAAO,IAAIiC,EAAM0B,GAE5D,IAAIuJ,EAASD,EAAOH,cAAc9M,OAAS,EACvCqB,EAAO2L,EAAQrJ,EAAW,EAAIA,GAAYA,EAAWd,KAAKkC,IAAIiI,EAAQrJ,GAAY,IAAMuJ,EAAS1D,EAAK,IAAM0D,EAAS,GAAKF,GAASrJ,EAAWqJ,EAAQrJ,GAAYuJ,EAAS1D,IAAO0D,EAAS,GAAKvJ,EAAWqJ,GAASE,EAAS1D,IAAO0D,EAAS,GAEjP,OAAO,IAAIjL,EAAMY,KAAK8C,IAAI9C,KAAKsK,MAAM9L,GAAO,MAEhD,MAEJ,IAAK,cACDE,KAAKgI,OAAO,GAAK,IAAInI,QAAQ4L,GAC7BzL,KAAKgI,OAAO,GAAK,IAAInI,QAAQyB,KAAKuK,KAAKJ,EAAQrJ,EAAW,EAAIA,EAAWd,KAAKkC,IAAIiI,EAAQrJ,GAAY,EAAIqJ,EAAQrJ,IAClHpC,KAAKgI,OAAO,GAAK,IAAInI,QAAQyB,KAAKuK,KAAKzJ,IAI/CpC,KAAKgI,OAAOlH,QAAQd,KAAK8L,UAAUpI,KAAK1D,OACxCA,KAAKQ,MAAQ,iBAGjBf,IAAK,YACLgB,MAAO,SAAmBC,EAAOqL,GAE7BrL,EAAMQ,IAAMlB,KACZU,EAAMsB,WAAahC,KAAKgC,WAExBtB,EAAMU,iBACN7B,OAAOyM,OAAOtL,EAAMU,cAAepB,KAAKoB,eAEpC2K,IACArL,EAAMU,cAAc8F,MAAQlH,KAAKgI,OAAO+D,EAAa,GAAGjM,KACxDE,KAAKgI,OAAO+D,EAAa,GAAG3K,cAAc+F,OAASzG,EAAMZ,KACzDE,KAAKgI,OAAO+D,EAAa,GAAGE,WAAWvL,GACvCA,EAAMwL,WAAWlM,KAAKgI,OAAO+D,EAAa,QAIlDtM,IAAK,UACLgB,MAAO,SAAiBmB,GAEpB,GAAkB,eAAd5B,KAAKQ,MACL,MAAM,IAAIgL,MAAM,iDAGpB,QAAajL,IAATqB,EACA,MAAM,IAAI4J,MAAM,uCAapB,OAVI5J,EAAKnD,QAAUuB,KAAKgI,OAAO,GAAG/H,QAAQxB,QACtC0N,QAAQC,KAAK,8DAGjBpM,KAAKgI,OAAO,GAAG/H,QAAQa,QAAQ,SAAUC,EAAQV,GAC7C,OAAOU,EAAOiB,WAAaJ,EAAKvB,KAEpCL,KAAKgI,OAAOlH,QAAQ,SAAUJ,EAAOuH,GACjC,OAAOA,GAAMvH,EAAM2L,QAAQzK,KAExB5B,KAAKgI,OAAOhI,KAAKgI,OAAOvJ,OAAS,GAAGwB,QAAQE,IAAI,SAAUC,GAC7D,OAAOA,EAAE4B,gBAIjBvC,IAAK,WACLgB,MAAO,SAAkB2B,GAErB,QAAiB7B,IAAb6B,EACA,MAAM,IAAIoJ,MAAM,wCAGhBpJ,EAAS3D,QAAUuB,KAAKgI,OAAOhI,KAAKgI,OAAOvJ,OAAS,GAAGwB,QAAQxB,QAC/D0N,QAAQC,KAAK,iEAAkEhK,GAGnFpC,KAAKgI,OAAOhI,KAAKgI,OAAOvJ,OAAS,GAAG6N,SAASlK,GAE7C,IAAK,IAAI2J,EAAa/L,KAAKgI,OAAOvJ,OAAS,EAAGsN,EAAa,EAAGA,IAC1D/L,KAAKgI,OAAO+D,GAAYO,cAIhC7M,IAAK,QACLgB,MAAO,SAAe8L,GAClB,IAAIC,EAASxM,KAETyM,EAAQlE,UAAU9J,OAAS,QAAsB8B,IAAjBgI,UAAU,GAAmBA,UAAU,MACvEmE,EAAeD,EAAM3B,OACrBA,OAA0BvK,IAAjBmM,EAA6B,EAAIA,EAC1CC,EAAWF,EAAME,SACjBC,EAAYH,EAAM7H,IAClBA,OAAoBrE,IAAdqM,GAAiCA,EACvCC,EAAsBJ,EAAMxJ,cAC5BA,OAAwC1C,IAAxBsM,EAAoC,EAAIA,EACxDC,EAAgBL,EAAMM,QACtBA,OAA4BxM,IAAlBuM,GAAsCA,EAYpD,OAVA9M,KAAKiD,cAAwC,kBAAjBA,GAA8BA,EAAgBsJ,EAAQ,GAAGnK,SAAS3D,OAASwE,EAEnG8J,GACA1E,QAAQ0E,QAAQR,GAGhB3H,GACAuH,QAAQvH,IAAI,6BAA+BkG,EAAS,gBAAkB9K,KAAKiD,eAGxE,IAAI+J,QAAQ,SAAUC,EAASC,GAElC,QAAgB3M,IAAZgM,GAAqC,OAAZA,EAA7B,CAIoB,eAAhBC,EAAOhM,OACPgM,EAAOlB,WAAWiB,EAAQ,GAAGd,MAAMhN,QAAS8N,EAAQ,GAAGnK,UAAYmK,EAAQ,GAAG7H,QAAQjG,QAG1F+N,EAAOxE,OAAOlH,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,aAGzB,IAAI2M,EAAiB,EACjBC,EAAgB,EAChBC,EAAY1E,KAAK2E,MAEjBC,EAAU,WACVf,EAAO1B,SACP0B,EAAOlK,MAAQ,EACf6K,EAAiB,OAEK5M,GAAlBiM,EAAOnJ,UAAsBmJ,EAAOnJ,QAAU,QAC5B9C,GAAlBiM,EAAOjJ,UAAsBiJ,EAAOjJ,QAAU,GAElDiK,KAGAA,EAAc,SAASA,IAEvB,GAAKjB,EAAQY,GAAgBM,eAAe,WAAalB,EAAQY,GAAgBM,eAAe,aAAgBlB,EAAQY,GAAgBM,eAAe,WAAvJ,CAIA,IAAIhC,EAAQc,EAAQY,GAAgB1B,MAChC/G,EAAS8H,EAAOH,QAAQZ,GACxBxM,EAASsN,EAAQY,GAAgB/K,UAAYmK,EAAQY,GAAgBzI,OAEzE8H,EAAOF,SAASrN,KAEVkO,EAAiBX,EAAOvJ,eAAiB,GAC3CuJ,EAAOkB,oBACPlB,EAAOmB,qBACAR,GAAkBZ,EAAQ9N,QACjC+N,EAAOkB,oBAGX,IAAIE,EAAiBpB,EAAO9B,KAAKzL,EAAQyF,GACrCmJ,EAAUlF,KAAK2E,MAAQD,EAC3Bb,EAAOlK,OAASsL,EAChBpB,EAAOvG,aAEgB,mBAAZ0G,GACPA,GACI1G,WAAYuG,EAAOvG,WACnB3D,MAAOsL,EACPC,QAASA,EAASpC,MAAOA,IAI7B0B,EAAiBZ,EAAQ9N,OACzBqP,WAAWN,EAAY9J,KAAK8I,GAAS,IAErCY,IAEIxI,GACAuH,QAAQvH,IAAI,UAAY4H,EAAO1B,OAAS,WAAa0B,EAAOlK,MAAQ6K,QAA+B5M,GAAbiM,EAAOzJ,GAAkB,GAAK,cAAgByJ,EAAOnJ,QAAU8J,GAAiB,cAAgB9E,QAAQ0C,OAAO8C,EAAS,QAAU,sBAAwBxF,QAAQ0C,OAAO8C,EAAUT,EAAe,SAGxRA,EAAgBtC,EAChByC,KAEAf,EAAOxE,OAAOlH,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,gBAGrBoE,GACAuH,QAAQvH,IAAI,kCAAoCyD,QAAQ0C,OAAO8C,EAAS,QAAU,6BAA+BxF,QAAQ0C,OAAO8C,EAAUV,EAAgB,SAE9JF,WAhDQC,EAAO,uFAqD3BV,EAAOmB,oBACPJ,SAnFgBL,EAAO,yBAuF/BzN,IAAK,OACLgB,MAAO,SAAcsN,GACjB,IAAIC,EAAShO,KAETiO,EAAQ1F,UAAU9J,OAAS,QAAsB8B,IAAjBgI,UAAU,GAAmBA,UAAU,MACvE2F,EAAYD,EAAMrJ,IAClBA,OAAoBrE,IAAd2N,GAAiCA,EACvCvB,EAAWsB,EAAMtB,SAErB,OAAO,IAAIK,QAAQ,SAAUC,EAASC,QAElB3M,IAAZwN,GAAqC,OAAZA,GACzBb,EAAO,oBAGX,IAAIiB,EAAa,EACbhB,EAAiB,EACjBE,EAAY1E,KAAK2E,OAEL,SAASc,IAErB,IAAI3C,EAAQsC,EAAQZ,GAAgB1B,MAChC/G,EAASsJ,EAAO3B,QAAQZ,GACxBxM,EAAS8O,EAAQZ,GAAgB/K,UAAY2L,EAAQZ,GAAgBzI,OACrEmJ,EAAUlF,KAAK2E,MAAQD,EAEvBO,EAAiBI,EAAOtD,KAAKzL,EAAQyF,GACzCyJ,GAAcP,EACdT,IAEIvI,GACAuH,QAAQvH,IAAI,oBAAqBuI,EAAgBS,GAG9B,mBAAZjB,GACPA,GACI1G,WAAYkH,EACZ7K,MAAOsL,EACPC,QAASA,EAASpC,MAAOA,IAI7B0B,EAAiBY,EAAQtP,OACzBqP,WAAWM,EAAU1K,KAAKsK,GAAS,IAG/BpJ,GACAuH,QAAQvH,IAAI,iCAAmCyD,QAAQ0C,OAAO8C,EAAS,QAAU,6BAA+BxF,QAAQ0C,OAAO8C,EAAUV,EAAgB,SAG7JF,EAAQkB,EAAaJ,EAAQtP,iBAO7CgB,IAAK,oBACLgB,MAAO,WACHT,KAAKgI,OAAOlH,QAAQ,SAAUJ,EAAOuH,GACjC,OAAOA,GAAMvH,EAAMiN,yBAI3BlO,IAAK,oBACLgB,MAAO,WAEHT,KAAKgI,OAAOlH,QAAQ,SAAUJ,EAAOuH,GACjC,OAAOA,GAAMvH,EAAMgN,2BAGHnN,GAAhBP,KAAK2D,UACL3D,KAAK4D,aAAetC,KAAKsE,KAAK5F,KAAK4D,cACnCI,QAAQL,QAAQD,KAAK1D,YAI7BP,IAAK,SACLgB,MAAO,WACH,OACIuH,OAAQhI,KAAKgI,OAAO7H,IAAI,SAAUO,GAC9B,OACIT,QAASS,EAAMT,QAAQE,IAAI,SAAUY,GACjC,OACIM,KAAMN,EAAOM,KACbJ,QAASF,EAAOE,kBAQxCxB,IAAK,WACLgB,MAAO,SAAkBmB,GAErB,QAAarB,IAATqB,GAA+B,OAATA,EACtB,MAAM,IAAI4J,MAAM,iCAGpBxL,KAAKgI,OAASpG,EAAKoG,OAAO7H,IAAI,SAAUO,GACpC,OAAO,IAAIb,QAAQa,EAAMT,QAAQxB,OAAQiC,EAAMT,WAEnDD,KAAKQ,MAAQ,cACbR,KAAKsL,iBAINlB,KAGM,oBAAVtG,SAA0BC,QAAQqG,QAAUA,SAGnD,IAAI9J,OAAS,WACT,SAASA,EAAOP,GACZpB,gBAAgBqB,KAAMM,GAElBP,IACAC,KAAKgB,UAAW,EAChBhB,KAAKiB,QAAUlB,EAAakB,YAC5BjB,KAAKqB,KAAOtB,EAAasB,MA+FjC,OA3FAtC,aAAauB,IACTb,IAAK,OACLgB,MAAO,SAAcX,GACjB,IAAIuO,EAASrO,KAETsO,EAAS/F,UAAU9J,OAAS,QAAsB8B,IAAjBgI,UAAU,GAAmBA,UAAU,MACxE9G,EAAa6M,EAAO7M,WACpBC,EAAmB4M,EAAO5M,iBAC1BC,EAAW2M,EAAO3M,SAMtB,OAJA3B,KAAK8C,aAAe9C,KAAKiB,QAAQd,IAAI,SAAU+F,GAC3C,OAAO,IAGHzE,GAEJ,IAAK,OACDzB,KAAKsF,SAAW,EAChBtF,KAAKuO,eAAiBrO,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU+F,GAC5E,OAAO,IAEXlG,KAAKuF,cAAgB,SAAUhH,GAC3B,OAAO8P,EAAOE,YAAYhQ,IAE9ByB,KAAKwF,cAAgB,SAAUjH,EAAG2H,GAC9B,OAAOmI,EAAOE,YAAYhQ,GAAK2H,GAEnC,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACDlG,KAAK2F,UAAY,EACjB3F,KAAKwO,gBAAkBtO,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU+F,GAC7E,OAAO,IAEXlG,KAAK6F,gBAAkB,SAAUtH,GAC7B,OAAO8P,EAAOG,aAAajQ,IAE/ByB,KAAK0F,gBAAkB,SAAUnH,EAAG2H,GAChC,OAAOmI,EAAOG,aAAajQ,GAAK2H,GAGlB,YAAdzE,IACAzB,KAAKwG,kBAAoB,EACzBxG,KAAKyO,iBAAmBvO,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU+F,GAC9E,OAAO,IAEXlG,KAAKqG,iBAAmB,SAAU9H,GAC9B,OAAO8P,EAAOI,cAAclQ,IAEhCyB,KAAKsG,iBAAmB,SAAU/H,EAAG2H,GACjC,OAAOmI,EAAOI,cAAclQ,GAAK2H,IAGzC,MAEJ,IAAK,OACDlG,KAAK+F,EAAI,EACT/F,KAAKkG,EAAI,EAIO,SAApBxE,EACA1B,KAAKsE,WAA6B,KAAhBhD,KAAKC,SACI,OAApBG,IACP1B,KAAK2B,SAAWA,MAIxBlC,IAAK,YACLgB,MAAO,SAAmBlC,GACtB,OAAOyB,KAAKiB,QAAQ1C,MAGxBkB,IAAK,YACLgB,MAAO,SAAmBlC,EAAG2H,GACzBlG,KAAKiB,QAAQ1C,GAAK2H,KAGtBzG,IAAK,iBACLgB,MAAO,SAAwBlC,GAC3B,OAAOyB,KAAK8C,aAAavE,MAG7BkB,IAAK,iBACLgB,MAAO,SAAwBlC,EAAG2H,GAC9BlG,KAAK8C,aAAavE,GAAK2H,MAIxB5F,KAGM,oBAAVwD,SAA0BC,QAAQzD,OAASA","sourcesContent":["\"use strict\";\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar FCLayer = function () {\n    function FCLayer(size, importedData) {\n        _classCallCheck(this, FCLayer);\n\n        this.size = size;\n        this.neurons = [].concat(_toConsumableArray(new Array(size))).map(function (n, ni) {\n            return new Neuron(importedData ? importedData[ni] : undefined);\n        });\n        this.state = \"not-initialised\";\n    }\n\n    _createClass(FCLayer, [{\n        key: \"assignNext\",\n        value: function assignNext(layer) {\n            this.nextLayer = layer;\n        }\n    }, {\n        key: \"assignPrev\",\n        value: function assignPrev(layer) {\n            var _this = this;\n\n            this.prevLayer = layer;\n            this.neurons.forEach(function (neuron) {\n\n                if (!neuron.imported) {\n                    neuron.weights = _this.net.weightsInitFn(layer.size, _this.weightsConfig);\n                    neuron.bias = Math.random() * 0.2 - 0.1;\n                }\n\n                neuron.init(layer.size, {\n                    adaptiveLR: _this.net.adaptiveLR,\n                    activationConfig: _this.net.activationConfig,\n                    eluAlpha: _this.net.eluAlpha\n                });\n            });\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n            var _this2 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (_this2.state == \"training\" && (neuron.dropped = Math.random() > _this2.net.dropout)) {\n                    neuron.activation = 0;\n                } else {\n                    neuron.sum = neuron.bias;\n                    _this2.prevLayer.neurons.forEach(function (pNeuron, pni) {\n                        return neuron.sum += pNeuron.activation * neuron.weights[pni];\n                    });\n                    neuron.activation = _this2.activation(neuron.sum, false, neuron) / (_this2.net.dropout | 1);\n                }\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            var _this3 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (neuron.dropped) {\n                    neuron.error = 0;\n                    neuron.deltaBias = 0;\n                } else {\n                    if (typeof expected !== \"undefined\") {\n                        neuron.error = expected[ni] - neuron.activation;\n                    } else {\n                        neuron.derivative = _this3.activation(neuron.sum, true, neuron);\n                        neuron.error = neuron.derivative * _this3.nextLayer.neurons.map(function (n) {\n                            return n.error * (n.weights[ni] | 0);\n                        }).reduce(function (p, c) {\n                            return p + c;\n                        }, 0);\n                    }\n\n                    neuron.weights.forEach(function (weight, wi) {\n                        neuron.deltaWeights[wi] += neuron.error * _this3.prevLayer.neurons[wi].activation * (1 + ((_this3.net.l2 || 0) + (_this3.net.l1 || 0)) / _this3.net.miniBatchSize * neuron.deltaWeights[wi]);\n                    });\n\n                    neuron.deltaBias = neuron.error;\n                }\n            });\n        }\n    }, {\n        key: \"resetDeltaWeights\",\n        value: function resetDeltaWeights() {\n            this.neurons.forEach(function (neuron) {\n                return neuron.deltaWeights = neuron.weights.map(function (dw) {\n                    return 0;\n                });\n            });\n        }\n    }, {\n        key: \"applyDeltaWeights\",\n        value: function applyDeltaWeights() {\n            var _this4 = this;\n\n            this.neurons.forEach(function (neuron) {\n                neuron.deltaWeights.forEach(function (dw, dwi) {\n\n                    if (_this4.net.l2 != undefined) _this4.net.l2Error += 0.5 * _this4.net.l2 * Math.pow(neuron.weights[dwi], 2);\n                    if (_this4.net.l1 != undefined) _this4.net.l1Error += _this4.net.l1 * Math.abs(neuron.weights[dwi]);\n\n                    neuron.weights[dwi] = _this4.net.weightUpdateFn.bind(_this4.net, neuron.weights[dwi], dw, neuron, dwi)();\n\n                    if (_this4.net.maxNorm != undefined) _this4.net.maxNormTotal += Math.pow(neuron.weights[dwi], 2);\n                });\n\n                neuron.bias = _this4.net.weightUpdateFn.bind(_this4.net, neuron.bias, neuron.deltaBias, neuron)();\n            });\n        }\n    }]);\n\n    return FCLayer;\n}();\n\nvar Layer = FCLayer;\n\ntypeof window == \"undefined\" && (exports.FCLayer = exports.Layer = FCLayer);\n\"use strict\";\n\nvar NetMath = function () {\n    function NetMath() {\n        _classCallCheck(this, NetMath);\n    }\n\n    _createClass(NetMath, null, [{\n        key: \"sigmoid\",\n\n\n        // Activation functions\n        value: function sigmoid(value, prime) {\n            var val = 1 / (1 + Math.exp(-value));\n            return prime ? val * (1 - val) : val;\n        }\n    }, {\n        key: \"tanh\",\n        value: function tanh(value, prime) {\n            var exp = Math.exp(2 * value);\n            return prime ? 4 / Math.pow(Math.exp(value) + Math.exp(-value), 2) || 1e-18 : (exp - 1) / (exp + 1) || 1e-18;\n        }\n    }, {\n        key: \"relu\",\n        value: function relu(value, prime) {\n            return prime ? value > 0 ? 1 : 0 : Math.max(value, 0);\n        }\n    }, {\n        key: \"lrelu\",\n        value: function lrelu(value, prime) {\n            return prime ? value > 0 ? 1 : this.lreluSlope : Math.max(this.lreluSlope * Math.abs(value), value);\n        }\n    }, {\n        key: \"rrelu\",\n        value: function rrelu(value, prime, neuron) {\n            return prime ? value > 0 ? 1 : neuron.rreluSlope : Math.max(neuron.rreluSlope, value);\n        }\n    }, {\n        key: \"lecuntanh\",\n        value: function lecuntanh(value, prime) {\n            return prime ? 1.15333 * Math.pow(NetMath.sech(2 / 3 * value), 2) : 1.7159 * NetMath.tanh(2 / 3 * value);\n        }\n    }, {\n        key: \"elu\",\n        value: function elu(value, prime, neuron) {\n            return prime ? value >= 0 ? 1 : NetMath.elu(value, false, neuron) + neuron.eluAlpha : value >= 0 ? value : neuron.eluAlpha * (Math.exp(value) - 1);\n        }\n\n        // Cost functions\n\n    }, {\n        key: \"crossentropy\",\n        value: function crossentropy(target, output) {\n            return output.map(function (value, vi) {\n                return target[vi] * Math.log(value + 1e-15) + (1 - target[vi]) * Math.log(1 + 1e-15 - value);\n            }).reduce(function (p, c) {\n                return p - c;\n            }, 0);\n        }\n    }, {\n        key: \"meansquarederror\",\n        value: function meansquarederror(calculated, desired) {\n            return calculated.map(function (output, index) {\n                return Math.pow(output - desired[index], 2);\n            }).reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0) / calculated.length;\n        }\n\n        // Weight updating functions\n\n    }, {\n        key: \"noadaptivelr\",\n        value: function noadaptivelr(value, deltaValue) {\n            return value + this.learningRate * deltaValue;\n        }\n    }, {\n        key: \"gain\",\n        value: function gain(value, deltaValue, neuron, weightI) {\n\n            var newVal = value + this.learningRate * deltaValue * (weightI == null ? neuron.biasGain : neuron.getWeightGain(weightI));\n\n            if (newVal <= 0 && value > 0 || newVal >= 0 && value < 0) {\n                if (weightI != null) {\n                    neuron.setWeightGain(weightI, Math.max(neuron.getWeightGain(weightI) * 0.95, 0.5));\n                } else {\n                    neuron.biasGain = Math.max(neuron.biasGain * 0.95, 0.5);\n                }\n            } else {\n                if (weightI != null) {\n                    neuron.setWeightGain(weightI, Math.min(neuron.getWeightGain(weightI) + 0.05, 5));\n                } else {\n                    neuron.biasGain = Math.min(neuron.biasGain + 0.05, 5);\n                }\n            }\n\n            return newVal;\n        }\n    }, {\n        key: \"adagrad\",\n        value: function adagrad(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.setWeightsCache(weightI, weightI + Math.pow(deltaValue, 2));\n            } else {\n                neuron.biasCache += Math.pow(deltaValue, 2);\n            }\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.getWeightsCache(weightI) : neuron.biasCache));\n        }\n    }, {\n        key: \"rmsprop\",\n        value: function rmsprop(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                // neuron.weightsCache[weightI] = this.rmsDecay * neuron.weightsCache[weightI] + (1 - this.rmsDecay) * Math.pow(deltaValue, 2)\n                neuron.setWeightsCache(weightI, this.rmsDecay * neuron.getWeightsCache(weightI) + (1 - this.rmsDecay) * Math.pow(deltaValue, 2));\n            } else {\n                neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);\n            }\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.getWeightsCache(weightI) : neuron.biasCache));\n        }\n    }, {\n        key: \"adam\",\n        value: function adam(value, deltaValue, neuron) {\n\n            neuron.m = 0.9 * neuron.m + (1 - 0.9) * deltaValue;\n            var mt = neuron.m / (1 - Math.pow(0.9, this.iterations + 1));\n\n            neuron.v = 0.999 * neuron.v + (1 - 0.999) * Math.pow(deltaValue, 2);\n            var vt = neuron.v / (1 - Math.pow(0.999, this.iterations + 1));\n\n            return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8);\n        }\n    }, {\n        key: \"adadelta\",\n        value: function adadelta(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.setWeightsCache(weightI, this.rho * neuron.getWeightsCache(weightI) + (1 - this.rho) * Math.pow(deltaValue, 2));\n                var newVal = value + Math.sqrt((neuron.getAdadeltaCache(weightI) + 1e-6) / (neuron.getWeightsCache(weightI) + 1e-6)) * deltaValue;\n                neuron.setAdadeltaCache(weightI, this.rho * neuron.getAdadeltaCache(weightI) + (1 - this.rho) * Math.pow(deltaValue, 2));\n                return newVal;\n            } else {\n                neuron.biasCache = this.rho * neuron.biasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var _newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6) / (neuron.biasCache + 1e-6)) * deltaValue;\n                neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return _newVal;\n            }\n        }\n\n        // Weights init\n\n    }, {\n        key: \"uniform\",\n        value: function uniform(size, _ref) {\n            var limit = _ref.limit;\n\n            return [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                return Math.random() * 2 * limit - limit;\n            });\n        }\n    }, {\n        key: \"gaussian\",\n        value: function gaussian(size, _ref2) {\n            var mean = _ref2.mean,\n                stdDeviation = _ref2.stdDeviation;\n\n            return [].concat(_toConsumableArray(new Array(size))).map(function () {\n                // Polar Box Muller\n                var x1 = void 0,\n                    x2 = void 0,\n                    r = void 0,\n                    y = void 0;\n\n                do {\n                    x1 = 2 * Math.random() - 1;\n                    x2 = 2 * Math.random() - 1;\n                    r = Math.pow(x1, 2) + Math.pow(x2, 2);\n                } while (r >= 1 || !r);\n\n                return mean + x1 * Math.sqrt(-2 * Math.log(r) / r) * stdDeviation;\n            });\n        }\n    }, {\n        key: \"xaviernormal\",\n        value: function xaviernormal(size, _ref3) {\n            var fanIn = _ref3.fanIn,\n                fanOut = _ref3.fanOut;\n\n            return fanOut || fanOut == 0 ? NetMath.gaussian(size, { mean: 0, stdDeviation: Math.sqrt(2 / (fanIn + fanOut)) }) : NetMath.lecunnormal(size, { fanIn: fanIn });\n        }\n    }, {\n        key: \"xavieruniform\",\n        value: function xavieruniform(size, _ref4) {\n            var fanIn = _ref4.fanIn,\n                fanOut = _ref4.fanOut;\n\n            return fanOut || fanOut == 0 ? NetMath.uniform(size, { limit: Math.sqrt(6 / (fanIn + fanOut)) }) : NetMath.lecununiform(size, { fanIn: fanIn });\n        }\n    }, {\n        key: \"lecunnormal\",\n        value: function lecunnormal(size, _ref5) {\n            var fanIn = _ref5.fanIn;\n\n            return NetMath.gaussian(size, { mean: 0, stdDeviation: Math.sqrt(1 / fanIn) });\n        }\n    }, {\n        key: \"lecununiform\",\n        value: function lecununiform(size, _ref6) {\n            var fanIn = _ref6.fanIn;\n\n            return NetMath.uniform(size, { limit: Math.sqrt(3 / fanIn) });\n        }\n\n        // Other\n\n    }, {\n        key: \"softmax\",\n        value: function softmax(values) {\n            var total = values.reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0);\n            return values.map(function (value) {\n                return value / total;\n            });\n        }\n    }, {\n        key: \"sech\",\n        value: function sech(value) {\n            return 2 * Math.exp(-value) / (1 + Math.exp(-2 * value));\n        }\n    }, {\n        key: \"standardDeviation\",\n        value: function standardDeviation(arr) {\n            var avg = arr.reduce(function (p, c) {\n                return p + c;\n            }) / arr.length;\n            var diffs = arr.map(function (v) {\n                return v - avg;\n            }).map(function (v) {\n                return Math.pow(v, 2);\n            });\n            return Math.sqrt(diffs.reduce(function (p, c) {\n                return p + c;\n            }) / diffs.length);\n        }\n    }, {\n        key: \"maxNorm\",\n        value: function maxNorm() {\n\n            if (this.maxNormTotal > this.maxNorm) {\n\n                var multiplier = this.maxNorm / (1e-18 + this.maxNormTotal);\n\n                this.layers.forEach(function (layer, li) {\n                    li && layer.neurons.forEach(function (neuron) {\n                        neuron.weights.forEach(function (w, wi) {\n                            return neuron.setWeight(wi, neuron.getWeight(wi) * multiplier);\n                        });\n                    });\n                });\n            }\n\n            this.maxNormTotal = 0;\n        }\n    }]);\n\n    return NetMath;\n}();\n\ntypeof window == \"undefined\" && (exports.NetMath = NetMath);\n\"use strict\";\n\nvar NetUtil = function () {\n    function NetUtil() {\n        _classCallCheck(this, NetUtil);\n    }\n\n    _createClass(NetUtil, null, [{\n        key: \"format\",\n        value: function format(value) {\n            var type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"string\";\n\n            switch (true) {\n\n                case type == \"string\" && typeof value == \"string\":\n                    value = value.replace(/(_|\\s)/g, \"\").toLowerCase();\n                    break;\n\n                case type == \"time\" && typeof value == \"number\":\n                    var date = new Date(value);\n                    var formatted = [];\n\n                    if (value < 1000) {\n                        formatted.push(date.getMilliseconds() + \"ms\");\n                    } else {\n\n                        if (value >= 3600000) formatted.push(date.getHours() + \"h\");\n                        if (value >= 60000) formatted.push(date.getMinutes() + \"m\");\n\n                        formatted.push(date.getSeconds() + \"s\");\n                    }\n\n                    value = formatted.join(\" \");\n                    break;\n            }\n\n            return value;\n        }\n    }, {\n        key: \"shuffle\",\n        value: function shuffle(arr) {\n            for (var i = arr.length; i; i--) {\n                var j = Math.floor(Math.random() * i);\n                var x = arr[i - 1];\n                arr[i - 1] = arr[j];\n                arr[j] = x;\n            }\n        }\n    }, {\n        key: \"addZeroPadding\",\n        value: function addZeroPadding(map, zP) {\n            var extraColumns = [].concat(_toConsumableArray(new Array(zP))).map(function (v) {\n                return 0;\n            });\n            map = map.map(function (row) {\n                return [].concat(_toConsumableArray(extraColumns), _toConsumableArray(row), _toConsumableArray(extraColumns));\n            });\n\n            var extraRows = [].concat(_toConsumableArray(new Array(zP))).map(function (r) {\n                return [].concat(_toConsumableArray(new Array(map.length + zP * 2))).map(function (x) {\n                    return 0;\n                });\n            });\n            return [].concat(_toConsumableArray(extraRows.slice(0)), _toConsumableArray(map), _toConsumableArray(extraRows.slice(0)));\n        }\n\n        // 2D Prefix Sum Array\n\n    }, {\n        key: \"build2DPSA\",\n        value: function build2DPSA(square) {\n\n            var l = square.length;\n            var map = [].concat(_toConsumableArray(new Array(l + 1))).map(function (row) {\n                return [].concat(_toConsumableArray(new Array(l + 1))).map(function (v) {\n                    return 0;\n                });\n            });\n\n            for (var ri = 1; ri <= l; ri++) {\n                for (var vi = 1; vi <= l; vi++) {\n                    map[ri][vi] = map[ri - 1][vi] + square[ri - 1][vi - 1];\n                }\n            }\n\n            for (var _ri = 1; _ri <= l; _ri++) {\n                for (var _vi = 1; _vi <= l; _vi++) {\n                    map[_ri][_vi] += map[_ri][_vi - 1];\n                }\n            }\n\n            return map;\n        }\n    }, {\n        key: \"sum2DPSA\",\n        value: function sum2DPSA(map, zP, fS) {\n\n            var l = map.length;\n            var sumMap = [].concat(_toConsumableArray(new Array(l - 1 - zP * 2))).map(function (row) {\n                return [].concat(_toConsumableArray(new Array(l - 1 - zP * 2))).map(function (v) {\n                    return 0;\n                });\n            });\n\n            for (var ri = l - zP; ri > zP + 1; ri--) {\n                for (var v = l - zP; v > zP + 1; v--) {\n\n                    var _l = v - fS;\n                    var t = ri - fS;\n\n                    sumMap[ri - Math.floor(fS)][v - Math.floor(fS)] = map[ri][v] - map[ri][_l] - map[t][v] + map[t][_l];\n                }\n            }\n\n            return sumMap;\n        }\n    }]);\n\n    return NetUtil;\n}();\n\ntypeof window == \"undefined\" && (exports.NetUtil = NetUtil);\n\"use strict\";\n\nvar Network = function () {\n    function Network() {\n        var _ref7 = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n            learningRate = _ref7.learningRate,\n            _ref7$layers = _ref7.layers,\n            layers = _ref7$layers === undefined ? [] : _ref7$layers,\n            _ref7$adaptiveLR = _ref7.adaptiveLR,\n            adaptiveLR = _ref7$adaptiveLR === undefined ? \"noadaptivelr\" : _ref7$adaptiveLR,\n            _ref7$activation = _ref7.activation,\n            activation = _ref7$activation === undefined ? \"sigmoid\" : _ref7$activation,\n            _ref7$cost = _ref7.cost,\n            cost = _ref7$cost === undefined ? \"meansquarederror\" : _ref7$cost,\n            rmsDecay = _ref7.rmsDecay,\n            rho = _ref7.rho,\n            lreluSlope = _ref7.lreluSlope,\n            eluAlpha = _ref7.eluAlpha,\n            _ref7$dropout = _ref7.dropout,\n            dropout = _ref7$dropout === undefined ? 1 : _ref7$dropout,\n            _ref7$l = _ref7.l2,\n            l2 = _ref7$l === undefined ? true : _ref7$l,\n            _ref7$l2 = _ref7.l1,\n            l1 = _ref7$l2 === undefined ? true : _ref7$l2,\n            maxNorm = _ref7.maxNorm,\n            weightsConfig = _ref7.weightsConfig;\n\n        _classCallCheck(this, Network);\n\n        this.state = \"not-defined\";\n        this.layers = [];\n        this.epochs = 0;\n        this.iterations = 0;\n        this.dropout = dropout == false ? 1 : dropout;\n        this.error = 0;\n        activation = NetUtil.format(activation);\n        adaptiveLR = NetUtil.format(adaptiveLR);\n        cost = NetUtil.format(cost);\n\n        if (learningRate != null) {\n            this.learningRate = learningRate;\n        }\n\n        if (l2) {\n            this.l2 = typeof l2 == \"boolean\" ? 0.001 : l2;\n            this.l2Error = 0;\n        }\n\n        if (l1) {\n            this.l1 = typeof l1 == \"boolean\" ? 0.005 : l1;\n            this.l1Error = 0;\n        }\n\n        if (maxNorm) {\n            this.maxNorm = typeof maxNorm == \"boolean\" && maxNorm ? 1000 : maxNorm;\n            this.maxNormTotal = 0;\n        }\n\n        // Activation function / Learning Rate\n        switch (adaptiveLR) {\n\n            case \"rmsprop\":\n                this.learningRate = this.learningRate == undefined ? 0.001 : this.learningRate;\n                break;\n\n            case \"adam\":\n                this.learningRate = this.learningRate == undefined ? 0.01 : this.learningRate;\n                break;\n\n            case \"adadelta\":\n                this.rho = rho == null ? 0.95 : rho;\n                break;\n\n            default:\n\n                if (this.learningRate == undefined) {\n\n                    switch (activation) {\n\n                        case \"relu\":\n                        case \"lrelu\":\n                        case \"rrelu\":\n                        case \"elu\":\n                            this.learningRate = 0.01;\n                            break;\n\n                        case \"tanh\":\n                        case \"lecuntanh\":\n                            this.learningRate = 0.001;\n                            break;\n\n                        default:\n                            this.learningRate = 0.2;\n                    }\n                }\n        }\n\n        this.adaptiveLR = [false, null, undefined].includes(adaptiveLR) ? \"noadaptivelr\" : adaptiveLR;\n        this.weightUpdateFn = NetMath[this.adaptiveLR];\n        this.activation = typeof activation == \"function\" ? activation : NetMath[activation].bind(this);\n        this.activationConfig = activation;\n        this.cost = typeof cost == \"function\" ? cost : NetMath[cost];\n\n        if (this.adaptiveLR == \"rmsprop\") {\n            this.rmsDecay = rmsDecay == undefined ? 0.99 : rmsDecay;\n        }\n\n        if (activation == \"lrelu\") {\n            this.lreluSlope = lreluSlope == undefined ? -0.0005 : lreluSlope;\n        } else if (activation == \"elu\") {\n            this.eluAlpha = eluAlpha == undefined ? 1 : eluAlpha;\n        }\n\n        // Weights distributiom\n        this.weightsConfig = { distribution: \"xavieruniform\" };\n\n        if (weightsConfig != undefined && weightsConfig.distribution) {\n            this.weightsConfig.distribution = NetUtil.format(weightsConfig.distribution);\n        }\n\n        if (this.weightsConfig.distribution == \"uniform\") {\n            this.weightsConfig.limit = weightsConfig && weightsConfig.limit != undefined ? weightsConfig.limit : 0.1;\n        } else if (this.weightsConfig.distribution == \"gaussian\") {\n            this.weightsConfig.mean = weightsConfig.mean || 0;\n            this.weightsConfig.stdDeviation = weightsConfig.stdDeviation || 0.05;\n        }\n\n        if (typeof this.weightsConfig.distribution == \"function\") {\n            this.weightsInitFn = this.weightsConfig.distribution;\n        } else {\n            this.weightsInitFn = NetMath[this.weightsConfig.distribution];\n        }\n\n        // Status\n        if (layers.length) {\n\n            switch (true) {\n\n                case layers.every(function (item) {\n                    return Number.isInteger(item);\n                }):\n                    this.layers = layers.map(function (size) {\n                        return new Layer(size);\n                    });\n                    this.state = \"constructed\";\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item instanceof Layer || item instanceof FCLayer;\n                }):\n                    this.state = \"constructed\";\n                    this.layers = layers;\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item === Layer || item === FCLayer;\n                }):\n                    this.state = \"defined\";\n                    this.definedLayers = layers;\n                    break;\n\n                default:\n                    throw new Error(\"There was an error constructing from the layers given.\");\n            }\n        }\n    }\n\n    _createClass(Network, [{\n        key: \"initLayers\",\n        value: function initLayers(input, expected) {\n            var _this5 = this;\n\n            switch (this.state) {\n\n                case \"initialised\":\n                    return;\n\n                case \"defined\":\n                    this.layers = this.definedLayers.map(function (layer, li) {\n\n                        if (!li) return new layer(input);\n\n                        if (li == _this5.definedLayers.length - 1) return new layer(expected);\n\n                        var hidden = _this5.definedLayers.length - 2;\n                        var size = input / expected > 5 ? expected + (expected + Math.abs(input - expected) / 4) * (hidden - li + 1) / (hidden / 2) : input >= expected ? input + expected * (hidden - li) / (hidden / 2) : expected + input * (hidden - li) / (hidden / 2);\n\n                        return new layer(Math.max(Math.round(size), 0));\n                    });\n                    break;\n\n                case \"not-defined\":\n                    this.layers[0] = new FCLayer(input);\n                    this.layers[1] = new FCLayer(Math.ceil(input / expected > 5 ? expected + Math.abs(input - expected) / 4 : input + expected));\n                    this.layers[2] = new FCLayer(Math.ceil(expected));\n                    break;\n            }\n\n            this.layers.forEach(this.joinLayer.bind(this));\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"joinLayer\",\n        value: function joinLayer(layer, layerIndex) {\n\n            layer.net = this;\n            layer.activation = this.activation;\n\n            layer.weightsConfig = {};\n            Object.assign(layer.weightsConfig, this.weightsConfig);\n\n            if (layerIndex) {\n                layer.weightsConfig.fanIn = this.layers[layerIndex - 1].size;\n                this.layers[layerIndex - 1].weightsConfig.fanOut = layer.size;\n                this.layers[layerIndex - 1].assignNext(layer);\n                layer.assignPrev(this.layers[layerIndex - 1]);\n            }\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n\n            if (this.state != \"initialised\") {\n                throw new Error(\"The network layers have not been initialised.\");\n            }\n\n            if (data === undefined) {\n                throw new Error(\"No data passed to Network.forward()\");\n            }\n\n            if (data.length != this.layers[0].neurons.length) {\n                console.warn(\"Input data length did not match input layer neurons count.\");\n            }\n\n            this.layers[0].neurons.forEach(function (neuron, ni) {\n                return neuron.activation = data[ni];\n            });\n            this.layers.forEach(function (layer, li) {\n                return li && layer.forward(data);\n            });\n            return this.layers[this.layers.length - 1].neurons.map(function (n) {\n                return n.activation;\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n\n            if (expected === undefined) {\n                throw new Error(\"No data passed to Network.backward()\");\n            }\n\n            if (expected.length != this.layers[this.layers.length - 1].neurons.length) {\n                console.warn(\"Expected data length did not match output layer neurons count.\", expected);\n            }\n\n            this.layers[this.layers.length - 1].backward(expected);\n\n            for (var layerIndex = this.layers.length - 2; layerIndex > 0; layerIndex--) {\n                this.layers[layerIndex].backward();\n            }\n        }\n    }, {\n        key: \"train\",\n        value: function train(dataSet) {\n            var _this6 = this;\n\n            var _ref8 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref8$epochs = _ref8.epochs,\n                epochs = _ref8$epochs === undefined ? 1 : _ref8$epochs,\n                callback = _ref8.callback,\n                _ref8$log = _ref8.log,\n                log = _ref8$log === undefined ? true : _ref8$log,\n                _ref8$miniBatchSize = _ref8.miniBatchSize,\n                miniBatchSize = _ref8$miniBatchSize === undefined ? 1 : _ref8$miniBatchSize,\n                _ref8$shuffle = _ref8.shuffle,\n                shuffle = _ref8$shuffle === undefined ? false : _ref8$shuffle;\n\n            this.miniBatchSize = typeof miniBatchSize == \"boolean\" && miniBatchSize ? dataSet[0].expected.length : miniBatchSize;\n\n            if (shuffle) {\n                NetUtil.shuffle(dataSet);\n            }\n\n            if (log) {\n                console.log(\"Training started. Epochs: \" + epochs + \" Batch Size: \" + this.miniBatchSize);\n            }\n\n            return new Promise(function (resolve, reject) {\n\n                if (dataSet === undefined || dataSet === null) {\n                    return void reject(\"No data provided\");\n                }\n\n                if (_this6.state != \"initialised\") {\n                    _this6.initLayers(dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length);\n                }\n\n                _this6.layers.forEach(function (layer) {\n                    return layer.state = \"training\";\n                });\n\n                var iterationIndex = 0;\n                var epochsCounter = 0;\n                var startTime = Date.now();\n\n                var doEpoch = function doEpoch() {\n                    _this6.epochs++;\n                    _this6.error = 0;\n                    iterationIndex = 0;\n\n                    if (_this6.l2Error != undefined) _this6.l2Error = 0;\n                    if (_this6.l1Error != undefined) _this6.l1Error = 0;\n\n                    doIteration();\n                };\n\n                var doIteration = function doIteration() {\n\n                    if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || !dataSet[iterationIndex].hasOwnProperty(\"expected\") && !dataSet[iterationIndex].hasOwnProperty(\"output\")) {\n                        return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\");\n                    }\n\n                    var input = dataSet[iterationIndex].input;\n                    var output = _this6.forward(input);\n                    var target = dataSet[iterationIndex].expected || dataSet[iterationIndex].output;\n\n                    _this6.backward(target);\n\n                    if (++iterationIndex % _this6.miniBatchSize == 0) {\n                        _this6.applyDeltaWeights();\n                        _this6.resetDeltaWeights();\n                    } else if (iterationIndex >= dataSet.length) {\n                        _this6.applyDeltaWeights();\n                    }\n\n                    var iterationError = _this6.cost(target, output);\n                    var elapsed = Date.now() - startTime;\n                    _this6.error += iterationError;\n                    _this6.iterations++;\n\n                    if (typeof callback == \"function\") {\n                        callback({\n                            iterations: _this6.iterations,\n                            error: iterationError,\n                            elapsed: elapsed, input: input\n                        });\n                    }\n\n                    if (iterationIndex < dataSet.length) {\n                        setTimeout(doIteration.bind(_this6), 0);\n                    } else {\n                        epochsCounter++;\n\n                        if (log) {\n                            console.log(\"Epoch: \" + _this6.epochs + \" Error: \" + _this6.error / iterationIndex + (_this6.l2 == undefined ? \"\" : \" L2 Error: \" + _this6.l2Error / iterationIndex), \"\\nElapsed: \" + NetUtil.format(elapsed, \"time\") + \" Average Duration: \" + NetUtil.format(elapsed / epochsCounter, \"time\"));\n                        }\n\n                        if (epochsCounter < epochs) {\n                            doEpoch();\n                        } else {\n                            _this6.layers.forEach(function (layer) {\n                                return layer.state = \"initialised\";\n                            });\n\n                            if (log) {\n                                console.log(\"Training finished. Total time: \" + NetUtil.format(elapsed, \"time\") + \"  Average iteration time: \" + NetUtil.format(elapsed / iterationIndex, \"time\"));\n                            }\n                            resolve();\n                        }\n                    }\n                };\n\n                _this6.resetDeltaWeights();\n                doEpoch();\n            });\n        }\n    }, {\n        key: \"test\",\n        value: function test(testSet) {\n            var _this7 = this;\n\n            var _ref9 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref9$log = _ref9.log,\n                log = _ref9$log === undefined ? true : _ref9$log,\n                callback = _ref9.callback;\n\n            return new Promise(function (resolve, reject) {\n\n                if (testSet === undefined || testSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                var totalError = 0;\n                var iterationIndex = 0;\n                var startTime = Date.now();\n\n                var testInput = function testInput() {\n\n                    var input = testSet[iterationIndex].input;\n                    var output = _this7.forward(input);\n                    var target = testSet[iterationIndex].expected || testSet[iterationIndex].output;\n                    var elapsed = Date.now() - startTime;\n\n                    var iterationError = _this7.cost(target, output);\n                    totalError += iterationError;\n                    iterationIndex++;\n\n                    if (log) {\n                        console.log(\"Testing iteration\", iterationIndex, iterationError);\n                    }\n\n                    if (typeof callback == \"function\") {\n                        callback({\n                            iterations: iterationIndex,\n                            error: iterationError,\n                            elapsed: elapsed, input: input\n                        });\n                    }\n\n                    if (iterationIndex < testSet.length) {\n                        setTimeout(testInput.bind(_this7), 0);\n                    } else {\n\n                        if (log) {\n                            console.log(\"Testing finished. Total time: \" + NetUtil.format(elapsed, \"time\") + \"  Average iteration time: \" + NetUtil.format(elapsed / iterationIndex, \"time\"));\n                        }\n\n                        resolve(totalError / testSet.length);\n                    }\n                };\n                testInput();\n            });\n        }\n    }, {\n        key: \"resetDeltaWeights\",\n        value: function resetDeltaWeights() {\n            this.layers.forEach(function (layer, li) {\n                return li && layer.resetDeltaWeights();\n            });\n        }\n    }, {\n        key: \"applyDeltaWeights\",\n        value: function applyDeltaWeights() {\n\n            this.layers.forEach(function (layer, li) {\n                return li && layer.applyDeltaWeights();\n            });\n\n            if (this.maxNorm != undefined) {\n                this.maxNormTotal = Math.sqrt(this.maxNormTotal);\n                NetMath.maxNorm.bind(this)();\n            }\n        }\n    }, {\n        key: \"toJSON\",\n        value: function toJSON() {\n            return {\n                layers: this.layers.map(function (layer) {\n                    return {\n                        neurons: layer.neurons.map(function (neuron) {\n                            return {\n                                bias: neuron.bias,\n                                weights: neuron.weights\n                            };\n                        })\n                    };\n                })\n            };\n        }\n    }, {\n        key: \"fromJSON\",\n        value: function fromJSON(data) {\n\n            if (data === undefined || data === null) {\n                throw new Error(\"No JSON data given to import.\");\n            }\n\n            this.layers = data.layers.map(function (layer) {\n                return new FCLayer(layer.neurons.length, layer.neurons);\n            });\n            this.state = \"constructed\";\n            this.initLayers();\n        }\n    }]);\n\n    return Network;\n}();\n\ntypeof window == \"undefined\" && (exports.Network = Network);\n\"use strict\";\n\nvar Neuron = function () {\n    function Neuron(importedData) {\n        _classCallCheck(this, Neuron);\n\n        if (importedData) {\n            this.imported = true;\n            this.weights = importedData.weights || [];\n            this.bias = importedData.bias;\n        }\n    }\n\n    _createClass(Neuron, [{\n        key: \"init\",\n        value: function init(size) {\n            var _this8 = this;\n\n            var _ref10 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                adaptiveLR = _ref10.adaptiveLR,\n                activationConfig = _ref10.activationConfig,\n                eluAlpha = _ref10.eluAlpha;\n\n            this.deltaWeights = this.weights.map(function (v) {\n                return 0;\n            });\n\n            switch (adaptiveLR) {\n\n                case \"gain\":\n                    this.biasGain = 1;\n                    this.weightGains = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 1;\n                    });\n                    this.getWeightGain = function (i) {\n                        return _this8.weightGains[i];\n                    };\n                    this.setWeightGain = function (i, v) {\n                        return _this8.weightGains[i] = v;\n                    };\n                    break;\n\n                case \"adagrad\":\n                case \"rmsprop\":\n                case \"adadelta\":\n                    this.biasCache = 0;\n                    this.weightsCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 0;\n                    });\n                    this.getWeightsCache = function (i) {\n                        return _this8.weightsCache[i];\n                    };\n                    this.setWeightsCache = function (i, v) {\n                        return _this8.weightsCache[i] = v;\n                    };\n\n                    if (adaptiveLR == \"adadelta\") {\n                        this.adadeltaBiasCache = 0;\n                        this.adadeltaCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                            return 0;\n                        });\n                        this.getAdadeltaCache = function (i) {\n                            return _this8.adadeltaCache[i];\n                        };\n                        this.setAdadeltaCache = function (i, v) {\n                            return _this8.adadeltaCache[i] = v;\n                        };\n                    }\n                    break;\n\n                case \"adam\":\n                    this.m = 0;\n                    this.v = 0;\n                    break;\n            }\n\n            if (activationConfig == \"rrelu\") {\n                this.rreluSlope = Math.random() * 0.001;\n            } else if (activationConfig == \"elu\") {\n                this.eluAlpha = eluAlpha;\n            }\n        }\n    }, {\n        key: \"getWeight\",\n        value: function getWeight(i) {\n            return this.weights[i];\n        }\n    }, {\n        key: \"setWeight\",\n        value: function setWeight(i, v) {\n            this.weights[i] = v;\n        }\n    }, {\n        key: \"getDeltaWeight\",\n        value: function getDeltaWeight(i) {\n            return this.deltaWeights[i];\n        }\n    }, {\n        key: \"setDeltaWeight\",\n        value: function setDeltaWeight(i, v) {\n            this.deltaWeights[i] = v;\n        }\n    }]);\n\n    return Neuron;\n}();\n\ntypeof window == \"undefined\" && (exports.Neuron = Neuron);\n//# sourceMappingURL=Network.concat.js.map\n//# sourceMappingURL=Network.min.js.map\n"]}