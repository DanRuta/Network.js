{"version":3,"sources":["Network.min.js"],"names":["_toConsumableArray","arr","Array","isArray","i","arr2","length","from","_classCallCheck","instance","Constructor","TypeError","_createClass","defineProperties","target","props","descriptor","enumerable","configurable","writable","Object","defineProperty","key","protoProps","staticProps","prototype","Layer","size","importedData","this","neurons","concat","map","n","ni","Neuron","undefined","state","value","layer","nextLayer","_this","prevLayer","forEach","neuron","imported","weights","weightsInitFn","weightsConfig","bias","Math","random","init","adaptiveLR","activationConfig","eluAlpha","data","_this2","dropped","dropout","activation","sum","pNeuron","pni","expected","_this3","error","deltaBias","derivative","reduce","p","c","weight","wi","deltaWeights","l2","l1","net","miniBatchSize","window","global","NetMath","prime","val","exp","pow","max","lreluSlope","abs","rreluSlope","sech","tanh","elu","output","vi","log","calculated","desired","index","prev","curr","deltaValue","learningRate","weightI","newVal","biasGain","weightGains","min","weightsCache","biasCache","sqrt","rmsDecay","m","mt","iterations","v","vt","rho","adadeltaCache","_newVal","adadeltaBiasCache","_ref","limit","_ref2","mean","stdDeviation","x1","x2","r","_ref3","fanIn","fanOut","gaussian","lecunnormal","_ref4","uniform","lecununiform","_ref5","_ref6","values","total","avg","diffs","maxNormTotal","maxNorm","multiplier","layers","li","w","Network","_ref7","arguments","_ref7$layers","_ref7$adaptiveLR","_ref7$activation","_ref7$cost","cost","_ref7$dropout","epochs","format","l2Error","l1Error","includes","weightUpdateFn","bind","distribution","every","item","Number","isInteger","initLayers","definedLayers","Error","input","_this4","hidden","round","ceil","joinLayer","layerIndex","assign","assignNext","assignPrev","console","warn","forward","backward","dataSet","_this5","_ref8","_ref8$epochs","callback","_ref8$log","_ref8$miniBatchSize","Promise","resolve","reject","iterationIndex","epochsCounter","startTime","Date","now","doEpoch","doIteration","hasOwnProperty","applyDeltaWeights","resetDeltaWeights","iterationError","elapsed","setTimeout","testSet","_this6","_ref9$log","totalError","testInput","dw","_this7","dwi","type","replace","toLowerCase","date","formatted","push","getMilliseconds","getHours","getMinutes","getSeconds","join","_ref10"],"mappings":"AAAA,aAIA,SAASA,mBAAmBC,GAAO,GAAIC,MAAMC,QAAQF,GAAM,CAAE,IAAK,IAAIG,EAAI,EAAGC,EAAOH,MAAMD,EAAIK,QAASF,EAAIH,EAAIK,OAAQF,IAAOC,EAAKD,GAAKH,EAAIG,GAAM,OAAOC,EAAe,OAAOH,MAAMK,KAAKN,GAE1L,SAASO,gBAAgBC,EAAUC,GAAe,KAAMD,aAAoBC,GAAgB,MAAM,IAAIC,UAAU,qCAJhH,IAAIC,aAAe,WAAc,SAASC,EAAiBC,EAAQC,GAAS,IAAK,IAAIX,EAAI,EAAGA,EAAIW,EAAMT,OAAQF,IAAK,CAAE,IAAIY,EAAaD,EAAMX,GAAIY,EAAWC,WAAaD,EAAWC,aAAc,EAAOD,EAAWE,cAAe,EAAU,UAAWF,IAAYA,EAAWG,UAAW,GAAMC,OAAOC,eAAeP,EAAQE,EAAWM,IAAKN,IAAiB,OAAO,SAAUN,EAAaa,EAAYC,GAAiJ,OAA9HD,GAAYV,EAAiBH,EAAYe,UAAWF,GAAiBC,GAAaX,EAAiBH,EAAac,GAAqBd,MAM5hBgB,MAAQ,WACR,SAASA,EAAMC,EAAMC,GACjBpB,gBAAgBqB,KAAMH,GAEtBG,KAAKF,KAAOA,EACZE,KAAKC,WAAaC,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUC,EAAGC,GAC3E,OAAO,IAAIC,OAAOP,EAAeA,EAAaM,QAAME,KAExDP,KAAKQ,MAAQ,kBA+EjB,OA5EAzB,aAAac,IACTJ,IAAK,aACLgB,MAAO,SAAoBC,GACvBV,KAAKW,UAAYD,KAGrBjB,IAAK,aACLgB,MAAO,SAAoBC,GACvB,IAAIE,EAAQZ,KAEZA,KAAKa,UAAYH,EACjBV,KAAKC,QAAQa,QAAQ,SAAUC,GAEtBA,EAAOC,WACRD,EAAOE,QAAUL,EAAMM,cAAcR,EAAMZ,KAAMc,EAAMO,eACvDJ,EAAOK,KAAuB,GAAhBC,KAAKC,SAAiB,IAGxCP,EAAOQ,KAAKb,EAAMZ,MACd0B,WAAYZ,EAAMY,WAClBC,iBAAkBb,EAAMa,iBACxBC,SAAUd,EAAMc,aAGxB1B,KAAKQ,MAAQ,iBAGjBf,IAAK,UACLgB,MAAO,SAAiBkB,GACpB,IAAIC,EAAS5B,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAEf,YAAhBuB,EAAOpB,QAAwBO,EAAOc,QAAUR,KAAKC,SAAWM,EAAOE,SACvEf,EAAOgB,WAAa,GAEpBhB,EAAOiB,IAAMjB,EAAOK,KACpBQ,EAAOf,UAAUZ,QAAQa,QAAQ,SAAUmB,EAASC,GAChD,OAAOnB,EAAOiB,KAAOC,EAAQF,WAAahB,EAAOE,QAAQiB,KAE7DnB,EAAOgB,WAAaH,EAAOG,WAAWhB,EAAOiB,KAAK,EAAOjB,IAA4B,EAAjBa,EAAOE,eAKvFrC,IAAK,WACLgB,MAAO,SAAkB0B,GACrB,IAAIC,EAASpC,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAE/BU,EAAOc,SACPd,EAAOsB,MAAQ,EACftB,EAAOuB,UAAY,SAEK,IAAbH,EACPpB,EAAOsB,MAAQF,EAAS9B,GAAMU,EAAOgB,YAErChB,EAAOwB,WAAaH,EAAOL,WAAWhB,EAAOiB,KAAK,EAAMjB,GACxDA,EAAOsB,MAAQtB,EAAOwB,WAAaH,EAAOzB,UAAUV,QAAQE,IAAI,SAAUC,GACtE,OAAOA,EAAEiC,OAAyB,EAAhBjC,EAAEa,QAAQZ,MAC7BmC,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,IAGP3B,EAAOE,QAAQH,QAAQ,SAAU6B,EAAQC,GACrC7B,EAAO8B,aAAaD,IAAO7B,EAAOsB,MAAQD,EAAOvB,UAAUZ,QAAQ2C,GAAIb,YAAc,IAAMK,EAAOU,IAAM,IAAMV,EAAOW,IAAM,IAAMX,EAAOY,IAAIC,cAAgBlC,EAAO8B,aAAaD,MAGpL7B,EAAOuB,UAAYvB,EAAOsB,aAMnCxC,KAGM,oBAAVqD,SAA0BC,OAAOtD,MAAQA,OAGhD,IAAIuD,QAAU,WACV,SAASA,IACLzE,gBAAgBqB,KAAMoD,GAwQ1B,OArQArE,aAAaqE,EAAS,OAClB3D,IAAK,UAILgB,MAAO,SAAiBA,EAAO4C,GAC3B,IAAIC,EAAM,GAAK,EAAIjC,KAAKkC,KAAK9C,IAC7B,OAAO4C,EAAQC,GAAO,EAAIA,GAAOA,KAGrC7D,IAAK,OACLgB,MAAO,SAAcA,EAAO4C,GACxB,IAAIE,EAAMlC,KAAKkC,IAAI,EAAI9C,GACvB,OAAO4C,EAAQ,EAAIhC,KAAKmC,IAAInC,KAAKkC,IAAI9C,GAASY,KAAKkC,KAAK9C,GAAQ,IAAM,OAAS8C,EAAM,IAAMA,EAAM,IAAM,SAG3G9D,IAAK,OACLgB,MAAO,SAAcA,EAAO4C,GACxB,OAAOA,EAAQ5C,EAAQ,EAAI,EAAI,EAAIY,KAAKoC,IAAIhD,EAAO,MAGvDhB,IAAK,QACLgB,MAAO,SAAeA,EAAO4C,GACzB,OAAOA,EAAQ5C,EAAQ,EAAI,EAAIT,KAAK0D,WAAarC,KAAKoC,IAAIzD,KAAK0D,WAAarC,KAAKsC,IAAIlD,GAAQA,MAGjGhB,IAAK,QACLgB,MAAO,SAAeA,EAAO4C,EAAOtC,GAChC,OAAOsC,EAAQ5C,EAAQ,EAAI,EAAIM,EAAO6C,WAAavC,KAAKoC,IAAI1C,EAAO6C,WAAYnD,MAGnFhB,IAAK,YACLgB,MAAO,SAAmBA,EAAO4C,GAC7B,OAAOA,EAAQ,QAAUhC,KAAKmC,IAAIJ,EAAQS,KAAK,EAAI,EAAIpD,GAAQ,GAAK,OAAS2C,EAAQU,KAAK,EAAI,EAAIrD,MAGtGhB,IAAK,MACLgB,MAAO,SAAaA,EAAO4C,EAAOtC,GAC9B,OAAOsC,EAAQ5C,GAAS,EAAI,EAAI2C,EAAQW,IAAItD,GAAO,EAAOM,GAAUA,EAAOW,SAAWjB,GAAS,EAAIA,EAAQM,EAAOW,UAAYL,KAAKkC,IAAI9C,GAAS,MAMpJhB,IAAK,eACLgB,MAAO,SAAsBxB,EAAQ+E,GACjC,OAAOA,EAAO7D,IAAI,SAAUM,EAAOwD,GAC/B,OAAOhF,EAAOgF,GAAM5C,KAAK6C,IAAIzD,EAAQ,QAAU,EAAIxB,EAAOgF,IAAO5C,KAAK6C,IAAI,EAAI,MAAQzD,KACvF+B,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,MAGPjD,IAAK,mBACLgB,MAAO,SAA0B0D,EAAYC,GACzC,OAAOD,EAAWhE,IAAI,SAAU6D,EAAQK,GACpC,OAAOhD,KAAKmC,IAAIQ,EAASI,EAAQC,GAAQ,KAC1C7B,OAAO,SAAU8B,EAAMC,GACtB,OAAOD,EAAOC,GACf,GAAKJ,EAAW1F,UAMvBgB,IAAK,eACLgB,MAAO,SAAsBA,EAAO+D,GAChC,OAAO/D,EAAQT,KAAKyE,aAAeD,KAGvC/E,IAAK,OACLgB,MAAO,SAAcA,EAAO+D,EAAYzD,EAAQ2D,GAE5C,IAAIC,EAASlE,EAAQT,KAAKyE,aAAeD,GAAyB,MAAXE,EAAkB3D,EAAO6D,SAAW7D,EAAO8D,YAAYH,IAgB9G,OAdIC,GAAU,GAAKlE,EAAQ,GAAKkE,GAAU,GAAKlE,EAAQ,EACpC,MAAXiE,EACA3D,EAAO8D,YAAYH,GAAWrD,KAAKoC,IAAkC,IAA9B1C,EAAO8D,YAAYH,GAAiB,IAE3E3D,EAAO6D,SAAWvD,KAAKoC,IAAsB,IAAlB1C,EAAO6D,SAAiB,IAGxC,MAAXF,EACA3D,EAAO8D,YAAYH,GAAWrD,KAAKyD,IAAI/D,EAAO8D,YAAYH,GAAW,IAAM,GAE3E3D,EAAO6D,SAAWvD,KAAKyD,IAAI/D,EAAO6D,SAAW,IAAM,GAIpDD,KAGXlF,IAAK,UACLgB,MAAO,SAAiBA,EAAO+D,EAAYzD,EAAQ2D,GAQ/C,OANe,MAAXA,EACA3D,EAAOgE,aAAaL,IAAYrD,KAAKmC,IAAIgB,EAAY,GAErDzD,EAAOiE,WAAa3D,KAAKmC,IAAIgB,EAAY,GAGtC/D,EAAQT,KAAKyE,aAAeD,GAAc,KAAOnD,KAAK4D,KAAgB,MAAXP,EAAkB3D,EAAOgE,aAAaL,GAAW3D,EAAOiE,eAG9HvF,IAAK,UACLgB,MAAO,SAAiBA,EAAO+D,EAAYzD,EAAQ2D,GAQ/C,OANe,MAAXA,EACA3D,EAAOgE,aAAaL,GAAW1E,KAAKkF,SAAWnE,EAAOgE,aAAaL,IAAY,EAAI1E,KAAKkF,UAAY7D,KAAKmC,IAAIgB,EAAY,GAEzHzD,EAAOiE,UAAYhF,KAAKkF,SAAWnE,EAAOiE,WAAa,EAAIhF,KAAKkF,UAAY7D,KAAKmC,IAAIgB,EAAY,GAG9F/D,EAAQT,KAAKyE,aAAeD,GAAc,KAAOnD,KAAK4D,KAAgB,MAAXP,EAAkB3D,EAAOgE,aAAaL,GAAW3D,EAAOiE,eAG9HvF,IAAK,OACLgB,MAAO,SAAcA,EAAO+D,EAAYzD,GAEpCA,EAAOoE,EAAI,GAAMpE,EAAOoE,GAAK,EAAI,IAAOX,EACxC,IAAIY,EAAKrE,EAAOoE,GAAK,EAAI9D,KAAKmC,IAAI,GAAKxD,KAAKqF,WAAa,IAEzDtE,EAAOuE,EAAI,KAAQvE,EAAOuE,GAAK,EAAI,MAASjE,KAAKmC,IAAIgB,EAAY,GACjE,IAAIe,EAAKxE,EAAOuE,GAAK,EAAIjE,KAAKmC,IAAI,KAAOxD,KAAKqF,WAAa,IAE3D,OAAO5E,EAAQT,KAAKyE,aAAeW,GAAM/D,KAAK4D,KAAKM,GAAM,SAG7D9F,IAAK,WACLgB,MAAO,SAAkBA,EAAO+D,EAAYzD,EAAQ2D,GAEhD,GAAe,MAAXA,EAAiB,CACjB3D,EAAOgE,aAAaL,GAAW1E,KAAKwF,IAAMzE,EAAOgE,aAAaL,IAAY,EAAI1E,KAAKwF,KAAOnE,KAAKmC,IAAIgB,EAAY,GAC/G,IAAIG,EAASlE,EAAQY,KAAK4D,MAAMlE,EAAO0E,cAAcf,GAAW,OAAS3D,EAAOgE,aAAaL,GAAW,OAASF,EAEjH,OADAzD,EAAO0E,cAAcf,GAAW1E,KAAKwF,IAAMzE,EAAO0E,cAAcf,IAAY,EAAI1E,KAAKwF,KAAOnE,KAAKmC,IAAIgB,EAAY,GAC1GG,EAEP5D,EAAOiE,UAAYhF,KAAKwF,IAAMzE,EAAOiE,WAAa,EAAIhF,KAAKwF,KAAOnE,KAAKmC,IAAIgB,EAAY,GACvF,IAAIkB,EAAUjF,EAAQY,KAAK4D,MAAMlE,EAAO4E,kBAAoB,OAAS5E,EAAOiE,UAAY,OAASR,EAEjG,OADAzD,EAAO4E,kBAAoB3F,KAAKwF,IAAMzE,EAAO4E,mBAAqB,EAAI3F,KAAKwF,KAAOnE,KAAKmC,IAAIgB,EAAY,GAChGkB,KAOfjG,IAAK,UACLgB,MAAO,SAAiBX,EAAM8F,GAC1B,IAAIC,EAAQD,EAAKC,MAEjB,SAAU3F,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUmF,GAChE,OAAuB,EAAhBjE,KAAKC,SAAeuE,EAAQA,OAI3CpG,IAAK,WACLgB,MAAO,SAAkBX,EAAMgG,GAC3B,IAAIC,EAAOD,EAAMC,KACbC,EAAeF,EAAME,aAEzB,SAAU9F,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,WAEtD,IAAI8F,OAAK,EACLC,OAAK,EACLC,OAAI,EAGR,GACIF,EAAK,EAAI5E,KAAKC,SAAW,EACzB4E,EAAK,EAAI7E,KAAKC,SAAW,EACzB6E,EAAI9E,KAAKmC,IAAIyC,EAAI,GAAK5E,KAAKmC,IAAI0C,EAAI,SAC9BC,GAAK,IAAMA,GAEpB,OAAOJ,EAAOE,EAAK5E,KAAK4D,MAAM,EAAI5D,KAAK6C,IAAIiC,GAAKA,GAAKH,OAI7DvG,IAAK,eACLgB,MAAO,SAAsBX,EAAMsG,GAC/B,IAAIC,EAAQD,EAAMC,MACdC,EAASF,EAAME,OAEnB,OAAOA,GAAoB,GAAVA,EAAclD,EAAQmD,SAASzG,GAAQiG,KAAM,EAAGC,aAAc3E,KAAK4D,KAAK,GAAKoB,EAAQC,MAAclD,EAAQoD,YAAY1G,GAAQuG,MAAOA,OAG3J5G,IAAK,gBACLgB,MAAO,SAAuBX,EAAM2G,GAChC,IAAIJ,EAAQI,EAAMJ,MACdC,EAASG,EAAMH,OAEnB,OAAOA,GAAoB,GAAVA,EAAclD,EAAQsD,QAAQ5G,GAAQ+F,MAAOxE,KAAK4D,KAAK,GAAKoB,EAAQC,MAAclD,EAAQuD,aAAa7G,GAAQuG,MAAOA,OAG3I5G,IAAK,cACLgB,MAAO,SAAqBX,EAAM8G,GAC9B,IAAIP,EAAQO,EAAMP,MAElB,OAAOjD,EAAQmD,SAASzG,GAAQiG,KAAM,EAAGC,aAAc3E,KAAK4D,KAAK,EAAIoB,QAGzE5G,IAAK,eACLgB,MAAO,SAAsBX,EAAM+G,GAC/B,IAAIR,EAAQQ,EAAMR,MAElB,OAAOjD,EAAQsD,QAAQ5G,GAAQ+F,MAAOxE,KAAK4D,KAAK,EAAIoB,QAMxD5G,IAAK,UACLgB,MAAO,SAAiBqG,GACpB,IAAIC,EAAQD,EAAOtE,OAAO,SAAU8B,EAAMC,GACtC,OAAOD,EAAOC,GACf,GACH,OAAOuC,EAAO3G,IAAI,SAAUM,GACxB,OAAOA,EAAQsG,OAIvBtH,IAAK,OACLgB,MAAO,SAAcA,GACjB,OAAO,EAAIY,KAAKkC,KAAK9C,IAAU,EAAIY,KAAKkC,KAAK,EAAI9C,OAGrDhB,IAAK,oBACLgB,MAAO,SAA2BrC,GAC9B,IAAI4I,EAAM5I,EAAIoE,OAAO,SAAUC,EAAGC,GAC9B,OAAOD,EAAIC,IACVtE,EAAIK,OACLwI,EAAQ7I,EAAI+B,IAAI,SAAUmF,GAC1B,OAAOA,EAAI0B,IACZ7G,IAAI,SAAUmF,GACb,OAAOjE,KAAKmC,IAAI8B,EAAG,KAEvB,OAAOjE,KAAK4D,KAAKgC,EAAMzE,OAAO,SAAUC,EAAGC,GACvC,OAAOD,EAAIC,IACVuE,EAAMxI,WAGfgB,IAAK,UACLgB,MAAO,WAEH,GAAIT,KAAKkH,aAAelH,KAAKmH,QAAS,CAElC,IAAIC,EAAapH,KAAKmH,SAAW,MAAQnH,KAAKkH,cAE9ClH,KAAKqH,OAAOvG,QAAQ,SAAUJ,EAAO4G,GACjCA,GAAM5G,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAOE,QAAQH,QAAQ,SAAUyG,EAAG3E,GAChC,OAAO7B,EAAOE,QAAQ2B,IAAOwE,QAM7CpH,KAAKkH,aAAe,MAIrB9D,KAGM,oBAAVF,SAA0BC,OAAOC,QAAUA,SAGlD,IAAIoE,QAAU,WACV,SAASA,IACL,IAAIC,EAAQC,UAAUjJ,OAAS,QAAsB8B,IAAjBmH,UAAU,GAAmBA,UAAU,MACvEjD,EAAegD,EAAMhD,aACrBkD,EAAeF,EAAMJ,OACrBA,OAA0B9G,IAAjBoH,KAAkCA,EAC3CC,EAAmBH,EAAMjG,WACzBA,OAAkCjB,IAArBqH,EAAiC,eAAiBA,EAC/DC,EAAmBJ,EAAM1F,WACzBA,OAAkCxB,IAArBsH,EAAiC,UAAYA,EAC1DC,EAAaL,EAAMM,KACnBA,OAAsBxH,IAAfuH,EAA2B,eAAiBA,EACnD5C,EAAWuC,EAAMvC,SACjBM,EAAMiC,EAAMjC,IACZ9B,EAAa+D,EAAM/D,WACnBhC,EAAW+F,EAAM/F,SACjBsG,EAAgBP,EAAM3F,QACtBA,OAA4BvB,IAAlByH,EAA8B,GAAMA,EAC9ClF,EAAK2E,EAAM3E,GACXC,EAAK0E,EAAM1E,GACXoE,EAAUM,EAAMN,QAChBhG,EAAgBsG,EAAMtG,cAkC1B,OAhCAxC,gBAAgBqB,KAAMwH,GAEtBxH,KAAKQ,MAAQ,cACbR,KAAKqH,UACLrH,KAAKiI,OAAS,EACdjI,KAAKqF,WAAa,EAClBrF,KAAK8B,QAAqB,GAAXA,EAAmB,EAAIA,EACtC9B,KAAKqC,MAAQ,EACbN,EAAa/B,KAAKkI,OAAOnG,GACzBP,EAAaxB,KAAKkI,OAAO1G,GACzBuG,EAAO/H,KAAKkI,OAAOH,GAEC,MAAhBtD,IACAzE,KAAKyE,aAAeA,GAGpB3B,IACA9C,KAAK8C,GAAkB,kBAANA,GAAmBA,EAAK,KAAQA,EACjD9C,KAAKmI,QAAU,GAGfpF,IACA/C,KAAK+C,GAAkB,kBAANA,GAAmBA,EAAK,KAAQA,EACjD/C,KAAKoI,QAAU,GAGfjB,IACAnH,KAAKmH,QAA4B,kBAAXA,GAAwBA,EAAU,IAAOA,EAC/DnH,KAAKkH,aAAe,GAIhB1F,GAEJ,IAAK,UACDxB,KAAKyE,kBAAoClE,GAArBP,KAAKyE,aAA4B,KAAQzE,KAAKyE,aAClE,MAEJ,IAAK,OACDzE,KAAKyE,kBAAoClE,GAArBP,KAAKyE,aAA4B,IAAOzE,KAAKyE,aACjE,MAEJ,IAAK,WACDzE,KAAKwF,IAAa,MAAPA,EAAc,IAAOA,EAChC,MAEJ,QAEI,QAAyBjF,GAArBP,KAAKyE,aAEL,OAAQ1C,GAEJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACD/B,KAAKyE,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACDzE,KAAKyE,aAAe,KACpB,MAEJ,QACIzE,KAAKyE,aAAe,IAoCxC,GA/BAzE,KAAKwB,aAAc,EAAO,UAAMjB,GAAW8H,SAAS7G,GAAc,eAAiBA,EACnFxB,KAAKsI,eAAiBlF,QAAQpD,KAAKwB,YACnCxB,KAAK+B,WAAkC,mBAAdA,EAA2BA,EAAaqB,QAAQrB,GAAYwG,KAAKvI,MAC1FA,KAAKyB,iBAAmBM,EACxB/B,KAAK+H,KAAsB,mBAARA,EAAqBA,EAAO3E,QAAQ2E,GAEhC,WAAnB/H,KAAKwB,aACLxB,KAAKkF,cAAuB3E,GAAZ2E,EAAwB,IAAOA,GAGjC,SAAdnD,EACA/B,KAAK0D,gBAA2BnD,GAAdmD,GAA2B,KAASA,EACjC,OAAd3B,IACP/B,KAAK0B,cAAuBnB,GAAZmB,EAAwB,EAAIA,GAIhD1B,KAAKmB,eAAkBqH,aAAc,gBAEhBjI,GAAjBY,GAA8BA,EAAcqH,eAC5CxI,KAAKmB,cAAcqH,aAAexI,KAAKkI,OAAO/G,EAAcqH,eAGzB,WAAnCxI,KAAKmB,cAAcqH,aACnBxI,KAAKmB,cAAc0E,MAAQ1E,QAAwCZ,GAAvBY,EAAc0E,MAAqB1E,EAAc0E,MAAQ,GAC3D,YAAnC7F,KAAKmB,cAAcqH,eAC1BxI,KAAKmB,cAAc4E,KAAO5E,EAAc4E,MAAQ,EAChD/F,KAAKmB,cAAc6E,aAAe7E,EAAc6E,cAAgB,KAIhEqB,EAAO5I,OAEP,QAAQ,GAEJ,KAAK4I,EAAOoB,MAAM,SAAUC,GACxB,OAAOC,OAAOC,UAAUF,KAExB1I,KAAKqH,OAASA,EAAOlH,IAAI,SAAUL,GAC/B,OAAO,IAAID,MAAMC,KAErBE,KAAKQ,MAAQ,cACbR,KAAK6I,aACL,MAEJ,KAAKxB,EAAOoB,MAAM,SAAUC,GACxB,OAAOA,aAAgB7I,QAEvBG,KAAKQ,MAAQ,cACbR,KAAKqH,OAASA,EACdrH,KAAK6I,aACL,MAEJ,KAAKxB,EAAOoB,MAAM,SAAUC,GACxB,OAAOA,IAAS7I,QAEhBG,KAAKQ,MAAQ,UACbR,KAAK8I,cAAgBzB,EACrB,MAEJ,QACI,MAAM,IAAI0B,MAAM,2DAqXhC,OAhXAhK,aAAayI,IACT/H,IAAK,aACLgB,MAAO,SAAoBuI,EAAO7G,GAC9B,IAAI8G,EAASjJ,KAEb,OAAQA,KAAKQ,OAET,IAAK,cACD,OAEJ,IAAK,UACDR,KAAKqH,OAASrH,KAAK8I,cAAc3I,IAAI,SAAUO,EAAO4G,GAElD,IAAKA,EAAI,OAAO,IAAI5G,EAAMsI,GAE1B,GAAI1B,GAAM2B,EAAOH,cAAcrK,OAAS,EAAG,OAAO,IAAIiC,EAAMyB,GAE5D,IAAI+G,EAASD,EAAOH,cAAcrK,OAAS,EACvCqB,EAAOkJ,EAAQ7G,EAAW,EAAIA,GAAYA,EAAWd,KAAKsC,IAAIqF,EAAQ7G,GAAY,IAAM+G,EAAS5B,EAAK,IAAM4B,EAAS,GAAKF,GAAS7G,EAAW6G,EAAQ7G,GAAY+G,EAAS5B,IAAO4B,EAAS,GAAK/G,EAAW6G,GAASE,EAAS5B,IAAO4B,EAAS,GAEjP,OAAO,IAAIxI,EAAMW,KAAKoC,IAAIpC,KAAK8H,MAAMrJ,GAAO,MAEhD,MAEJ,IAAK,cACDE,KAAKqH,OAAO,GAAK,IAAIxH,MAAMmJ,GAC3BhJ,KAAKqH,OAAO,GAAK,IAAIxH,MAAMwB,KAAK+H,KAAKJ,EAAQ7G,EAAW,EAAIA,EAAWd,KAAKsC,IAAIqF,EAAQ7G,GAAY,EAAI6G,EAAQ7G,IAChHnC,KAAKqH,OAAO,GAAK,IAAIxH,MAAMwB,KAAK+H,KAAKjH,IAI7CnC,KAAKqH,OAAOvG,QAAQd,KAAKqJ,UAAUd,KAAKvI,OACxCA,KAAKQ,MAAQ,iBAGjBf,IAAK,YACLgB,MAAO,SAAmBC,EAAO4I,GAE7B5I,EAAMsC,IAAMhD,KAEZU,EAAMqB,WAAa/B,KAAK+B,WACxBrB,EAAMc,WAAaxB,KAAKwB,WACxBd,EAAMe,iBAAmBzB,KAAKyB,iBAC9Bf,EAAMoB,QAAU9B,KAAK8B,QAErBpB,EAAMS,iBACN5B,OAAOgK,OAAO7I,EAAMS,cAAenB,KAAKmB,eAEO,mBAApCT,EAAMS,cAAcqH,aAC3B9H,EAAMQ,cAAgBR,EAAMS,cAAcqH,aAE1C9H,EAAMQ,cAAgBkC,QAAQ1C,EAAMS,cAAcqH,mBAGtCjI,GAAZP,KAAKwF,MAAkB9E,EAAM8E,IAAMxF,KAAKwF,UACvBjF,GAAjBP,KAAK0B,WAAuBhB,EAAMgB,SAAW1B,KAAK0B,eACvCnB,GAAXP,KAAK8C,KAAiBpC,EAAMoC,GAAK9C,KAAK8C,SAC3BvC,GAAXP,KAAK+C,KAAiBrC,EAAMqC,GAAK/C,KAAK+C,IAEtCuG,IACA5I,EAAMS,cAAckF,MAAQrG,KAAKqH,OAAOiC,EAAa,GAAGxJ,KACxDE,KAAKqH,OAAOiC,EAAa,GAAGnI,cAAcmF,OAAS5F,EAAMZ,KACzDE,KAAKqH,OAAOiC,EAAa,GAAGE,WAAW9I,GACvCA,EAAM+I,WAAWzJ,KAAKqH,OAAOiC,EAAa,QAIlD7J,IAAK,UACLgB,MAAO,SAAiBkB,GAEpB,GAAkB,eAAd3B,KAAKQ,MACL,MAAM,IAAIuI,MAAM,iDAGpB,QAAaxI,IAAToB,EACA,MAAM,IAAIoH,MAAM,uCAapB,OAVIpH,EAAKlD,QAAUuB,KAAKqH,OAAO,GAAGpH,QAAQxB,QACtCiL,QAAQC,KAAK,8DAGjB3J,KAAKqH,OAAO,GAAGpH,QAAQa,QAAQ,SAAUC,EAAQV,GAC7C,OAAOU,EAAOgB,WAAaJ,EAAKtB,KAEpCL,KAAKqH,OAAOvG,QAAQ,SAAUJ,EAAO4G,GACjC,OAAOA,GAAM5G,EAAMkJ,QAAQjI,KAExB3B,KAAKqH,OAAOrH,KAAKqH,OAAO5I,OAAS,GAAGwB,QAAQE,IAAI,SAAUC,GAC7D,OAAOA,EAAE2B,gBAIjBtC,IAAK,WACLgB,MAAO,SAAkB0B,GAErB,QAAiB5B,IAAb4B,EACA,MAAM,IAAI4G,MAAM,wCAGhB5G,EAAS1D,QAAUuB,KAAKqH,OAAOrH,KAAKqH,OAAO5I,OAAS,GAAGwB,QAAQxB,QAC/DiL,QAAQC,KAAK,kEAGjB3J,KAAKqH,OAAOrH,KAAKqH,OAAO5I,OAAS,GAAGoL,SAAS1H,GAE7C,IAAK,IAAImH,EAAatJ,KAAKqH,OAAO5I,OAAS,EAAG6K,EAAa,EAAGA,IAC1DtJ,KAAKqH,OAAOiC,GAAYO,cAIhCpK,IAAK,QACLgB,MAAO,SAAeqJ,GAClB,IAAIC,EAAS/J,KAETgK,EAAQtC,UAAUjJ,OAAS,QAAsB8B,IAAjBmH,UAAU,GAAmBA,UAAU,MACvEuC,EAAeD,EAAM/B,OACrBA,OAA0B1H,IAAjB0J,EAA6B,EAAIA,EAC1CC,EAAWF,EAAME,SACjBC,EAAYH,EAAM9F,IAClBA,OAAoB3D,IAAd4J,GAAiCA,EACvCC,EAAsBJ,EAAM/G,cAC5BA,OAAwC1C,IAAxB6J,EAAoC,EAAIA,EAQ5D,OANApK,KAAKiD,cAAwC,kBAAjBA,GAA8BA,EAAgB6G,EAAQ,GAAG3H,SAAS1D,OAASwE,EAEnGiB,GACAwF,QAAQxF,IAAI,6BAA+B+D,EAAS,gBAAkBjI,KAAKiD,eAGxE,IAAIoH,QAAQ,SAAUC,EAASC,GAElC,QAAgBhK,IAAZuJ,GAAqC,OAAZA,EAA7B,CAIoB,eAAhBC,EAAOvJ,OACPuJ,EAAOlB,WAAWiB,EAAQ,GAAGd,MAAMvK,QAASqL,EAAQ,GAAG3H,UAAY2H,EAAQ,GAAG9F,QAAQvF,QAG1FsL,EAAO1C,OAAOvG,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,aAGzB,IAAIgK,EAAiB,EACjBC,EAAgB,EAChBC,EAAYC,KAAKC,MAEjBC,EAAU,WACVd,EAAO9B,SACP8B,EAAO1H,MAAQ,EACfmI,EAAiB,OAEKjK,GAAlBwJ,EAAO5B,UAAsB4B,EAAO5B,QAAU,QAC5B5H,GAAlBwJ,EAAO3B,UAAsB2B,EAAO3B,QAAU,GAElD0C,KAGAA,EAAc,SAASA,IAEvB,GAAKhB,EAAQU,GAAgBO,eAAe,WAAajB,EAAQU,GAAgBO,eAAe,aAAgBjB,EAAQU,GAAgBO,eAAe,WAAvJ,CAIA,IAAI/B,EAAQc,EAAQU,GAAgBxB,MAChChF,EAAS+F,EAAOH,QAAQZ,GACxB/J,EAAS6K,EAAQU,GAAgBrI,UAAY2H,EAAQU,GAAgBxG,OAEzE+F,EAAOF,SAAS5K,KAEVuL,EAAiBT,EAAO9G,eAAiB,GAC3C8G,EAAOiB,oBACPjB,EAAOkB,qBACAT,GAAkBV,EAAQrL,QACjCsL,EAAOiB,oBAGX,IAAIE,EAAiBnB,EAAOhC,KAAK9I,EAAQ+E,GACrCmH,EAAUR,KAAKC,MAAQF,EAC3BX,EAAO1H,OAAS6I,EAEO,mBAAZhB,GACPA,GACI7E,WAAY0E,EAAO1E,WACnBhD,MAAO6I,EACPC,QAASA,EAASnC,MAAOA,IAIjCe,EAAO1E,aAEHmF,EAAiBV,EAAQrL,OACzB2M,WAAWN,EAAYvC,KAAKwB,GAAS,IAErCU,IAEIvG,GACAwF,QAAQxF,IAAI,UAAY6F,EAAO9B,OAAS,WAAa8B,EAAO1H,MAAQmI,QAA+BjK,GAAbwJ,EAAOjH,GAAkB,GAAK,cAAgBiH,EAAO5B,QAAUqC,GAAiB,cAAgBT,EAAO7B,OAAOiD,EAAS,QAAU,sBAAwBpB,EAAO7B,OAAOiD,EAAUV,EAAe,SAGtRA,EAAgBxC,EAChB4C,KAEAd,EAAO1C,OAAOvG,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,gBAGrB0D,GACAwF,QAAQxF,IAAI,kCAAoC6F,EAAO7B,OAAOiD,EAAS,QAAU,6BAA+BpB,EAAO7B,OAAOiD,EAAUX,EAAgB,SAE5JF,WAjDQC,EAAO,uFAsD3BR,EAAOkB,oBACPJ,SApFgBN,EAAO,yBAwF/B9K,IAAK,OACLgB,MAAO,SAAc4K,GACjB,IAAIC,EAAStL,KAGTuL,GADQ7D,UAAUjJ,OAAS,QAAsB8B,IAAjBmH,UAAU,GAAmBA,UAAU,OACrDxD,IAClBA,OAAoB3D,IAAdgL,GAAiCA,EAE3C,OAAO,IAAIlB,QAAQ,SAAUC,EAASC,QAElBhK,IAAZ8K,GAAqC,OAAZA,GACzBd,EAAO,oBAGX,IAAIiB,EAAa,EACbhB,EAAiB,EACjBE,EAAYC,KAAKC,OAEL,SAASa,IAErB,IAAIzH,EAASsH,EAAO1B,QAAQyB,EAAQb,GAAgBxB,OAChD/J,EAASoM,EAAQb,GAAgBrI,UAAYkJ,EAAQb,GAAgBxG,OAUzE,GARAwH,GAAcF,EAAOvD,KAAK9I,EAAQ+E,GAE9BE,GACAwF,QAAQxF,IAAI,oBAAqBsG,EAAiB,EAAGgB,GAAchB,EAAiB,MAGxFA,EAEqBa,EAAQ5M,OACzB2M,WAAWK,EAAUlD,KAAK+C,GAAS,OAChC,CACH,IAAIH,EAAUR,KAAKC,MAAQF,EAEvBxG,GACAwF,QAAQxF,IAAI,iCAAmCoH,EAAOpD,OAAOiD,EAAS,QAAU,6BAA+BG,EAAOpD,OAAOiD,EAAUX,EAAgB,SAG3JF,EAAQkB,EAAaH,EAAQ5M,iBAO7CgB,IAAK,oBACLgB,MAAO,WACHT,KAAKqH,OAAOvG,QAAQ,SAAUJ,EAAO4G,GACjCA,GAAM5G,EAAMT,QAAQa,QAAQ,SAAUC,GAClC,OAAOA,EAAO8B,aAAe9B,EAAOE,QAAQd,IAAI,SAAUuL,GACtD,OAAO,WAMvBjM,IAAK,oBACLgB,MAAO,WACH,IAAIkL,EAAS3L,KAEbA,KAAKqH,OAAOvG,QAAQ,SAAUJ,EAAO4G,GACjCA,GAAM5G,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAO8B,aAAa/B,QAAQ,SAAU4K,EAAIE,QAErBrL,GAAboL,EAAO7I,KAAiB6I,EAAOxD,SAAW,GAAMwD,EAAO7I,GAAKzB,KAAKmC,IAAIzC,EAAOE,QAAQ2K,GAAM,SAC7ErL,GAAboL,EAAO5I,KAAiB4I,EAAOvD,SAAWuD,EAAO5I,GAAK1B,KAAKsC,IAAI5C,EAAOE,QAAQ2K,KAElF7K,EAAOE,QAAQ2K,GAAOD,EAAOrD,eAAeC,KAAKoD,EAAQ5K,EAAOE,QAAQ2K,GAAMF,EAAI3K,EAAQ6K,UAEpErL,GAAlBoL,EAAOxE,UAAsBwE,EAAOzE,cAAgB7F,KAAKmC,IAAIzC,EAAOE,QAAQ2K,GAAM,MAG1F7K,EAAOK,KAAOuK,EAAOrD,eAAeC,KAAKoD,EAAQ5K,EAAOK,KAAML,EAAOuB,UAAWvB,cAIpER,GAAhBP,KAAKmH,UACLnH,KAAKkH,aAAe7F,KAAK4D,KAAKjF,KAAKkH,cACnC9D,QAAQ+D,QAAQoB,KAAKvI,YAI7BP,IAAK,SACLgB,MAAO,WACH,OACI4G,OAAQrH,KAAKqH,OAAOlH,IAAI,SAAUO,GAC9B,OACIT,QAASS,EAAMT,QAAQE,IAAI,SAAUY,GACjC,OACIK,KAAML,EAAOK,KACbH,QAASF,EAAOE,kBAQxCxB,IAAK,WACLgB,MAAO,SAAkBkB,GAErB,QAAapB,IAAToB,GAA+B,OAATA,EACtB,MAAM,IAAIoH,MAAM,iCAGpB/I,KAAKqH,OAAS1F,EAAK0F,OAAOlH,IAAI,SAAUO,GACpC,OAAO,IAAIb,MAAMa,EAAMT,QAAQxB,OAAQiC,EAAMT,WAEjDD,KAAKQ,MAAQ,cACbR,KAAK6I,gBAGTpJ,IAAK,SACLgB,MAAO,SAAgBA,GACnB,IAAIoL,EAAOnE,UAAUjJ,OAAS,QAAsB8B,IAAjBmH,UAAU,GAAmBA,UAAU,GAAK,SAG/E,QAAQ,GAEJ,IAAa,UAARmE,GAAoC,iBAATpL,EAC5BA,EAAQA,EAAMqL,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAa,QAARF,GAAkC,iBAATpL,EAC1B,IAAIuL,EAAO,IAAIrB,KAAKlK,GAChBwL,KAEAxL,EAAQ,IACRwL,EAAUC,KAAKF,EAAKG,kBAAoB,OAGpC1L,GAAS,MAASwL,EAAUC,KAAKF,EAAKI,WAAa,KACnD3L,GAAS,KAAOwL,EAAUC,KAAKF,EAAKK,aAAe,KAEvDJ,EAAUC,KAAKF,EAAKM,aAAe,MAGvC7L,EAAQwL,EAAUM,KAAK,KAI/B,OAAO9L,MAIR+G,KAGM,oBAAVtE,SAA0BC,OAAOqE,QAAUA,SAGlD,IAAIlH,OAAS,WACT,SAASA,EAAOP,GACZpB,gBAAgBqB,KAAMM,GAElBP,IACAC,KAAKgB,UAAW,EAChBhB,KAAKiB,QAAUlB,EAAakB,YAC5BjB,KAAKoB,KAAOrB,EAAaqB,MAuDjC,OAnDArC,aAAauB,IACTb,IAAK,OACLgB,MAAO,SAAcX,GACjB,IAAI0M,EAAS9E,UAAUjJ,OAAS,QAAsB8B,IAAjBmH,UAAU,GAAmBA,UAAU,MACxElG,EAAagL,EAAOhL,WACpBC,EAAmB+K,EAAO/K,iBAC1BC,EAAW8K,EAAO9K,SAMtB,OAJA1B,KAAK6C,aAAe7C,KAAKiB,QAAQd,IAAI,SAAUmF,GAC3C,OAAO,IAGH9D,GAEJ,IAAK,OACDxB,KAAK6E,eAAiB3E,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUmF,GAC5E,OAAO,IAEXtF,KAAK4E,SAAW,EAChB,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACD5E,KAAKgF,UAAY,EACjBhF,KAAK+E,gBAAkB7E,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUmF,GAC7E,OAAO,IAGO,YAAd9D,IACAxB,KAAKyF,iBAAmBvF,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUmF,GAC9E,OAAO,IAEXtF,KAAK2F,kBAAoB,GAE7B,MAEJ,IAAK,OACD3F,KAAKmF,EAAI,EACTnF,KAAKsF,EAAI,EAIO,SAApB7D,EACAzB,KAAK4D,WAA6B,KAAhBvC,KAAKC,SACI,OAApBG,IACPzB,KAAK0B,SAAWA,OAKrBpB,KAGM,oBAAV4C,SAA0BC,OAAO7C,OAASA","sourcesContent":["\"use strict\";\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Layer = function () {\n    function Layer(size, importedData) {\n        _classCallCheck(this, Layer);\n\n        this.size = size;\n        this.neurons = [].concat(_toConsumableArray(new Array(size))).map(function (n, ni) {\n            return new Neuron(importedData ? importedData[ni] : undefined);\n        });\n        this.state = \"not-initialised\";\n    }\n\n    _createClass(Layer, [{\n        key: \"assignNext\",\n        value: function assignNext(layer) {\n            this.nextLayer = layer;\n        }\n    }, {\n        key: \"assignPrev\",\n        value: function assignPrev(layer) {\n            var _this = this;\n\n            this.prevLayer = layer;\n            this.neurons.forEach(function (neuron) {\n\n                if (!neuron.imported) {\n                    neuron.weights = _this.weightsInitFn(layer.size, _this.weightsConfig);\n                    neuron.bias = Math.random() * 0.2 - 0.1;\n                }\n\n                neuron.init(layer.size, {\n                    adaptiveLR: _this.adaptiveLR,\n                    activationConfig: _this.activationConfig,\n                    eluAlpha: _this.eluAlpha\n                });\n            });\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n            var _this2 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (_this2.state == \"training\" && (neuron.dropped = Math.random() > _this2.dropout)) {\n                    neuron.activation = 0;\n                } else {\n                    neuron.sum = neuron.bias;\n                    _this2.prevLayer.neurons.forEach(function (pNeuron, pni) {\n                        return neuron.sum += pNeuron.activation * neuron.weights[pni];\n                    });\n                    neuron.activation = _this2.activation(neuron.sum, false, neuron) / (_this2.dropout | 1);\n                }\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            var _this3 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (neuron.dropped) {\n                    neuron.error = 0;\n                    neuron.deltaBias = 0;\n                } else {\n                    if (typeof expected !== \"undefined\") {\n                        neuron.error = expected[ni] - neuron.activation;\n                    } else {\n                        neuron.derivative = _this3.activation(neuron.sum, true, neuron);\n                        neuron.error = neuron.derivative * _this3.nextLayer.neurons.map(function (n) {\n                            return n.error * (n.weights[ni] | 0);\n                        }).reduce(function (p, c) {\n                            return p + c;\n                        }, 0);\n                    }\n\n                    neuron.weights.forEach(function (weight, wi) {\n                        neuron.deltaWeights[wi] += neuron.error * _this3.prevLayer.neurons[wi].activation * (1 + ((_this3.l2 || 0) + (_this3.l1 || 0)) / _this3.net.miniBatchSize * neuron.deltaWeights[wi]);\n                    });\n\n                    neuron.deltaBias = neuron.error;\n                }\n            });\n        }\n    }]);\n\n    return Layer;\n}();\n\ntypeof window == \"undefined\" && (global.Layer = Layer);\n\"use strict\";\n\nvar NetMath = function () {\n    function NetMath() {\n        _classCallCheck(this, NetMath);\n    }\n\n    _createClass(NetMath, null, [{\n        key: \"sigmoid\",\n\n\n        // Activation functions\n        value: function sigmoid(value, prime) {\n            var val = 1 / (1 + Math.exp(-value));\n            return prime ? val * (1 - val) : val;\n        }\n    }, {\n        key: \"tanh\",\n        value: function tanh(value, prime) {\n            var exp = Math.exp(2 * value);\n            return prime ? 4 / Math.pow(Math.exp(value) + Math.exp(-value), 2) || 1e-18 : (exp - 1) / (exp + 1) || 1e-18;\n        }\n    }, {\n        key: \"relu\",\n        value: function relu(value, prime) {\n            return prime ? value > 0 ? 1 : 0 : Math.max(value, 0);\n        }\n    }, {\n        key: \"lrelu\",\n        value: function lrelu(value, prime) {\n            return prime ? value > 0 ? 1 : this.lreluSlope : Math.max(this.lreluSlope * Math.abs(value), value);\n        }\n    }, {\n        key: \"rrelu\",\n        value: function rrelu(value, prime, neuron) {\n            return prime ? value > 0 ? 1 : neuron.rreluSlope : Math.max(neuron.rreluSlope, value);\n        }\n    }, {\n        key: \"lecuntanh\",\n        value: function lecuntanh(value, prime) {\n            return prime ? 1.15333 * Math.pow(NetMath.sech(2 / 3 * value), 2) : 1.7159 * NetMath.tanh(2 / 3 * value);\n        }\n    }, {\n        key: \"elu\",\n        value: function elu(value, prime, neuron) {\n            return prime ? value >= 0 ? 1 : NetMath.elu(value, false, neuron) + neuron.eluAlpha : value >= 0 ? value : neuron.eluAlpha * (Math.exp(value) - 1);\n        }\n\n        // Cost functions\n\n    }, {\n        key: \"crossentropy\",\n        value: function crossentropy(target, output) {\n            return output.map(function (value, vi) {\n                return target[vi] * Math.log(value + 1e-15) + (1 - target[vi]) * Math.log(1 + 1e-15 - value);\n            }).reduce(function (p, c) {\n                return p - c;\n            }, 0);\n        }\n    }, {\n        key: \"meansquarederror\",\n        value: function meansquarederror(calculated, desired) {\n            return calculated.map(function (output, index) {\n                return Math.pow(output - desired[index], 2);\n            }).reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0) / calculated.length;\n        }\n\n        // Weight updating functions\n\n    }, {\n        key: \"noadaptivelr\",\n        value: function noadaptivelr(value, deltaValue) {\n            return value + this.learningRate * deltaValue;\n        }\n    }, {\n        key: \"gain\",\n        value: function gain(value, deltaValue, neuron, weightI) {\n\n            var newVal = value + this.learningRate * deltaValue * (weightI == null ? neuron.biasGain : neuron.weightGains[weightI]);\n\n            if (newVal <= 0 && value > 0 || newVal >= 0 && value < 0) {\n                if (weightI != null) {\n                    neuron.weightGains[weightI] = Math.max(neuron.weightGains[weightI] * 0.95, 0.5);\n                } else {\n                    neuron.biasGain = Math.max(neuron.biasGain * 0.95, 0.5);\n                }\n            } else {\n                if (weightI != null) {\n                    neuron.weightGains[weightI] = Math.min(neuron.weightGains[weightI] + 0.05, 5);\n                } else {\n                    neuron.biasGain = Math.min(neuron.biasGain + 0.05, 5);\n                }\n            }\n\n            return newVal;\n        }\n    }, {\n        key: \"adagrad\",\n        value: function adagrad(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.weightsCache[weightI] += Math.pow(deltaValue, 2);\n            } else {\n                neuron.biasCache += Math.pow(deltaValue, 2);\n            }\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"rmsprop\",\n        value: function rmsprop(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.weightsCache[weightI] = this.rmsDecay * neuron.weightsCache[weightI] + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);\n            } else {\n                neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);\n            }\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"adam\",\n        value: function adam(value, deltaValue, neuron) {\n\n            neuron.m = 0.9 * neuron.m + (1 - 0.9) * deltaValue;\n            var mt = neuron.m / (1 - Math.pow(0.9, this.iterations + 1));\n\n            neuron.v = 0.999 * neuron.v + (1 - 0.999) * Math.pow(deltaValue, 2);\n            var vt = neuron.v / (1 - Math.pow(0.999, this.iterations + 1));\n\n            return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8);\n        }\n    }, {\n        key: \"adadelta\",\n        value: function adadelta(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.weightsCache[weightI] = this.rho * neuron.weightsCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var newVal = value + Math.sqrt((neuron.adadeltaCache[weightI] + 1e-6) / (neuron.weightsCache[weightI] + 1e-6)) * deltaValue;\n                neuron.adadeltaCache[weightI] = this.rho * neuron.adadeltaCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return newVal;\n            } else {\n                neuron.biasCache = this.rho * neuron.biasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var _newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6) / (neuron.biasCache + 1e-6)) * deltaValue;\n                neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return _newVal;\n            }\n        }\n\n        // Weights init\n\n    }, {\n        key: \"uniform\",\n        value: function uniform(size, _ref) {\n            var limit = _ref.limit;\n\n            return [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                return Math.random() * 2 * limit - limit;\n            });\n        }\n    }, {\n        key: \"gaussian\",\n        value: function gaussian(size, _ref2) {\n            var mean = _ref2.mean,\n                stdDeviation = _ref2.stdDeviation;\n\n            return [].concat(_toConsumableArray(new Array(size))).map(function () {\n                // Polar Box Muller\n                var x1 = void 0,\n                    x2 = void 0,\n                    r = void 0,\n                    y = void 0;\n\n                do {\n                    x1 = 2 * Math.random() - 1;\n                    x2 = 2 * Math.random() - 1;\n                    r = Math.pow(x1, 2) + Math.pow(x2, 2);\n                } while (r >= 1 || !r);\n\n                return mean + x1 * Math.sqrt(-2 * Math.log(r) / r) * stdDeviation;\n            });\n        }\n    }, {\n        key: \"xaviernormal\",\n        value: function xaviernormal(size, _ref3) {\n            var fanIn = _ref3.fanIn,\n                fanOut = _ref3.fanOut;\n\n            return fanOut || fanOut == 0 ? NetMath.gaussian(size, { mean: 0, stdDeviation: Math.sqrt(2 / (fanIn + fanOut)) }) : NetMath.lecunnormal(size, { fanIn: fanIn });\n        }\n    }, {\n        key: \"xavieruniform\",\n        value: function xavieruniform(size, _ref4) {\n            var fanIn = _ref4.fanIn,\n                fanOut = _ref4.fanOut;\n\n            return fanOut || fanOut == 0 ? NetMath.uniform(size, { limit: Math.sqrt(6 / (fanIn + fanOut)) }) : NetMath.lecununiform(size, { fanIn: fanIn });\n        }\n    }, {\n        key: \"lecunnormal\",\n        value: function lecunnormal(size, _ref5) {\n            var fanIn = _ref5.fanIn;\n\n            return NetMath.gaussian(size, { mean: 0, stdDeviation: Math.sqrt(1 / fanIn) });\n        }\n    }, {\n        key: \"lecununiform\",\n        value: function lecununiform(size, _ref6) {\n            var fanIn = _ref6.fanIn;\n\n            return NetMath.uniform(size, { limit: Math.sqrt(3 / fanIn) });\n        }\n\n        // Other\n\n    }, {\n        key: \"softmax\",\n        value: function softmax(values) {\n            var total = values.reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0);\n            return values.map(function (value) {\n                return value / total;\n            });\n        }\n    }, {\n        key: \"sech\",\n        value: function sech(value) {\n            return 2 * Math.exp(-value) / (1 + Math.exp(-2 * value));\n        }\n    }, {\n        key: \"standardDeviation\",\n        value: function standardDeviation(arr) {\n            var avg = arr.reduce(function (p, c) {\n                return p + c;\n            }) / arr.length;\n            var diffs = arr.map(function (v) {\n                return v - avg;\n            }).map(function (v) {\n                return Math.pow(v, 2);\n            });\n            return Math.sqrt(diffs.reduce(function (p, c) {\n                return p + c;\n            }) / diffs.length);\n        }\n    }, {\n        key: \"maxNorm\",\n        value: function maxNorm() {\n\n            if (this.maxNormTotal > this.maxNorm) {\n\n                var multiplier = this.maxNorm / (1e-18 + this.maxNormTotal);\n\n                this.layers.forEach(function (layer, li) {\n                    li && layer.neurons.forEach(function (neuron) {\n                        neuron.weights.forEach(function (w, wi) {\n                            return neuron.weights[wi] *= multiplier;\n                        });\n                    });\n                });\n            }\n\n            this.maxNormTotal = 0;\n        }\n    }]);\n\n    return NetMath;\n}();\n\ntypeof window == \"undefined\" && (global.NetMath = NetMath);\n\"use strict\";\n\nvar Network = function () {\n    function Network() {\n        var _ref7 = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n            learningRate = _ref7.learningRate,\n            _ref7$layers = _ref7.layers,\n            layers = _ref7$layers === undefined ? [] : _ref7$layers,\n            _ref7$adaptiveLR = _ref7.adaptiveLR,\n            adaptiveLR = _ref7$adaptiveLR === undefined ? \"noadaptivelr\" : _ref7$adaptiveLR,\n            _ref7$activation = _ref7.activation,\n            activation = _ref7$activation === undefined ? \"sigmoid\" : _ref7$activation,\n            _ref7$cost = _ref7.cost,\n            cost = _ref7$cost === undefined ? \"crossentropy\" : _ref7$cost,\n            rmsDecay = _ref7.rmsDecay,\n            rho = _ref7.rho,\n            lreluSlope = _ref7.lreluSlope,\n            eluAlpha = _ref7.eluAlpha,\n            _ref7$dropout = _ref7.dropout,\n            dropout = _ref7$dropout === undefined ? 0.5 : _ref7$dropout,\n            l2 = _ref7.l2,\n            l1 = _ref7.l1,\n            maxNorm = _ref7.maxNorm,\n            weightsConfig = _ref7.weightsConfig;\n\n        _classCallCheck(this, Network);\n\n        this.state = \"not-defined\";\n        this.layers = [];\n        this.epochs = 0;\n        this.iterations = 0;\n        this.dropout = dropout == false ? 1 : dropout;\n        this.error = 0;\n        activation = this.format(activation);\n        adaptiveLR = this.format(adaptiveLR);\n        cost = this.format(cost);\n\n        if (learningRate != null) {\n            this.learningRate = learningRate;\n        }\n\n        if (l2) {\n            this.l2 = typeof l2 == \"boolean\" && l2 ? 0.001 : l2;\n            this.l2Error = 0;\n        }\n\n        if (l1) {\n            this.l1 = typeof l1 == \"boolean\" && l1 ? 0.005 : l1;\n            this.l1Error = 0;\n        }\n\n        if (maxNorm) {\n            this.maxNorm = typeof maxNorm == \"boolean\" && maxNorm ? 1000 : maxNorm;\n            this.maxNormTotal = 0;\n        }\n\n        // Activation function / Learning Rate\n        switch (adaptiveLR) {\n\n            case \"rmsprop\":\n                this.learningRate = this.learningRate == undefined ? 0.001 : this.learningRate;\n                break;\n\n            case \"adam\":\n                this.learningRate = this.learningRate == undefined ? 0.01 : this.learningRate;\n                break;\n\n            case \"adadelta\":\n                this.rho = rho == null ? 0.95 : rho;\n                break;\n\n            default:\n\n                if (this.learningRate == undefined) {\n\n                    switch (activation) {\n\n                        case \"relu\":\n                        case \"lrelu\":\n                        case \"rrelu\":\n                        case \"elu\":\n                            this.learningRate = 0.01;\n                            break;\n\n                        case \"tanh\":\n                        case \"lecuntanh\":\n                            this.learningRate = 0.001;\n                            break;\n\n                        default:\n                            this.learningRate = 0.2;\n                    }\n                }\n        }\n\n        this.adaptiveLR = [false, null, undefined].includes(adaptiveLR) ? \"noadaptivelr\" : adaptiveLR;\n        this.weightUpdateFn = NetMath[this.adaptiveLR];\n        this.activation = typeof activation == \"function\" ? activation : NetMath[activation].bind(this);\n        this.activationConfig = activation;\n        this.cost = typeof cost == \"function\" ? cost : NetMath[cost];\n\n        if (this.adaptiveLR == \"rmsprop\") {\n            this.rmsDecay = rmsDecay == undefined ? 0.99 : rmsDecay;\n        }\n\n        if (activation == \"lrelu\") {\n            this.lreluSlope = lreluSlope == undefined ? -0.0005 : lreluSlope;\n        } else if (activation == \"elu\") {\n            this.eluAlpha = eluAlpha == undefined ? 1 : eluAlpha;\n        }\n\n        // Weights distributiom\n        this.weightsConfig = { distribution: \"uniform\" };\n\n        if (weightsConfig != undefined && weightsConfig.distribution) {\n            this.weightsConfig.distribution = this.format(weightsConfig.distribution);\n        }\n\n        if (this.weightsConfig.distribution == \"uniform\") {\n            this.weightsConfig.limit = weightsConfig && weightsConfig.limit != undefined ? weightsConfig.limit : 0.1;\n        } else if (this.weightsConfig.distribution == \"gaussian\") {\n            this.weightsConfig.mean = weightsConfig.mean || 0;\n            this.weightsConfig.stdDeviation = weightsConfig.stdDeviation || 0.05;\n        }\n\n        // Status\n        if (layers.length) {\n\n            switch (true) {\n\n                case layers.every(function (item) {\n                    return Number.isInteger(item);\n                }):\n                    this.layers = layers.map(function (size) {\n                        return new Layer(size);\n                    });\n                    this.state = \"constructed\";\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item instanceof Layer;\n                }):\n                    this.state = \"constructed\";\n                    this.layers = layers;\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item === Layer;\n                }):\n                    this.state = \"defined\";\n                    this.definedLayers = layers;\n                    break;\n\n                default:\n                    throw new Error(\"There was an error constructing from the layers given.\");\n            }\n        }\n    }\n\n    _createClass(Network, [{\n        key: \"initLayers\",\n        value: function initLayers(input, expected) {\n            var _this4 = this;\n\n            switch (this.state) {\n\n                case \"initialised\":\n                    return;\n\n                case \"defined\":\n                    this.layers = this.definedLayers.map(function (layer, li) {\n\n                        if (!li) return new layer(input);\n\n                        if (li == _this4.definedLayers.length - 1) return new layer(expected);\n\n                        var hidden = _this4.definedLayers.length - 2;\n                        var size = input / expected > 5 ? expected + (expected + Math.abs(input - expected) / 4) * (hidden - li + 1) / (hidden / 2) : input >= expected ? input + expected * (hidden - li) / (hidden / 2) : expected + input * (hidden - li) / (hidden / 2);\n\n                        return new layer(Math.max(Math.round(size), 0));\n                    });\n                    break;\n\n                case \"not-defined\":\n                    this.layers[0] = new Layer(input);\n                    this.layers[1] = new Layer(Math.ceil(input / expected > 5 ? expected + Math.abs(input - expected) / 4 : input + expected));\n                    this.layers[2] = new Layer(Math.ceil(expected));\n                    break;\n            }\n\n            this.layers.forEach(this.joinLayer.bind(this));\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"joinLayer\",\n        value: function joinLayer(layer, layerIndex) {\n\n            layer.net = this;\n\n            layer.activation = this.activation;\n            layer.adaptiveLR = this.adaptiveLR;\n            layer.activationConfig = this.activationConfig;\n            layer.dropout = this.dropout;\n\n            layer.weightsConfig = {};\n            Object.assign(layer.weightsConfig, this.weightsConfig);\n\n            if (typeof layer.weightsConfig.distribution == \"function\") {\n                layer.weightsInitFn = layer.weightsConfig.distribution;\n            } else {\n                layer.weightsInitFn = NetMath[layer.weightsConfig.distribution];\n            }\n\n            if (this.rho != undefined) layer.rho = this.rho;\n            if (this.eluAlpha != undefined) layer.eluAlpha = this.eluAlpha;\n            if (this.l2 != undefined) layer.l2 = this.l2;\n            if (this.l1 != undefined) layer.l1 = this.l1;\n\n            if (layerIndex) {\n                layer.weightsConfig.fanIn = this.layers[layerIndex - 1].size;\n                this.layers[layerIndex - 1].weightsConfig.fanOut = layer.size;\n                this.layers[layerIndex - 1].assignNext(layer);\n                layer.assignPrev(this.layers[layerIndex - 1]);\n            }\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n\n            if (this.state != \"initialised\") {\n                throw new Error(\"The network layers have not been initialised.\");\n            }\n\n            if (data === undefined) {\n                throw new Error(\"No data passed to Network.forward()\");\n            }\n\n            if (data.length != this.layers[0].neurons.length) {\n                console.warn(\"Input data length did not match input layer neurons count.\");\n            }\n\n            this.layers[0].neurons.forEach(function (neuron, ni) {\n                return neuron.activation = data[ni];\n            });\n            this.layers.forEach(function (layer, li) {\n                return li && layer.forward(data);\n            });\n            return this.layers[this.layers.length - 1].neurons.map(function (n) {\n                return n.activation;\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n\n            if (expected === undefined) {\n                throw new Error(\"No data passed to Network.backward()\");\n            }\n\n            if (expected.length != this.layers[this.layers.length - 1].neurons.length) {\n                console.warn(\"Expected data length did not match output layer neurons count.\");\n            }\n\n            this.layers[this.layers.length - 1].backward(expected);\n\n            for (var layerIndex = this.layers.length - 2; layerIndex > 0; layerIndex--) {\n                this.layers[layerIndex].backward();\n            }\n        }\n    }, {\n        key: \"train\",\n        value: function train(dataSet) {\n            var _this5 = this;\n\n            var _ref8 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref8$epochs = _ref8.epochs,\n                epochs = _ref8$epochs === undefined ? 1 : _ref8$epochs,\n                callback = _ref8.callback,\n                _ref8$log = _ref8.log,\n                log = _ref8$log === undefined ? true : _ref8$log,\n                _ref8$miniBatchSize = _ref8.miniBatchSize,\n                miniBatchSize = _ref8$miniBatchSize === undefined ? 1 : _ref8$miniBatchSize;\n\n            this.miniBatchSize = typeof miniBatchSize == \"boolean\" && miniBatchSize ? dataSet[0].expected.length : miniBatchSize;\n\n            if (log) {\n                console.log(\"Training started. Epochs: \" + epochs + \" Batch Size: \" + this.miniBatchSize);\n            }\n\n            return new Promise(function (resolve, reject) {\n\n                if (dataSet === undefined || dataSet === null) {\n                    return void reject(\"No data provided\");\n                }\n\n                if (_this5.state != \"initialised\") {\n                    _this5.initLayers(dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length);\n                }\n\n                _this5.layers.forEach(function (layer) {\n                    return layer.state = \"training\";\n                });\n\n                var iterationIndex = 0;\n                var epochsCounter = 0;\n                var startTime = Date.now();\n\n                var doEpoch = function doEpoch() {\n                    _this5.epochs++;\n                    _this5.error = 0;\n                    iterationIndex = 0;\n\n                    if (_this5.l2Error != undefined) _this5.l2Error = 0;\n                    if (_this5.l1Error != undefined) _this5.l1Error = 0;\n\n                    doIteration();\n                };\n\n                var doIteration = function doIteration() {\n\n                    if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || !dataSet[iterationIndex].hasOwnProperty(\"expected\") && !dataSet[iterationIndex].hasOwnProperty(\"output\")) {\n                        return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\");\n                    }\n\n                    var input = dataSet[iterationIndex].input;\n                    var output = _this5.forward(input);\n                    var target = dataSet[iterationIndex].expected || dataSet[iterationIndex].output;\n\n                    _this5.backward(target);\n\n                    if (++iterationIndex % _this5.miniBatchSize == 0) {\n                        _this5.applyDeltaWeights();\n                        _this5.resetDeltaWeights();\n                    } else if (iterationIndex >= dataSet.length) {\n                        _this5.applyDeltaWeights();\n                    }\n\n                    var iterationError = _this5.cost(target, output);\n                    var elapsed = Date.now() - startTime;\n                    _this5.error += iterationError;\n\n                    if (typeof callback == \"function\") {\n                        callback({\n                            iterations: _this5.iterations,\n                            error: iterationError,\n                            elapsed: elapsed, input: input\n                        });\n                    }\n\n                    _this5.iterations++;\n\n                    if (iterationIndex < dataSet.length) {\n                        setTimeout(doIteration.bind(_this5), 0);\n                    } else {\n                        epochsCounter++;\n\n                        if (log) {\n                            console.log(\"Epoch: \" + _this5.epochs + \" Error: \" + _this5.error / iterationIndex + (_this5.l2 == undefined ? \"\" : \" L2 Error: \" + _this5.l2Error / iterationIndex), \"\\nElapsed: \" + _this5.format(elapsed, \"time\") + \" Average Duration: \" + _this5.format(elapsed / epochsCounter, \"time\"));\n                        }\n\n                        if (epochsCounter < epochs) {\n                            doEpoch();\n                        } else {\n                            _this5.layers.forEach(function (layer) {\n                                return layer.state = \"initialised\";\n                            });\n\n                            if (log) {\n                                console.log(\"Training finished. Total time: \" + _this5.format(elapsed, \"time\") + \"  Average iteration time: \" + _this5.format(elapsed / iterationIndex, \"time\"));\n                            }\n                            resolve();\n                        }\n                    }\n                };\n\n                _this5.resetDeltaWeights();\n                doEpoch();\n            });\n        }\n    }, {\n        key: \"test\",\n        value: function test(testSet) {\n            var _this6 = this;\n\n            var _ref9 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref9$log = _ref9.log,\n                log = _ref9$log === undefined ? true : _ref9$log;\n\n            return new Promise(function (resolve, reject) {\n\n                if (testSet === undefined || testSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                var totalError = 0;\n                var iterationIndex = 0;\n                var startTime = Date.now();\n\n                var testInput = function testInput() {\n\n                    var output = _this6.forward(testSet[iterationIndex].input);\n                    var target = testSet[iterationIndex].expected || testSet[iterationIndex].output;\n\n                    totalError += _this6.cost(target, output);\n\n                    if (log) {\n                        console.log(\"Testing iteration\", iterationIndex + 1, totalError / (iterationIndex + 1));\n                    }\n\n                    iterationIndex++;\n\n                    if (iterationIndex < testSet.length) {\n                        setTimeout(testInput.bind(_this6), 0);\n                    } else {\n                        var elapsed = Date.now() - startTime;\n\n                        if (log) {\n                            console.log(\"Testing finished. Total time: \" + _this6.format(elapsed, \"time\") + \"  Average iteration time: \" + _this6.format(elapsed / iterationIndex, \"time\"));\n                        }\n\n                        resolve(totalError / testSet.length);\n                    }\n                };\n                testInput();\n            });\n        }\n    }, {\n        key: \"resetDeltaWeights\",\n        value: function resetDeltaWeights() {\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    return neuron.deltaWeights = neuron.weights.map(function (dw) {\n                        return 0;\n                    });\n                });\n            });\n        }\n    }, {\n        key: \"applyDeltaWeights\",\n        value: function applyDeltaWeights() {\n            var _this7 = this;\n\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    neuron.deltaWeights.forEach(function (dw, dwi) {\n\n                        if (_this7.l2 != undefined) _this7.l2Error += 0.5 * _this7.l2 * Math.pow(neuron.weights[dwi], 2);\n                        if (_this7.l1 != undefined) _this7.l1Error += _this7.l1 * Math.abs(neuron.weights[dwi]);\n\n                        neuron.weights[dwi] = _this7.weightUpdateFn.bind(_this7, neuron.weights[dwi], dw, neuron, dwi)();\n\n                        if (_this7.maxNorm != undefined) _this7.maxNormTotal += Math.pow(neuron.weights[dwi], 2);\n                    });\n\n                    neuron.bias = _this7.weightUpdateFn.bind(_this7, neuron.bias, neuron.deltaBias, neuron)();\n                });\n            });\n\n            if (this.maxNorm != undefined) {\n                this.maxNormTotal = Math.sqrt(this.maxNormTotal);\n                NetMath.maxNorm.bind(this)();\n            }\n        }\n    }, {\n        key: \"toJSON\",\n        value: function toJSON() {\n            return {\n                layers: this.layers.map(function (layer) {\n                    return {\n                        neurons: layer.neurons.map(function (neuron) {\n                            return {\n                                bias: neuron.bias,\n                                weights: neuron.weights\n                            };\n                        })\n                    };\n                })\n            };\n        }\n    }, {\n        key: \"fromJSON\",\n        value: function fromJSON(data) {\n\n            if (data === undefined || data === null) {\n                throw new Error(\"No JSON data given to import.\");\n            }\n\n            this.layers = data.layers.map(function (layer) {\n                return new Layer(layer.neurons.length, layer.neurons);\n            });\n            this.state = \"constructed\";\n            this.initLayers();\n        }\n    }, {\n        key: \"format\",\n        value: function format(value) {\n            var type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"string\";\n\n\n            switch (true) {\n\n                case type == \"string\" && typeof value == \"string\":\n                    value = value.replace(/(_|\\s)/g, \"\").toLowerCase();\n                    break;\n\n                case type == \"time\" && typeof value == \"number\":\n                    var date = new Date(value);\n                    var formatted = [];\n\n                    if (value < 1000) {\n                        formatted.push(date.getMilliseconds() + \"ms\");\n                    } else {\n\n                        if (value >= 3600000) formatted.push(date.getHours() + \"h\");\n                        if (value >= 60000) formatted.push(date.getMinutes() + \"m\");\n\n                        formatted.push(date.getSeconds() + \"s\");\n                    }\n\n                    value = formatted.join(\" \");\n                    break;\n            }\n\n            return value;\n        }\n    }]);\n\n    return Network;\n}();\n\ntypeof window == \"undefined\" && (global.Network = Network);\n\"use strict\";\n\nvar Neuron = function () {\n    function Neuron(importedData) {\n        _classCallCheck(this, Neuron);\n\n        if (importedData) {\n            this.imported = true;\n            this.weights = importedData.weights || [];\n            this.bias = importedData.bias;\n        }\n    }\n\n    _createClass(Neuron, [{\n        key: \"init\",\n        value: function init(size) {\n            var _ref10 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                adaptiveLR = _ref10.adaptiveLR,\n                activationConfig = _ref10.activationConfig,\n                eluAlpha = _ref10.eluAlpha;\n\n            this.deltaWeights = this.weights.map(function (v) {\n                return 0;\n            });\n\n            switch (adaptiveLR) {\n\n                case \"gain\":\n                    this.weightGains = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 1;\n                    });\n                    this.biasGain = 1;\n                    break;\n\n                case \"adagrad\":\n                case \"rmsprop\":\n                case \"adadelta\":\n                    this.biasCache = 0;\n                    this.weightsCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 0;\n                    });\n\n                    if (adaptiveLR == \"adadelta\") {\n                        this.adadeltaCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                            return 0;\n                        });\n                        this.adadeltaBiasCache = 0;\n                    }\n                    break;\n\n                case \"adam\":\n                    this.m = 0;\n                    this.v = 0;\n                    break;\n            }\n\n            if (activationConfig == \"rrelu\") {\n                this.rreluSlope = Math.random() * 0.001;\n            } else if (activationConfig == \"elu\") {\n                this.eluAlpha = eluAlpha;\n            }\n        }\n    }]);\n\n    return Neuron;\n}();\n\ntypeof window == \"undefined\" && (global.Neuron = Neuron);\n//# sourceMappingURL=Network.concat.js.map\n//# sourceMappingURL=Network.min.js.map\n"]}