{"version":3,"sources":["Network.min.js"],"names":["_toConsumableArray","arr","Array","isArray","i","arr2","length","from","_classCallCheck","instance","Constructor","TypeError","_createClass","defineProperties","target","props","descriptor","enumerable","configurable","writable","Object","defineProperty","key","protoProps","staticProps","prototype","Layer","size","importedData","this","neurons","concat","map","n","ni","Neuron","undefined","value","layer","nextLayer","_this","prevLayer","forEach","neuron","init","adaptiveLR","rho","data","_this2","sum","bias","pNeuron","pni","activation","weights","expected","_this3","error","derivative","reduce","p","c","weight","wi","deltaWeights","deltaBias","window","global","NetMath","prime","sigmoid","Math","exp","output","vi","log","calculated","desired","index","pow","prev","curr","deltaValue","learningRate","weightI","newVal","biasGain","weightGains","max","min","weightsCache","biasCache","sqrt","rmsDecay","m","mt","iterations","v","vt","adadeltaCache","_newVal","adadeltaBiasCache","values","total","Network","_ref","arguments","_ref$layers","layers","_ref$adaptiveLR","_ref$activation","_ref$cost","cost","state","epochs","includes","weightUpdateFn","every","item","Number","isInteger","initLayers","definedLayers","Error","input","_this4","li","hidden","abs","round","ceil","joinLayer","bind","layerIndex","assignNext","assignPrev","console","warn","forward","backward","dataSet","_this5","_ref2","_ref2$epochs","callback","Promise","resolve","reject","iterationIndex","epochsCounter","doEpoch","doIteration","hasOwnProperty","resetDeltaWeights","applyDeltaWeights","iterationError","setTimeout","testSet","_this6","totalError","testIteration","testInput","dw","_this7","dwi","imported","random"],"mappings":"AAAA,aAIA,SAASA,mBAAmBC,GAAO,GAAIC,MAAMC,QAAQF,GAAM,CAAE,IAAK,IAAIG,EAAI,EAAGC,EAAOH,MAAMD,EAAIK,QAASF,EAAIH,EAAIK,OAAQF,IAAOC,EAAKD,GAAKH,EAAIG,GAAM,OAAOC,EAAe,OAAOH,MAAMK,KAAKN,GAE1L,SAASO,gBAAgBC,EAAUC,GAAe,KAAMD,aAAoBC,GAAgB,MAAM,IAAIC,UAAU,qCAJhH,IAAIC,aAAe,WAAc,SAASC,EAAiBC,EAAQC,GAAS,IAAK,IAAIX,EAAI,EAAGA,EAAIW,EAAMT,OAAQF,IAAK,CAAE,IAAIY,EAAaD,EAAMX,GAAIY,EAAWC,WAAaD,EAAWC,aAAc,EAAOD,EAAWE,cAAe,EAAU,UAAWF,IAAYA,EAAWG,UAAW,GAAMC,OAAOC,eAAeP,EAAQE,EAAWM,IAAKN,IAAiB,OAAO,SAAUN,EAAaa,EAAYC,GAAiJ,OAA9HD,GAAYV,EAAiBH,EAAYe,UAAWF,GAAiBC,GAAaX,EAAiBH,EAAac,GAAqBd,MAM5hBgB,MAAQ,WACR,SAASA,EAAMC,EAAMC,GACjBpB,gBAAgBqB,KAAMH,GAEtBG,KAAKF,KAAOA,EACZE,KAAKC,WAAaC,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUC,EAAGC,GAC3E,OAAO,IAAIC,OAAOP,EAAeA,EAAaM,QAAME,KA4D5D,OAxDAxB,aAAac,IACTJ,IAAK,aACLe,MAAO,SAAoBC,GACvBT,KAAKU,UAAYD,KAGrBhB,IAAK,aACLe,MAAO,SAAoBC,GACvB,IAAIE,EAAQX,KAEZA,KAAKY,UAAYH,EACjBT,KAAKC,QAAQY,QAAQ,SAAUC,GAC3B,OAAOA,EAAOC,KAAKN,EAAMX,KAAMa,EAAMK,WAAYL,EAAMM,UAI/DxB,IAAK,UACLe,MAAO,SAAiBU,GACpB,IAAIC,EAASnB,KAEbA,KAAKC,QAAQY,QAAQ,SAAUC,EAAQT,GAEnCS,EAAOM,IAAMN,EAAOO,KACpBF,EAAOP,UAAUX,QAAQY,QAAQ,SAAUS,EAASC,GAChD,OAAOT,EAAOM,KAAOE,EAAQE,WAAaV,EAAOW,QAAQF,KAE7DT,EAAOU,WAAaL,EAAOK,WAAWV,EAAOM,UAIrD3B,IAAK,WACLe,MAAO,SAAkBkB,GACrB,IAAIC,EAAS3B,KAEbA,KAAKC,QAAQY,QAAQ,SAAUC,EAAQT,QAEX,IAAbqB,EACPZ,EAAOc,MAAQF,EAASrB,GAAMS,EAAOU,YAErCV,EAAOe,WAAaF,EAAOH,WAAWV,EAAOM,KAAK,GAClDN,EAAOc,MAAQd,EAAOe,WAAaF,EAAOjB,UAAUT,QAAQE,IAAI,SAAUC,GACtE,OAAOA,EAAEwB,MAAQxB,EAAEqB,QAAQpB,KAC5ByB,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,IAGPlB,EAAOW,QAAQZ,QAAQ,SAAUoB,EAAQC,GACrCpB,EAAOqB,aAAaD,IAAOpB,EAAOc,MAAQD,EAAOf,UAAUX,QAAQiC,GAAIV,aAG3EV,EAAOsB,UAAYtB,EAAOc,YAK/B/B,KAGM,oBAAVwC,SAA0BC,OAAOzC,MAAQA,OAGhD,IAAI0C,QAAU,WACV,SAASA,IACL5D,gBAAgBqB,KAAMuC,GAiH1B,OA9GAxD,aAAawD,EAAS,OAClB9C,IAAK,UAILe,MAAO,SAAiBA,EAAOgC,GAC3B,OAAOA,EAAQD,EAAQE,QAAQjC,IAAU,EAAI+B,EAAQE,QAAQjC,IAAU,GAAK,EAAIkC,KAAKC,KAAKnC,OAM9Ff,IAAK,eACLe,MAAO,SAAsBvB,EAAQ2D,GACjC,OAAOA,EAAOzC,IAAI,SAAUK,EAAOqC,GAC/B,OAAO5D,EAAO4D,GAAMH,KAAKI,IAAItC,EAAQ,QAAU,EAAIvB,EAAO4D,IAAOH,KAAKI,IAAI,EAAI,MAAQtC,KACvFsB,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,MAGPvC,IAAK,mBACLe,MAAO,SAA0BuC,EAAYC,GACzC,OAAOD,EAAW5C,IAAI,SAAUyC,EAAQK,GACpC,OAAOP,KAAKQ,IAAIN,EAASI,EAAQC,GAAQ,KAC1CnB,OAAO,SAAUqB,EAAMC,GACtB,OAAOD,EAAOC,GACf,GAAKL,EAAWtE,UAMvBgB,IAAK,eACLe,MAAO,SAAsBA,EAAO6C,GAChC,OAAO7C,EAAQR,KAAKsD,aAAeD,KAGvC5D,IAAK,OACLe,MAAO,SAAcA,EAAO6C,EAAYvC,EAAQyC,GAE5C,IAAIC,EAAShD,EAAQR,KAAKsD,aAAeD,GAAyB,MAAXE,EAAkBzC,EAAO2C,SAAW3C,EAAO4C,YAAYH,IAQ9G,OANIC,GAAU,GAAKhD,EAAQ,GAAKgD,GAAU,GAAKhD,EAAQ,EACpC,MAAX+C,EAAiBzC,EAAO4C,YAAYH,GAAWb,KAAKiB,IAAkC,IAA9B7C,EAAO4C,YAAYH,GAAiB,IAAUzC,EAAO2C,SAAWf,KAAKiB,IAAsB,IAAlB7C,EAAO2C,SAAiB,IAE9I,MAAXF,EAAiBzC,EAAO4C,YAAYH,GAAWb,KAAKkB,IAAI9C,EAAO4C,YAAYH,GAAW,IAAM,GAAQzC,EAAO2C,SAAWf,KAAKkB,IAAI9C,EAAO2C,SAAW,IAAM,GAGxJD,KAGX/D,IAAK,UACLe,MAAO,SAAiBA,EAAO6C,EAAYvC,EAAQyC,GAI/C,OAFe,MAAXA,EAAiBzC,EAAO+C,aAAaN,IAAYb,KAAKQ,IAAIG,EAAY,GAAQvC,EAAOgD,WAAapB,KAAKQ,IAAIG,EAAY,GAEpH7C,EAAQR,KAAKsD,aAAeD,GAAc,KAAOX,KAAKqB,KAAgB,MAAXR,EAAkBzC,EAAO+C,aAAaN,GAAWzC,EAAOgD,eAG9HrE,IAAK,UACLe,MAAO,SAAiBA,EAAO6C,EAAYvC,EAAQyC,GAI/C,OAFe,MAAXA,EAAiBzC,EAAO+C,aAAaN,GAAWvD,KAAKgE,SAAWlD,EAAO+C,aAAaN,IAAY,EAAIvD,KAAKgE,UAAYtB,KAAKQ,IAAIG,EAAY,GAAQvC,EAAOgD,UAAY9D,KAAKgE,SAAWlD,EAAOgD,WAAa,EAAI9D,KAAKgE,UAAYtB,KAAKQ,IAAIG,EAAY,GAEhP7C,EAAQR,KAAKsD,aAAeD,GAAc,KAAOX,KAAKqB,KAAgB,MAAXR,EAAkBzC,EAAO+C,aAAaN,GAAWzC,EAAOgD,eAG9HrE,IAAK,OACLe,MAAO,SAAcA,EAAO6C,EAAYvC,GAEpCA,EAAOmD,EAAI,GAAMnD,EAAOmD,GAAK,EAAI,IAAOZ,EACxC,IAAIa,EAAKpD,EAAOmD,GAAK,EAAIvB,KAAKQ,IAAI,GAAKlD,KAAKmE,WAAa,IAEzDrD,EAAOsD,EAAI,KAAQtD,EAAOsD,GAAK,EAAI,MAAS1B,KAAKQ,IAAIG,EAAY,GACjE,IAAIgB,EAAKvD,EAAOsD,GAAK,EAAI1B,KAAKQ,IAAI,KAAOlD,KAAKmE,WAAa,IAE3D,OAAO3D,EAAQR,KAAKsD,aAAeY,GAAMxB,KAAKqB,KAAKM,GAAM,SAG7D5E,IAAK,WACLe,MAAO,SAAkBA,EAAO6C,EAAYvC,EAAQyC,GAEhD,GAAe,MAAXA,EAAiB,CACjBzC,EAAO+C,aAAaN,GAAWvD,KAAKiB,IAAMH,EAAO+C,aAAaN,IAAY,EAAIvD,KAAKiB,KAAOyB,KAAKQ,IAAIG,EAAY,GAC/G,IAAIG,EAAShD,EAAQkC,KAAKqB,MAAMjD,EAAOwD,cAAcf,GAAW,OAASzC,EAAO+C,aAAaN,GAAW,OAASF,EAEjH,OADAvC,EAAOwD,cAAcf,GAAWvD,KAAKiB,IAAMH,EAAOwD,cAAcf,IAAY,EAAIvD,KAAKiB,KAAOyB,KAAKQ,IAAIG,EAAY,GAC1GG,EAEP1C,EAAOgD,UAAY9D,KAAKiB,IAAMH,EAAOgD,WAAa,EAAI9D,KAAKiB,KAAOyB,KAAKQ,IAAIG,EAAY,GACvF,IAAIkB,EAAU/D,EAAQkC,KAAKqB,MAAMjD,EAAO0D,kBAAoB,OAAS1D,EAAOgD,UAAY,OAAST,EAEjG,OADAvC,EAAO0D,kBAAoBxE,KAAKiB,IAAMH,EAAO0D,mBAAqB,EAAIxE,KAAKiB,KAAOyB,KAAKQ,IAAIG,EAAY,GAChGkB,KAOf9E,IAAK,UACLe,MAAO,SAAiBiE,GACpB,IAAIC,EAAQD,EAAO3C,OAAO,SAAUqB,EAAMC,GACtC,OAAOD,EAAOC,GACf,GACH,OAAOqB,EAAOtE,IAAI,SAAUK,GACxB,OAAOA,EAAQkE,QAKpBnC,KAGM,oBAAVF,SAA0BC,OAAOC,QAAUA,SAGlD,IAAIoC,QAAU,WACV,SAASA,IACL,IAAIC,EAAOC,UAAUpG,OAAS,QAAsB8B,IAAjBsE,UAAU,GAAmBA,UAAU,MACtEvB,EAAesB,EAAKtB,aACpBwB,EAAcF,EAAKG,OACnBA,OAAyBxE,IAAhBuE,KAAiCA,EAC1CE,EAAkBJ,EAAK5D,WACvBA,OAAiCT,IAApByE,EAAgC,eAAiBA,EAC9DC,EAAkBL,EAAKpD,WACvBA,OAAiCjB,IAApB0E,EAAgC,UAAYA,EACzDC,EAAYN,EAAKO,KACjBA,OAAqB5E,IAAd2E,EAA0B,eAAiBA,EAClDlB,EAAWY,EAAKZ,SAChB/C,EAAM2D,EAAK3D,IAaf,OAXAtC,gBAAgBqB,KAAM2E,GAEtB3E,KAAKoF,MAAQ,cACbpF,KAAK+E,UACL/E,KAAKqF,OAAS,EACdrF,KAAKmE,WAAa,EAEE,MAAhBb,IACAtD,KAAKsD,aAAeA,IAGhB,GAEJ,IAAmB,WAAdtC,EACDhB,KAAKsD,kBAAoC/C,GAArBP,KAAKsD,aAA4B,KAAQtD,KAAKsD,aAClE,MAEJ,IAAmB,QAAdtC,EACDhB,KAAKsD,kBAAoC/C,GAArBP,KAAKsD,aAA4B,IAAOtD,KAAKsD,aACjE,MAEJ,IAAmB,YAAdtC,EACDhB,KAAKiB,IAAa,MAAPA,EAAc,IAAOA,EAChC,MAEJ,QACIjB,KAAKsD,kBAAoC/C,GAArBP,KAAKsD,aAA4B,GAAMtD,KAAKsD,aAYxE,GATAtD,KAAKgB,aAAc,EAAO,UAAMT,GAAW+E,SAAStE,GAAc,eAAiBA,EACnFhB,KAAKuF,eAAiBhD,QAAQvC,KAAKgB,YACnChB,KAAKwB,WAAae,QAAQf,GAC1BxB,KAAKmF,KAAO5C,QAAQ4C,GAEG,WAAnBnF,KAAKgB,aACLhB,KAAKgE,cAAuBzD,GAAZyD,EAAwB,IAAOA,GAG/Ce,EAAOtG,OAEP,QAAQ,GAEJ,KAAKsG,EAAOS,MAAM,SAAUC,GACxB,OAAOC,OAAOC,UAAUF,KAExBzF,KAAK+E,OAASA,EAAO5E,IAAI,SAAUL,GAC/B,OAAO,IAAID,MAAMC,KAErBE,KAAKoF,MAAQ,cACbpF,KAAK4F,aACL,MAEJ,KAAKb,EAAOS,MAAM,SAAUC,GACxB,OAAOA,aAAgB5F,QAEvBG,KAAKoF,MAAQ,cACbpF,KAAK+E,OAASA,EACd/E,KAAK4F,aACL,MAEJ,KAAKb,EAAOS,MAAM,SAAUC,GACxB,OAAOA,IAAS5F,QAEhBG,KAAKoF,MAAQ,UACbpF,KAAK6F,cAAgBd,EACrB,MAEJ,QACI,MAAM,IAAIe,MAAM,2DAoQhC,OA/PA/G,aAAa4F,IACTlF,IAAK,aACLe,MAAO,SAAoBuF,EAAOrE,GAC9B,IAAIsE,EAAShG,KAEb,OAAQA,KAAKoF,OAET,IAAK,cACD,OAEJ,IAAK,UACDpF,KAAK+E,OAAS/E,KAAK6F,cAAc1F,IAAI,SAAUM,EAAOwF,GAClD,IAAKA,EAAI,OAAO,IAAIxF,EAAMsF,GAE1B,GAAIE,GAAMD,EAAOH,cAAcpH,OAAS,EAAG,OAAO,IAAIgC,EAAMiB,GAE5D,IAAIwE,EAASF,EAAOH,cAAcpH,OAAS,EACvCqB,EAAOiG,EAAQrE,EAAW,EAAIA,GAAYA,EAAWgB,KAAKyD,IAAIJ,EAAQrE,GAAY,IAAMwE,EAASD,EAAK,IAAMC,EAAS,GAAKH,GAASrE,EAAWqE,EAAQrE,GAAYwE,EAASD,IAAOC,EAAS,GAAKxE,EAAWqE,GAASG,EAASD,IAAOC,EAAS,GAEjP,OAAO,IAAIzF,EAAMiC,KAAKiB,IAAIjB,KAAK0D,MAAMtG,GAAO,MAEhD,MAEJ,IAAK,cACDE,KAAK+E,OAAO,GAAK,IAAIlF,MAAMkG,GAC3B/F,KAAK+E,OAAO,GAAK,IAAIlF,MAAM6C,KAAK2D,KAAKN,EAAQrE,EAAW,EAAIA,EAAWgB,KAAKyD,IAAIJ,EAAQrE,GAAY,EAAIqE,EAAQrE,IAChH1B,KAAK+E,OAAO,GAAK,IAAIlF,MAAM6C,KAAK2D,KAAK3E,IAI7C1B,KAAK+E,OAAOlE,QAAQb,KAAKsG,UAAUC,KAAKvG,OACxCA,KAAKoF,MAAQ,iBAGjB3F,IAAK,YACLe,MAAO,SAAmBC,EAAO+F,GAE7B/F,EAAMe,WAAaxB,KAAKwB,WACxBf,EAAMO,WAAahB,KAAKgB,gBAERT,GAAZP,KAAKiB,MACLR,EAAMQ,IAAMjB,KAAKiB,KAGjBuF,IACAxG,KAAK+E,OAAOyB,EAAa,GAAGC,WAAWhG,GACvCA,EAAMiG,WAAW1G,KAAK+E,OAAOyB,EAAa,QAIlD/G,IAAK,UACLe,MAAO,SAAiBU,GAEpB,GAAkB,eAAdlB,KAAKoF,MACL,MAAM,IAAIU,MAAM,iDAGpB,QAAavF,IAATW,EACA,MAAM,IAAI4E,MAAM,uCAapB,OAVI5E,EAAKzC,QAAUuB,KAAK+E,OAAO,GAAG9E,QAAQxB,QACtCkI,QAAQC,KAAK,8DAGjB5G,KAAK+E,OAAO,GAAG9E,QAAQY,QAAQ,SAAUC,EAAQT,GAC7C,OAAOS,EAAOU,WAAaN,EAAKb,KAEpCL,KAAK+E,OAAOlE,QAAQ,SAAUJ,EAAOwF,GACjC,OAAOA,GAAMxF,EAAMoG,QAAQ3F,KAExBlB,KAAK+E,OAAO/E,KAAK+E,OAAOtG,OAAS,GAAGwB,QAAQE,IAAI,SAAUC,GAC7D,OAAOA,EAAEoB,gBAIjB/B,IAAK,WACLe,MAAO,SAAkBkB,GACrB,QAAiBnB,IAAbmB,EACA,MAAM,IAAIoE,MAAM,wCAGhBpE,EAASjD,QAAUuB,KAAK+E,OAAO/E,KAAK+E,OAAOtG,OAAS,GAAGwB,QAAQxB,QAC/DkI,QAAQC,KAAK,kEAGjB5G,KAAK+E,OAAO/E,KAAK+E,OAAOtG,OAAS,GAAGqI,SAASpF,GAE7C,IAAK,IAAI8E,EAAaxG,KAAK+E,OAAOtG,OAAS,EAAG+H,EAAa,EAAGA,IAC1DxG,KAAK+E,OAAOyB,GAAYM,cAIhCrH,IAAK,QACLe,MAAO,SAAeuG,GAClB,IAAIC,EAAShH,KAETiH,EAAQpC,UAAUpG,OAAS,QAAsB8B,IAAjBsE,UAAU,GAAmBA,UAAU,MACvEqC,EAAeD,EAAM5B,OACrBA,OAA0B9E,IAAjB2G,EAA6B,EAAIA,EAC1CC,EAAWF,EAAME,SAErB,OAAO,IAAIC,QAAQ,SAAUC,EAASC,QAElB/G,IAAZwG,GAAqC,OAAZA,GACzBO,EAAO,oBAGS,eAAhBN,EAAO5B,OACP4B,EAAOpB,WAAWmB,EAAQ,GAAGhB,MAAMtH,QAASsI,EAAQ,GAAGrF,UAAYqF,EAAQ,GAAGnE,QAAQnE,QAG1F,IAAI8I,EAAiB,EACjBC,EAAgB,EAChB5F,EAAQ,EAER6F,EAAU,WACVT,EAAO3B,SACPkC,EAAiB,EAEjBG,KAGAA,EAAc,SAASA,IAEvB,IAAKX,EAAQQ,GAAgBI,eAAe,WAAaZ,EAAQQ,GAAgBI,eAAe,cAAgBZ,EAAQQ,GAAgBI,eAAe,UACnJ,OAAOL,EAAO,sFAGlBN,EAAOY,oBAEP,IAAI7B,EAAQgB,EAAQQ,GAAgBxB,MAChCnD,EAASoE,EAAOH,QAAQd,GACxB9G,EAAS8H,EAAQQ,GAAgB7F,UAAYqF,EAAQQ,GAAgB3E,OAEzEoE,EAAOF,SAAS7H,GAChB+H,EAAOa,oBAEP,IAAIC,EAAiBd,EAAO7B,KAAKlG,EAAQ2D,GACzChB,GAASkG,EAEc,mBAAZX,GACPA,GACIhD,WAAY6C,EAAO7C,WACnBvC,MAAOkG,EACP/B,MAAOA,IAIfiB,EAAO7C,eACPoD,EAEqBR,EAAQtI,OACzBsJ,WAAWL,EAAYnB,KAAKS,GAAS,IAGrCQ,IACAb,QAAQ7D,IAAI,UAAY0E,EAAgB,WAAa5F,EAAQ,KAEzD4F,EAAgBnC,EAChBoC,IACGJ,MAIfI,SAIRhI,IAAK,OACLe,MAAO,SAAcwH,GACjB,IAAIC,EAASjI,KAEb,OAAO,IAAIoH,QAAQ,SAAUC,EAASC,QAElB/G,IAAZyH,GAAqC,OAAZA,GACzBV,EAAO,oBAGX,IAAIY,EAAa,EACbC,EAAgB,GAEJ,SAASC,IAErBzB,QAAQ7D,IAAI,oBAAqBqF,EAAgB,EAAGD,GAAcC,EAAgB,IAElF,IAAIvF,EAASqF,EAAOpB,QAAQmB,EAAQG,GAAepC,OAC/C9G,EAAS+I,EAAQG,GAAezG,UAAYsG,EAAQG,GAAevF,OAEvEsF,GAAcD,EAAO9C,KAAKlG,EAAQ2D,KAElCuF,EAEoBH,EAAQvJ,OAAQsJ,WAAWK,EAAU7B,KAAK0B,GAAS,GAAQZ,EAAQa,EAAaF,EAAQvJ,gBAMxHgB,IAAK,oBACLe,MAAO,WACHR,KAAK+E,OAAOlE,QAAQ,SAAUJ,EAAOwF,GACjCA,GAAMxF,EAAMR,QAAQY,QAAQ,SAAUC,GAClCA,EAAOqB,aAAerB,EAAOW,QAAQtB,IAAI,SAAUkI,GAC/C,OAAO,WAMvB5I,IAAK,oBACLe,MAAO,WACH,IAAI8H,EAAStI,KAEbA,KAAK+E,OAAOlE,QAAQ,SAAUJ,EAAOwF,GACjCA,GAAMxF,EAAMR,QAAQY,QAAQ,SAAUC,GAClCA,EAAOqB,aAAatB,QAAQ,SAAUwH,EAAIE,GACtCzH,EAAOW,QAAQ8G,GAAOD,EAAO/C,eAAegB,KAAK+B,EAAQxH,EAAOW,QAAQ8G,GAAMF,EAAIvH,EAAQyH,OAE9FzH,EAAOO,KAAOiH,EAAO/C,eAAegB,KAAK+B,EAAQxH,EAAOO,KAAMP,EAAOsB,UAAWtB,YAK5FrB,IAAK,SACLe,MAAO,WACH,OACIuE,OAAQ/E,KAAK+E,OAAO5E,IAAI,SAAUM,GAC9B,OACIR,QAASQ,EAAMR,QAAQE,IAAI,SAAUW,GACjC,OACIO,KAAMP,EAAOO,KACbI,QAASX,EAAOW,kBAQxChC,IAAK,WACLe,MAAO,SAAkBU,GAErB,QAAaX,IAATW,GAA+B,OAATA,EACtB,MAAM,IAAI4E,MAAM,iCAGpB9F,KAAK+E,OAAS7D,EAAK6D,OAAO5E,IAAI,SAAUM,GACpC,OAAO,IAAIZ,MAAMY,EAAMR,QAAQxB,OAAQgC,EAAMR,WAEjDD,KAAKoF,MAAQ,cACbpF,KAAK4F,iBAINjB,KAGM,oBAAVtC,SAA0BC,OAAOqC,QAAUA,SAGlD,IAAIrE,OAAS,WACT,SAASA,EAAOP,GACZpB,gBAAgBqB,KAAMM,GAElBP,IACAC,KAAKwI,UAAW,EAChBxI,KAAKyB,QAAU1B,EAAa0B,YAC5BzB,KAAKqB,KAAOtB,EAAasB,MAkDjC,OA9CAtC,aAAauB,IACTb,IAAK,OACLe,MAAO,SAAcV,EAAMkB,GAYvB,OAXKhB,KAAKwI,WACNxI,KAAKyB,WAAavB,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUiE,GACxE,MAAuB,GAAhB1B,KAAK+F,SAAiB,KAEjCzI,KAAKqB,KAAuB,GAAhBqB,KAAK+F,SAAiB,IAGtCzI,KAAKmC,aAAenC,KAAKyB,QAAQtB,IAAI,SAAUiE,GAC3C,OAAO,IAGHpD,GACJ,IAAK,OACDhB,KAAK0D,eAAiBxD,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUiE,GAC5E,OAAO,IAEXpE,KAAKyD,SAAW,EAChB,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACDzD,KAAK8D,UAAY,EACjB9D,KAAK6D,gBAAkB3D,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUiE,GAC7E,OAAO,IAGO,YAAdpD,IACAhB,KAAKsE,iBAAmBpE,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUiE,GAC9E,OAAO,IAEXpE,KAAKwE,kBAAoB,GAE7B,MAEJ,IAAK,OACDxE,KAAKiE,EAAI,EACTjE,KAAKoE,EAAI,OAMlB9D,KAGM,oBAAV+B,SAA0BC,OAAOhC,OAASA","sourcesContent":["\"use strict\";\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Layer = function () {\n    function Layer(size, importedData) {\n        _classCallCheck(this, Layer);\n\n        this.size = size;\n        this.neurons = [].concat(_toConsumableArray(new Array(size))).map(function (n, ni) {\n            return new Neuron(importedData ? importedData[ni] : undefined);\n        });\n    }\n\n    _createClass(Layer, [{\n        key: \"assignNext\",\n        value: function assignNext(layer) {\n            this.nextLayer = layer;\n        }\n    }, {\n        key: \"assignPrev\",\n        value: function assignPrev(layer) {\n            var _this = this;\n\n            this.prevLayer = layer;\n            this.neurons.forEach(function (neuron) {\n                return neuron.init(layer.size, _this.adaptiveLR, _this.rho);\n            });\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n            var _this2 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                neuron.sum = neuron.bias;\n                _this2.prevLayer.neurons.forEach(function (pNeuron, pni) {\n                    return neuron.sum += pNeuron.activation * neuron.weights[pni];\n                });\n                neuron.activation = _this2.activation(neuron.sum);\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            var _this3 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (typeof expected !== \"undefined\") {\n                    neuron.error = expected[ni] - neuron.activation;\n                } else {\n                    neuron.derivative = _this3.activation(neuron.sum, true);\n                    neuron.error = neuron.derivative * _this3.nextLayer.neurons.map(function (n) {\n                        return n.error * n.weights[ni];\n                    }).reduce(function (p, c) {\n                        return p + c;\n                    }, 0);\n                }\n\n                neuron.weights.forEach(function (weight, wi) {\n                    neuron.deltaWeights[wi] += neuron.error * _this3.prevLayer.neurons[wi].activation;\n                });\n\n                neuron.deltaBias = neuron.error;\n            });\n        }\n    }]);\n\n    return Layer;\n}();\n\ntypeof window == \"undefined\" && (global.Layer = Layer);\n\"use strict\";\n\nvar NetMath = function () {\n    function NetMath() {\n        _classCallCheck(this, NetMath);\n    }\n\n    _createClass(NetMath, null, [{\n        key: \"sigmoid\",\n\n\n        // Activation functions\n        value: function sigmoid(value, prime) {\n            return prime ? NetMath.sigmoid(value) * (1 - NetMath.sigmoid(value)) : 1 / (1 + Math.exp(-value));\n        }\n\n        // Cost functions\n\n    }, {\n        key: \"crossEntropy\",\n        value: function crossEntropy(target, output) {\n            return output.map(function (value, vi) {\n                return target[vi] * Math.log(value + 1e-15) + (1 - target[vi]) * Math.log(1 + 1e-15 - value);\n            }).reduce(function (p, c) {\n                return p - c;\n            }, 0);\n        }\n    }, {\n        key: \"meanSquaredError\",\n        value: function meanSquaredError(calculated, desired) {\n            return calculated.map(function (output, index) {\n                return Math.pow(output - desired[index], 2);\n            }).reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0) / calculated.length;\n        }\n\n        // Weight updating functions\n\n    }, {\n        key: \"noAdaptiveLR\",\n        value: function noAdaptiveLR(value, deltaValue) {\n            return value + this.learningRate * deltaValue;\n        }\n    }, {\n        key: \"gain\",\n        value: function gain(value, deltaValue, neuron, weightI) {\n\n            var newVal = value + this.learningRate * deltaValue * (weightI == null ? neuron.biasGain : neuron.weightGains[weightI]);\n\n            if (newVal <= 0 && value > 0 || newVal >= 0 && value < 0) {\n                if (weightI != null) neuron.weightGains[weightI] = Math.max(neuron.weightGains[weightI] * 0.95, 0.5);else neuron.biasGain = Math.max(neuron.biasGain * 0.95, 0.5);\n            } else {\n                if (weightI != null) neuron.weightGains[weightI] = Math.min(neuron.weightGains[weightI] + 0.05, 5);else neuron.biasGain = Math.min(neuron.biasGain + 0.05, 5);\n            }\n\n            return newVal;\n        }\n    }, {\n        key: \"adagrad\",\n        value: function adagrad(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) neuron.weightsCache[weightI] += Math.pow(deltaValue, 2);else neuron.biasCache += Math.pow(deltaValue, 2);\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"RMSProp\",\n        value: function RMSProp(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) neuron.weightsCache[weightI] = this.rmsDecay * neuron.weightsCache[weightI] + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);else neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"adam\",\n        value: function adam(value, deltaValue, neuron) {\n\n            neuron.m = 0.9 * neuron.m + (1 - 0.9) * deltaValue;\n            var mt = neuron.m / (1 - Math.pow(0.9, this.iterations + 1));\n\n            neuron.v = 0.999 * neuron.v + (1 - 0.999) * Math.pow(deltaValue, 2);\n            var vt = neuron.v / (1 - Math.pow(0.999, this.iterations + 1));\n\n            return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8);\n        }\n    }, {\n        key: \"adadelta\",\n        value: function adadelta(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.weightsCache[weightI] = this.rho * neuron.weightsCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var newVal = value + Math.sqrt((neuron.adadeltaCache[weightI] + 1e-6) / (neuron.weightsCache[weightI] + 1e-6)) * deltaValue;\n                neuron.adadeltaCache[weightI] = this.rho * neuron.adadeltaCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return newVal;\n            } else {\n                neuron.biasCache = this.rho * neuron.biasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var _newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6) / (neuron.biasCache + 1e-6)) * deltaValue;\n                neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return _newVal;\n            }\n        }\n\n        // Other\n\n    }, {\n        key: \"softmax\",\n        value: function softmax(values) {\n            var total = values.reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0);\n            return values.map(function (value) {\n                return value / total;\n            });\n        }\n    }]);\n\n    return NetMath;\n}();\n\ntypeof window == \"undefined\" && (global.NetMath = NetMath);\n\"use strict\";\n\nvar Network = function () {\n    function Network() {\n        var _ref = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n            learningRate = _ref.learningRate,\n            _ref$layers = _ref.layers,\n            layers = _ref$layers === undefined ? [] : _ref$layers,\n            _ref$adaptiveLR = _ref.adaptiveLR,\n            adaptiveLR = _ref$adaptiveLR === undefined ? \"noAdaptiveLR\" : _ref$adaptiveLR,\n            _ref$activation = _ref.activation,\n            activation = _ref$activation === undefined ? \"sigmoid\" : _ref$activation,\n            _ref$cost = _ref.cost,\n            cost = _ref$cost === undefined ? \"crossEntropy\" : _ref$cost,\n            rmsDecay = _ref.rmsDecay,\n            rho = _ref.rho;\n\n        _classCallCheck(this, Network);\n\n        this.state = \"not-defined\";\n        this.layers = [];\n        this.epochs = 0;\n        this.iterations = 0;\n\n        if (learningRate != null) {\n            this.learningRate = learningRate;\n        }\n\n        switch (true) {\n\n            case adaptiveLR == \"RMSProp\":\n                this.learningRate = this.learningRate == undefined ? 0.001 : this.learningRate;\n                break;\n\n            case adaptiveLR == \"adam\":\n                this.learningRate = this.learningRate == undefined ? 0.01 : this.learningRate;\n                break;\n\n            case adaptiveLR == \"adadelta\":\n                this.rho = rho == null ? 0.95 : rho;\n                break;\n\n            default:\n                this.learningRate = this.learningRate == undefined ? 0.2 : this.learningRate;\n        }\n\n        this.adaptiveLR = [false, null, undefined].includes(adaptiveLR) ? \"noAdaptiveLR\" : adaptiveLR;\n        this.weightUpdateFn = NetMath[this.adaptiveLR];\n        this.activation = NetMath[activation];\n        this.cost = NetMath[cost];\n\n        if (this.adaptiveLR == \"RMSProp\") {\n            this.rmsDecay = rmsDecay == undefined ? 0.99 : rmsDecay;\n        }\n\n        if (layers.length) {\n\n            switch (true) {\n\n                case layers.every(function (item) {\n                    return Number.isInteger(item);\n                }):\n                    this.layers = layers.map(function (size) {\n                        return new Layer(size);\n                    });\n                    this.state = \"constructed\";\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item instanceof Layer;\n                }):\n                    this.state = \"constructed\";\n                    this.layers = layers;\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item === Layer;\n                }):\n                    this.state = \"defined\";\n                    this.definedLayers = layers;\n                    break;\n\n                default:\n                    throw new Error(\"There was an error constructing from the layers given.\");\n            }\n        }\n    }\n\n    _createClass(Network, [{\n        key: \"initLayers\",\n        value: function initLayers(input, expected) {\n            var _this4 = this;\n\n            switch (this.state) {\n\n                case \"initialised\":\n                    return;\n\n                case \"defined\":\n                    this.layers = this.definedLayers.map(function (layer, li) {\n                        if (!li) return new layer(input);\n\n                        if (li == _this4.definedLayers.length - 1) return new layer(expected);\n\n                        var hidden = _this4.definedLayers.length - 2;\n                        var size = input / expected > 5 ? expected + (expected + Math.abs(input - expected) / 4) * (hidden - li + 1) / (hidden / 2) : input >= expected ? input + expected * (hidden - li) / (hidden / 2) : expected + input * (hidden - li) / (hidden / 2);\n\n                        return new layer(Math.max(Math.round(size), 0));\n                    });\n                    break;\n\n                case \"not-defined\":\n                    this.layers[0] = new Layer(input);\n                    this.layers[1] = new Layer(Math.ceil(input / expected > 5 ? expected + Math.abs(input - expected) / 4 : input + expected));\n                    this.layers[2] = new Layer(Math.ceil(expected));\n                    break;\n            }\n\n            this.layers.forEach(this.joinLayer.bind(this));\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"joinLayer\",\n        value: function joinLayer(layer, layerIndex) {\n\n            layer.activation = this.activation;\n            layer.adaptiveLR = this.adaptiveLR;\n\n            if (this.rho != undefined) {\n                layer.rho = this.rho;\n            }\n\n            if (layerIndex) {\n                this.layers[layerIndex - 1].assignNext(layer);\n                layer.assignPrev(this.layers[layerIndex - 1]);\n            }\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n\n            if (this.state != \"initialised\") {\n                throw new Error(\"The network layers have not been initialised.\");\n            }\n\n            if (data === undefined) {\n                throw new Error(\"No data passed to Network.forward()\");\n            }\n\n            if (data.length != this.layers[0].neurons.length) {\n                console.warn(\"Input data length did not match input layer neurons count.\");\n            }\n\n            this.layers[0].neurons.forEach(function (neuron, ni) {\n                return neuron.activation = data[ni];\n            });\n            this.layers.forEach(function (layer, li) {\n                return li && layer.forward(data);\n            });\n            return this.layers[this.layers.length - 1].neurons.map(function (n) {\n                return n.activation;\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            if (expected === undefined) {\n                throw new Error(\"No data passed to Network.backward()\");\n            }\n\n            if (expected.length != this.layers[this.layers.length - 1].neurons.length) {\n                console.warn(\"Expected data length did not match output layer neurons count.\");\n            }\n\n            this.layers[this.layers.length - 1].backward(expected);\n\n            for (var layerIndex = this.layers.length - 2; layerIndex > 0; layerIndex--) {\n                this.layers[layerIndex].backward();\n            }\n        }\n    }, {\n        key: \"train\",\n        value: function train(dataSet) {\n            var _this5 = this;\n\n            var _ref2 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref2$epochs = _ref2.epochs,\n                epochs = _ref2$epochs === undefined ? 1 : _ref2$epochs,\n                callback = _ref2.callback;\n\n            return new Promise(function (resolve, reject) {\n\n                if (dataSet === undefined || dataSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                if (_this5.state != \"initialised\") {\n                    _this5.initLayers(dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length);\n                }\n\n                var iterationIndex = 0;\n                var epochsCounter = 0;\n                var error = 0;\n\n                var doEpoch = function doEpoch() {\n                    _this5.epochs++;\n                    iterationIndex = 0;\n\n                    doIteration();\n                };\n\n                var doIteration = function doIteration() {\n\n                    if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || !dataSet[iterationIndex].hasOwnProperty(\"expected\") && !dataSet[iterationIndex].hasOwnProperty(\"output\")) {\n                        return reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\");\n                    }\n\n                    _this5.resetDeltaWeights();\n\n                    var input = dataSet[iterationIndex].input;\n                    var output = _this5.forward(input);\n                    var target = dataSet[iterationIndex].expected || dataSet[iterationIndex].output;\n\n                    _this5.backward(target);\n                    _this5.applyDeltaWeights();\n\n                    var iterationError = _this5.cost(target, output);\n                    error += iterationError;\n\n                    if (typeof callback == \"function\") {\n                        callback({\n                            iterations: _this5.iterations,\n                            error: iterationError,\n                            input: input\n                        });\n                    }\n\n                    _this5.iterations++;\n                    iterationIndex++;\n\n                    if (iterationIndex < dataSet.length) {\n                        setTimeout(doIteration.bind(_this5), 0);\n                    } else {\n\n                        epochsCounter++;\n                        console.log(\"Epoch: \" + epochsCounter + \" Error: \" + error / 100);\n\n                        if (epochsCounter < epochs) {\n                            doEpoch();\n                        } else resolve();\n                    }\n                };\n\n                doEpoch();\n            });\n        }\n    }, {\n        key: \"test\",\n        value: function test(testSet) {\n            var _this6 = this;\n\n            return new Promise(function (resolve, reject) {\n\n                if (testSet === undefined || testSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                var totalError = 0;\n                var testIteration = 0;\n\n                var testInput = function testInput() {\n\n                    console.log(\"Testing iteration\", testIteration + 1, totalError / (testIteration + 1));\n\n                    var output = _this6.forward(testSet[testIteration].input);\n                    var target = testSet[testIteration].expected || testSet[testIteration].output;\n\n                    totalError += _this6.cost(target, output);\n\n                    testIteration++;\n\n                    if (testIteration < testSet.length) setTimeout(testInput.bind(_this6), 0);else resolve(totalError / testSet.length);\n                };\n                testInput();\n            });\n        }\n    }, {\n        key: \"resetDeltaWeights\",\n        value: function resetDeltaWeights() {\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    neuron.deltaWeights = neuron.weights.map(function (dw) {\n                        return 0;\n                    });\n                });\n            });\n        }\n    }, {\n        key: \"applyDeltaWeights\",\n        value: function applyDeltaWeights() {\n            var _this7 = this;\n\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    neuron.deltaWeights.forEach(function (dw, dwi) {\n                        neuron.weights[dwi] = _this7.weightUpdateFn.bind(_this7, neuron.weights[dwi], dw, neuron, dwi)();\n                    });\n                    neuron.bias = _this7.weightUpdateFn.bind(_this7, neuron.bias, neuron.deltaBias, neuron)();\n                });\n            });\n        }\n    }, {\n        key: \"toJSON\",\n        value: function toJSON() {\n            return {\n                layers: this.layers.map(function (layer) {\n                    return {\n                        neurons: layer.neurons.map(function (neuron) {\n                            return {\n                                bias: neuron.bias,\n                                weights: neuron.weights\n                            };\n                        })\n                    };\n                })\n            };\n        }\n    }, {\n        key: \"fromJSON\",\n        value: function fromJSON(data) {\n\n            if (data === undefined || data === null) {\n                throw new Error(\"No JSON data given to import.\");\n            }\n\n            this.layers = data.layers.map(function (layer) {\n                return new Layer(layer.neurons.length, layer.neurons);\n            });\n            this.state = \"constructed\";\n            this.initLayers();\n        }\n    }]);\n\n    return Network;\n}();\n\ntypeof window == \"undefined\" && (global.Network = Network);\n\"use strict\";\n\nvar Neuron = function () {\n    function Neuron(importedData) {\n        _classCallCheck(this, Neuron);\n\n        if (importedData) {\n            this.imported = true;\n            this.weights = importedData.weights || [];\n            this.bias = importedData.bias;\n        }\n    }\n\n    _createClass(Neuron, [{\n        key: \"init\",\n        value: function init(size, adaptiveLR) {\n            if (!this.imported) {\n                this.weights = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                    return Math.random() * 0.2 - 0.1;\n                });\n                this.bias = Math.random() * 0.2 - 0.1;\n            }\n\n            this.deltaWeights = this.weights.map(function (v) {\n                return 0;\n            });\n\n            switch (adaptiveLR) {\n                case \"gain\":\n                    this.weightGains = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 1;\n                    });\n                    this.biasGain = 1;\n                    break;\n\n                case \"adagrad\":\n                case \"RMSProp\":\n                case \"adadelta\":\n                    this.biasCache = 0;\n                    this.weightsCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 0;\n                    });\n\n                    if (adaptiveLR == \"adadelta\") {\n                        this.adadeltaCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                            return 0;\n                        });\n                        this.adadeltaBiasCache = 0;\n                    }\n                    break;\n\n                case \"adam\":\n                    this.m = 0;\n                    this.v = 0;\n                    break;\n            }\n        }\n    }]);\n\n    return Neuron;\n}();\n\ntypeof window == \"undefined\" && (global.Neuron = Neuron);\n//# sourceMappingURL=Network.concat.js.map\n//# sourceMappingURL=Network.min.js.map\n"]}