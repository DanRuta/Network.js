{"version":3,"sources":["Network.min.js"],"names":["_toConsumableArray","arr","Array","isArray","i","arr2","length","from","_classCallCheck","instance","Constructor","TypeError","_createClass","defineProperties","target","props","descriptor","enumerable","configurable","writable","Object","defineProperty","key","protoProps","staticProps","prototype","Layer","size","importedData","this","neurons","concat","map","n","ni","Neuron","undefined","state","value","layer","nextLayer","_this","prevLayer","forEach","neuron","init","adaptiveLR","activationConfig","eluAlpha","data","_this2","dropped","Math","random","dropout","activation","sum","bias","pNeuron","pni","weights","expected","_this3","error","deltaBias","derivative","reduce","p","c","weight","wi","deltaWeights","l2","l1","window","global","NetMath","prime","val","exp","pow","max","lreluSlope","abs","rreluSlope","sech","tanh","elu","output","vi","log","calculated","desired","index","prev","curr","deltaValue","learningRate","weightI","newVal","biasGain","weightGains","min","weightsCache","biasCache","sqrt","rmsDecay","m","mt","iterations","v","vt","rho","adadeltaCache","_newVal","adadeltaBiasCache","values","total","maxNormTotal","maxNorm","multiplier","layers","li","w","Network","_ref","arguments","_ref$layers","_ref$adaptiveLR","_ref$activation","_ref$cost","cost","_ref$dropout","epochs","l2Error","l1Error","includes","weightUpdateFn","bind","every","item","Number","isInteger","initLayers","definedLayers","Error","input","_this4","hidden","round","ceil","joinLayer","layerIndex","assignNext","assignPrev","console","warn","forward","backward","dataSet","_this5","_ref2","_ref2$epochs","callback","Promise","resolve","reject","iterationIndex","epochsCounter","doEpoch","doIteration","hasOwnProperty","resetDeltaWeights","applyDeltaWeights","iterationError","setTimeout","testSet","_this6","totalError","testIteration","testInput","dw","_this7","dwi","imported","_ref3"],"mappings":"AAAA,aAIA,SAASA,mBAAmBC,GAAO,GAAIC,MAAMC,QAAQF,GAAM,CAAE,IAAK,IAAIG,EAAI,EAAGC,EAAOH,MAAMD,EAAIK,QAASF,EAAIH,EAAIK,OAAQF,IAAOC,EAAKD,GAAKH,EAAIG,GAAM,OAAOC,EAAe,OAAOH,MAAMK,KAAKN,GAE1L,SAASO,gBAAgBC,EAAUC,GAAe,KAAMD,aAAoBC,GAAgB,MAAM,IAAIC,UAAU,qCAJhH,IAAIC,aAAe,WAAc,SAASC,EAAiBC,EAAQC,GAAS,IAAK,IAAIX,EAAI,EAAGA,EAAIW,EAAMT,OAAQF,IAAK,CAAE,IAAIY,EAAaD,EAAMX,GAAIY,EAAWC,WAAaD,EAAWC,aAAc,EAAOD,EAAWE,cAAe,EAAU,UAAWF,IAAYA,EAAWG,UAAW,GAAMC,OAAOC,eAAeP,EAAQE,EAAWM,IAAKN,IAAiB,OAAO,SAAUN,EAAaa,EAAYC,GAAiJ,OAA9HD,GAAYV,EAAiBH,EAAYe,UAAWF,GAAiBC,GAAaX,EAAiBH,EAAac,GAAqBd,MAM5hBgB,MAAQ,WACR,SAASA,EAAMC,EAAMC,GACjBpB,gBAAgBqB,KAAMH,GAEtBG,KAAKF,KAAOA,EACZE,KAAKC,WAAaC,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAUC,EAAGC,GAC3E,OAAO,IAAIC,OAAOP,EAAeA,EAAaM,QAAME,KAExDP,KAAKQ,MAAQ,kBAyEjB,OAtEAzB,aAAac,IACTJ,IAAK,aACLgB,MAAO,SAAoBC,GACvBV,KAAKW,UAAYD,KAGrBjB,IAAK,aACLgB,MAAO,SAAoBC,GACvB,IAAIE,EAAQZ,KAEZA,KAAKa,UAAYH,EACjBV,KAAKC,QAAQa,QAAQ,SAAUC,GAC3B,OAAOA,EAAOC,KAAKN,EAAMZ,MACrBmB,WAAYL,EAAMK,WAClBC,iBAAkBN,EAAMM,iBACxBC,SAAUP,EAAMO,aAGxBnB,KAAKQ,MAAQ,iBAGjBf,IAAK,UACLgB,MAAO,SAAiBW,GACpB,IAAIC,EAASrB,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAEf,YAAhBgB,EAAOb,QAAwBO,EAAOO,QAAUC,KAAKC,SAAWH,EAAOI,SACvEV,EAAOW,WAAa,GAEpBX,EAAOY,IAAMZ,EAAOa,KACpBP,EAAOR,UAAUZ,QAAQa,QAAQ,SAAUe,EAASC,GAChD,OAAOf,EAAOY,KAAOE,EAAQH,WAAaX,EAAOgB,QAAQD,KAE7Df,EAAOW,WAAaL,EAAOK,WAAWX,EAAOY,KAAK,EAAOZ,IAA4B,EAAjBM,EAAOI,eAKvFhC,IAAK,WACLgB,MAAO,SAAkBuB,GACrB,IAAIC,EAASjC,KAEbA,KAAKC,QAAQa,QAAQ,SAAUC,EAAQV,GAE/BU,EAAOO,SACPP,EAAOmB,MAAQ,EACfnB,EAAOoB,UAAY,SAEK,IAAbH,EACPjB,EAAOmB,MAAQF,EAAS3B,GAAMU,EAAOW,YAErCX,EAAOqB,WAAaH,EAAOP,WAAWX,EAAOY,KAAK,EAAMZ,GACxDA,EAAOmB,MAAQnB,EAAOqB,WAAaH,EAAOtB,UAAUV,QAAQE,IAAI,SAAUC,GACtE,OAAOA,EAAE8B,OAAyB,EAAhB9B,EAAE2B,QAAQ1B,MAC7BgC,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,IAGPxB,EAAOgB,QAAQjB,QAAQ,SAAU0B,EAAQC,GACrC1B,EAAO2B,aAAaD,IAAO1B,EAAOmB,MAAQD,EAAOpB,UAAUZ,QAAQwC,GAAIf,YAAc,IAAMO,EAAOU,IAAM,IAAMV,EAAOW,IAAM,IAAM7B,EAAO2B,aAAaD,MAGzJ1B,EAAOoB,UAAYpB,EAAOmB,aAMnCrC,KAGM,oBAAVgD,SAA0BC,OAAOjD,MAAQA,OAGhD,IAAIkD,QAAU,WACV,SAASA,IACLpE,gBAAgBqB,KAAM+C,GAyK1B,OAtKAhE,aAAagE,EAAS,OAClBtD,IAAK,UAILgB,MAAO,SAAiBA,EAAOuC,GAC3B,IAAIC,EAAM,GAAK,EAAI1B,KAAK2B,KAAKzC,IAC7B,OAAOuC,EAAQC,GAAO,EAAIA,GAAOA,KAGrCxD,IAAK,OACLgB,MAAO,SAAcA,EAAOuC,GACxB,IAAIE,EAAM3B,KAAK2B,IAAI,EAAIzC,GACvB,OAAOuC,EAAQ,EAAIzB,KAAK4B,IAAI5B,KAAK2B,IAAIzC,GAASc,KAAK2B,KAAKzC,GAAQ,IAAM,OAASyC,EAAM,IAAMA,EAAM,IAAM,SAG3GzD,IAAK,OACLgB,MAAO,SAAcA,EAAOuC,GACxB,OAAOA,EAAQvC,EAAQ,EAAI,EAAI,EAAIc,KAAK6B,IAAI3C,EAAO,MAGvDhB,IAAK,QACLgB,MAAO,SAAeA,EAAOuC,GACzB,OAAOA,EAAQvC,EAAQ,EAAI,EAAIT,KAAKqD,WAAa9B,KAAK6B,IAAIpD,KAAKqD,WAAa9B,KAAK+B,IAAI7C,GAAQA,MAGjGhB,IAAK,QACLgB,MAAO,SAAeA,EAAOuC,EAAOjC,GAChC,OAAOiC,EAAQvC,EAAQ,EAAI,EAAIM,EAAOwC,WAAahC,KAAK6B,IAAIrC,EAAOwC,WAAY9C,MAGnFhB,IAAK,YACLgB,MAAO,SAAmBA,EAAOuC,GAC7B,OAAOA,EAAQ,QAAUzB,KAAK4B,IAAIJ,EAAQS,KAAK,EAAI,EAAI/C,GAAQ,GAAK,OAASsC,EAAQU,KAAK,EAAI,EAAIhD,MAGtGhB,IAAK,MACLgB,MAAO,SAAaA,EAAOuC,EAAOjC,GAC9B,OAAOiC,EAAQvC,GAAS,EAAI,EAAIsC,EAAQW,IAAIjD,GAAO,EAAOM,GAAUA,EAAOI,SAAWV,GAAS,EAAIA,EAAQM,EAAOI,UAAYI,KAAK2B,IAAIzC,GAAS,MAMpJhB,IAAK,eACLgB,MAAO,SAAsBxB,EAAQ0E,GACjC,OAAOA,EAAOxD,IAAI,SAAUM,EAAOmD,GAC/B,OAAO3E,EAAO2E,GAAMrC,KAAKsC,IAAIpD,EAAQ,QAAU,EAAIxB,EAAO2E,IAAOrC,KAAKsC,IAAI,EAAI,MAAQpD,KACvF4B,OAAO,SAAUC,EAAGC,GACnB,OAAOD,EAAIC,GACZ,MAGP9C,IAAK,mBACLgB,MAAO,SAA0BqD,EAAYC,GACzC,OAAOD,EAAW3D,IAAI,SAAUwD,EAAQK,GACpC,OAAOzC,KAAK4B,IAAIQ,EAASI,EAAQC,GAAQ,KAC1C3B,OAAO,SAAU4B,EAAMC,GACtB,OAAOD,EAAOC,GACf,GAAKJ,EAAWrF,UAMvBgB,IAAK,eACLgB,MAAO,SAAsBA,EAAO0D,GAChC,OAAO1D,EAAQT,KAAKoE,aAAeD,KAGvC1E,IAAK,OACLgB,MAAO,SAAcA,EAAO0D,EAAYpD,EAAQsD,GAE5C,IAAIC,EAAS7D,EAAQT,KAAKoE,aAAeD,GAAyB,MAAXE,EAAkBtD,EAAOwD,SAAWxD,EAAOyD,YAAYH,IAQ9G,OANIC,GAAU,GAAK7D,EAAQ,GAAK6D,GAAU,GAAK7D,EAAQ,EACpC,MAAX4D,EAAiBtD,EAAOyD,YAAYH,GAAW9C,KAAK6B,IAAkC,IAA9BrC,EAAOyD,YAAYH,GAAiB,IAAUtD,EAAOwD,SAAWhD,KAAK6B,IAAsB,IAAlBrC,EAAOwD,SAAiB,IAE9I,MAAXF,EAAiBtD,EAAOyD,YAAYH,GAAW9C,KAAKkD,IAAI1D,EAAOyD,YAAYH,GAAW,IAAM,GAAQtD,EAAOwD,SAAWhD,KAAKkD,IAAI1D,EAAOwD,SAAW,IAAM,GAGxJD,KAGX7E,IAAK,UACLgB,MAAO,SAAiBA,EAAO0D,EAAYpD,EAAQsD,GAI/C,OAFe,MAAXA,EAAiBtD,EAAO2D,aAAaL,IAAY9C,KAAK4B,IAAIgB,EAAY,GAAQpD,EAAO4D,WAAapD,KAAK4B,IAAIgB,EAAY,GAEpH1D,EAAQT,KAAKoE,aAAeD,GAAc,KAAO5C,KAAKqD,KAAgB,MAAXP,EAAkBtD,EAAO2D,aAAaL,GAAWtD,EAAO4D,eAG9HlF,IAAK,UACLgB,MAAO,SAAiBA,EAAO0D,EAAYpD,EAAQsD,GAI/C,OAFe,MAAXA,EAAiBtD,EAAO2D,aAAaL,GAAWrE,KAAK6E,SAAW9D,EAAO2D,aAAaL,IAAY,EAAIrE,KAAK6E,UAAYtD,KAAK4B,IAAIgB,EAAY,GAAQpD,EAAO4D,UAAY3E,KAAK6E,SAAW9D,EAAO4D,WAAa,EAAI3E,KAAK6E,UAAYtD,KAAK4B,IAAIgB,EAAY,GAEhP1D,EAAQT,KAAKoE,aAAeD,GAAc,KAAO5C,KAAKqD,KAAgB,MAAXP,EAAkBtD,EAAO2D,aAAaL,GAAWtD,EAAO4D,eAG9HlF,IAAK,OACLgB,MAAO,SAAcA,EAAO0D,EAAYpD,GAEpCA,EAAO+D,EAAI,GAAM/D,EAAO+D,GAAK,EAAI,IAAOX,EACxC,IAAIY,EAAKhE,EAAO+D,GAAK,EAAIvD,KAAK4B,IAAI,GAAKnD,KAAKgF,WAAa,IAEzDjE,EAAOkE,EAAI,KAAQlE,EAAOkE,GAAK,EAAI,MAAS1D,KAAK4B,IAAIgB,EAAY,GACjE,IAAIe,EAAKnE,EAAOkE,GAAK,EAAI1D,KAAK4B,IAAI,KAAOnD,KAAKgF,WAAa,IAE3D,OAAOvE,EAAQT,KAAKoE,aAAeW,GAAMxD,KAAKqD,KAAKM,GAAM,SAG7DzF,IAAK,WACLgB,MAAO,SAAkBA,EAAO0D,EAAYpD,EAAQsD,GAEhD,GAAe,MAAXA,EAAiB,CACjBtD,EAAO2D,aAAaL,GAAWrE,KAAKmF,IAAMpE,EAAO2D,aAAaL,IAAY,EAAIrE,KAAKmF,KAAO5D,KAAK4B,IAAIgB,EAAY,GAC/G,IAAIG,EAAS7D,EAAQc,KAAKqD,MAAM7D,EAAOqE,cAAcf,GAAW,OAAStD,EAAO2D,aAAaL,GAAW,OAASF,EAEjH,OADApD,EAAOqE,cAAcf,GAAWrE,KAAKmF,IAAMpE,EAAOqE,cAAcf,IAAY,EAAIrE,KAAKmF,KAAO5D,KAAK4B,IAAIgB,EAAY,GAC1GG,EAEPvD,EAAO4D,UAAY3E,KAAKmF,IAAMpE,EAAO4D,WAAa,EAAI3E,KAAKmF,KAAO5D,KAAK4B,IAAIgB,EAAY,GACvF,IAAIkB,EAAU5E,EAAQc,KAAKqD,MAAM7D,EAAOuE,kBAAoB,OAASvE,EAAO4D,UAAY,OAASR,EAEjG,OADApD,EAAOuE,kBAAoBtF,KAAKmF,IAAMpE,EAAOuE,mBAAqB,EAAItF,KAAKmF,KAAO5D,KAAK4B,IAAIgB,EAAY,GAChGkB,KAOf5F,IAAK,UACLgB,MAAO,SAAiB8E,GACpB,IAAIC,EAAQD,EAAOlD,OAAO,SAAU4B,EAAMC,GACtC,OAAOD,EAAOC,GACf,GACH,OAAOqB,EAAOpF,IAAI,SAAUM,GACxB,OAAOA,EAAQ+E,OAIvB/F,IAAK,OACLgB,MAAO,SAAcA,GACjB,OAAO,EAAIc,KAAK2B,KAAKzC,IAAU,EAAIc,KAAK2B,KAAK,EAAIzC,OAGrDhB,IAAK,UACLgB,MAAO,WAEH,GAAIT,KAAKyF,aAAezF,KAAK0F,QAAS,CAElC,IAAIC,EAAa3F,KAAK0F,SAAW,MAAQ1F,KAAKyF,cAE9CzF,KAAK4F,OAAO9E,QAAQ,SAAUJ,EAAOmF,GACjCA,GAAMnF,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAOgB,QAAQjB,QAAQ,SAAUgF,EAAGrD,GAChC1B,EAAOgB,QAAQU,IAAOkD,QAMtC3F,KAAKyF,aAAe,MAIrB1C,KAGM,oBAAVF,SAA0BC,OAAOC,QAAUA,SAGlD,IAAIgD,QAAU,WACV,SAASA,IACL,IAAIC,EAAOC,UAAUxH,OAAS,QAAsB8B,IAAjB0F,UAAU,GAAmBA,UAAU,MACtE7B,EAAe4B,EAAK5B,aACpB8B,EAAcF,EAAKJ,OACnBA,OAAyBrF,IAAhB2F,KAAiCA,EAC1CC,EAAkBH,EAAK/E,WACvBA,OAAiCV,IAApB4F,EAAgC,eAAiBA,EAC9DC,EAAkBJ,EAAKtE,WACvBA,OAAiCnB,IAApB6F,EAAgC,UAAYA,EACzDC,EAAYL,EAAKM,KACjBA,OAAqB/F,IAAd8F,EAA0B,eAAiBA,EAClDxB,EAAWmB,EAAKnB,SAChBM,EAAMa,EAAKb,IACX9B,EAAa2C,EAAK3C,WAClBlC,EAAW6E,EAAK7E,SAChBoF,EAAeP,EAAKvE,QACpBA,OAA2BlB,IAAjBgG,EAA6B,GAAMA,EAC7C5D,EAAKqD,EAAKrD,GACVC,EAAKoD,EAAKpD,GACV8C,EAAUM,EAAKN,QA8BnB,OA5BA/G,gBAAgBqB,KAAM+F,GAEtB/F,KAAKQ,MAAQ,cACbR,KAAK4F,UACL5F,KAAKwG,OAAS,EACdxG,KAAKgF,WAAa,EAClBhF,KAAKyB,QAAqB,GAAXA,EAAmB,EAAIA,EACtCzB,KAAKkC,MAAQ,EAEO,MAAhBkC,IACApE,KAAKoE,aAAeA,GAGpBzB,IACA3C,KAAK2C,GAAkB,kBAANA,GAAmBA,EAAK,KAAQA,EACjD3C,KAAKyG,QAAU,GAGf7D,IACA5C,KAAK4C,GAAkB,kBAANA,GAAmBA,EAAK,KAAQA,EACjD5C,KAAK0G,QAAU,GAGfhB,IACA1F,KAAK0F,QAA4B,kBAAXA,GAAwBA,EAAU,IAAOA,EAC/D1F,KAAKyF,aAAe,IAGhB,GAEJ,IAAmB,WAAdxE,EACDjB,KAAKoE,kBAAoC7D,GAArBP,KAAKoE,aAA4B,KAAQpE,KAAKoE,aAClE,MAEJ,IAAmB,QAAdnD,EACDjB,KAAKoE,kBAAoC7D,GAArBP,KAAKoE,aAA4B,IAAOpE,KAAKoE,aACjE,MAEJ,IAAmB,YAAdnD,EACDjB,KAAKmF,IAAa,MAAPA,EAAc,IAAOA,EAChC,MAEJ,QAEI,QAAyB5E,GAArBP,KAAKoE,aACL,OAAQ1C,GACJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACD1B,KAAKoE,aAAe,IACpB,MACJ,IAAK,OACL,IAAK,YACDpE,KAAKoE,aAAe,KACpB,MACJ,QACIpE,KAAKoE,aAAe,IAqBxC,GAhBApE,KAAKiB,aAAc,EAAO,UAAMV,GAAWoG,SAAS1F,GAAc,eAAiBA,EACnFjB,KAAK4G,eAAiB7D,QAAQ/C,KAAKiB,YACnCjB,KAAK0B,WAAaqB,QAAQrB,GAAYmF,KAAK7G,MAC3CA,KAAKkB,iBAAmBQ,EACxB1B,KAAKsG,KAAOvD,QAAQuD,GAEG,WAAnBtG,KAAKiB,aACLjB,KAAK6E,cAAuBtE,GAAZsE,EAAwB,IAAOA,GAGjC,SAAdnD,EACA1B,KAAKqD,gBAA2B9C,GAAd8C,GAA2B,KAASA,EACjC,OAAd3B,IACP1B,KAAKmB,cAAuBZ,GAAZY,EAAwB,EAAIA,GAG5CyE,EAAOnH,OAEP,QAAQ,GAEJ,KAAKmH,EAAOkB,MAAM,SAAUC,GACxB,OAAOC,OAAOC,UAAUF,KAExB/G,KAAK4F,OAASA,EAAOzF,IAAI,SAAUL,GAC/B,OAAO,IAAID,MAAMC,KAErBE,KAAKQ,MAAQ,cACbR,KAAKkH,aACL,MAEJ,KAAKtB,EAAOkB,MAAM,SAAUC,GACxB,OAAOA,aAAgBlH,QAEvBG,KAAKQ,MAAQ,cACbR,KAAK4F,OAASA,EACd5F,KAAKkH,aACL,MAEJ,KAAKtB,EAAOkB,MAAM,SAAUC,GACxB,OAAOA,IAASlH,QAEhBG,KAAKQ,MAAQ,UACbR,KAAKmH,cAAgBvB,EACrB,MAEJ,QACI,MAAM,IAAIwB,MAAM,2DAsThC,OAjTArI,aAAagH,IACTtG,IAAK,aACLgB,MAAO,SAAoB4G,EAAOrF,GAC9B,IAAIsF,EAAStH,KAEb,OAAQA,KAAKQ,OAET,IAAK,cACD,OAEJ,IAAK,UACDR,KAAK4F,OAAS5F,KAAKmH,cAAchH,IAAI,SAAUO,EAAOmF,GAElD,IAAKA,EAAI,OAAO,IAAInF,EAAM2G,GAE1B,GAAIxB,GAAMyB,EAAOH,cAAc1I,OAAS,EAAG,OAAO,IAAIiC,EAAMsB,GAE5D,IAAIuF,EAASD,EAAOH,cAAc1I,OAAS,EACvCqB,EAAOuH,EAAQrF,EAAW,EAAIA,GAAYA,EAAWT,KAAK+B,IAAI+D,EAAQrF,GAAY,IAAMuF,EAAS1B,EAAK,IAAM0B,EAAS,GAAKF,GAASrF,EAAWqF,EAAQrF,GAAYuF,EAAS1B,IAAO0B,EAAS,GAAKvF,EAAWqF,GAASE,EAAS1B,IAAO0B,EAAS,GAEjP,OAAO,IAAI7G,EAAMa,KAAK6B,IAAI7B,KAAKiG,MAAM1H,GAAO,MAEhD,MAEJ,IAAK,cACDE,KAAK4F,OAAO,GAAK,IAAI/F,MAAMwH,GAC3BrH,KAAK4F,OAAO,GAAK,IAAI/F,MAAM0B,KAAKkG,KAAKJ,EAAQrF,EAAW,EAAIA,EAAWT,KAAK+B,IAAI+D,EAAQrF,GAAY,EAAIqF,EAAQrF,IAChHhC,KAAK4F,OAAO,GAAK,IAAI/F,MAAM0B,KAAKkG,KAAKzF,IAI7ChC,KAAK4F,OAAO9E,QAAQd,KAAK0H,UAAUb,KAAK7G,OACxCA,KAAKQ,MAAQ,iBAGjBf,IAAK,YACLgB,MAAO,SAAmBC,EAAOiH,GAE7BjH,EAAMgB,WAAa1B,KAAK0B,WACxBhB,EAAMO,WAAajB,KAAKiB,WACxBP,EAAMQ,iBAAmBlB,KAAKkB,iBAC9BR,EAAMe,QAAUzB,KAAKyB,aAELlB,GAAZP,KAAKmF,MACLzE,EAAMyE,IAAMnF,KAAKmF,UAGA5E,GAAjBP,KAAKmB,WACLT,EAAMS,SAAWnB,KAAKmB,eAGXZ,GAAXP,KAAK2C,KACLjC,EAAMiC,GAAK3C,KAAK2C,SAGLpC,GAAXP,KAAK4C,KACLlC,EAAMkC,GAAK5C,KAAK4C,IAGhB+E,IACA3H,KAAK4F,OAAO+B,EAAa,GAAGC,WAAWlH,GACvCA,EAAMmH,WAAW7H,KAAK4F,OAAO+B,EAAa,QAIlDlI,IAAK,UACLgB,MAAO,SAAiBW,GAEpB,GAAkB,eAAdpB,KAAKQ,MACL,MAAM,IAAI4G,MAAM,iDAGpB,QAAa7G,IAATa,EACA,MAAM,IAAIgG,MAAM,uCAapB,OAVIhG,EAAK3C,QAAUuB,KAAK4F,OAAO,GAAG3F,QAAQxB,QACtCqJ,QAAQC,KAAK,8DAGjB/H,KAAK4F,OAAO,GAAG3F,QAAQa,QAAQ,SAAUC,EAAQV,GAC7C,OAAOU,EAAOW,WAAaN,EAAKf,KAEpCL,KAAK4F,OAAO9E,QAAQ,SAAUJ,EAAOmF,GACjC,OAAOA,GAAMnF,EAAMsH,QAAQ5G,KAExBpB,KAAK4F,OAAO5F,KAAK4F,OAAOnH,OAAS,GAAGwB,QAAQE,IAAI,SAAUC,GAC7D,OAAOA,EAAEsB,gBAIjBjC,IAAK,WACLgB,MAAO,SAAkBuB,GACrB,QAAiBzB,IAAbyB,EACA,MAAM,IAAIoF,MAAM,wCAGhBpF,EAASvD,QAAUuB,KAAK4F,OAAO5F,KAAK4F,OAAOnH,OAAS,GAAGwB,QAAQxB,QAC/DqJ,QAAQC,KAAK,kEAGjB/H,KAAK4F,OAAO5F,KAAK4F,OAAOnH,OAAS,GAAGwJ,SAASjG,GAE7C,IAAK,IAAI2F,EAAa3H,KAAK4F,OAAOnH,OAAS,EAAGkJ,EAAa,EAAGA,IAC1D3H,KAAK4F,OAAO+B,GAAYM,cAIhCxI,IAAK,QACLgB,MAAO,SAAeyH,GAClB,IAAIC,EAASnI,KAEToI,EAAQnC,UAAUxH,OAAS,QAAsB8B,IAAjB0F,UAAU,GAAmBA,UAAU,MACvEoC,EAAeD,EAAM5B,OACrBA,OAA0BjG,IAAjB8H,EAA6B,EAAIA,EAC1CC,EAAWF,EAAME,SAErB,OAAO,IAAIC,QAAQ,SAAUC,EAASC,QAElBlI,IAAZ2H,GAAqC,OAAZA,GACzBO,EAAO,oBAGS,eAAhBN,EAAO3H,OACP2H,EAAOjB,WAAWgB,EAAQ,GAAGb,MAAM5I,QAASyJ,EAAQ,GAAGlG,UAAYkG,EAAQ,GAAGvE,QAAQlF,QAG1F0J,EAAOvC,OAAO9E,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,aAGzB,IAAIkI,EAAiB,EACjBC,EAAgB,EAEhBC,EAAU,WACVT,EAAO3B,SACP2B,EAAOjG,MAAQ,EACfwG,EAAiB,OAEKnI,GAAlB4H,EAAO1B,UACP0B,EAAO1B,QAAU,QAGClG,GAAlB4H,EAAOzB,UACPyB,EAAOzB,QAAU,GAGrBmC,KAGAA,EAAc,SAASA,IAEvB,IAAKX,EAAQQ,GAAgBI,eAAe,WAAaZ,EAAQQ,GAAgBI,eAAe,cAAgBZ,EAAQQ,GAAgBI,eAAe,UACnJ,OAAOL,EAAO,sFAGlBN,EAAOY,oBAEP,IAAI1B,EAAQa,EAAQQ,GAAgBrB,MAChC1D,EAASwE,EAAOH,QAAQX,GACxBpI,EAASiJ,EAAQQ,GAAgB1G,UAAYkG,EAAQQ,GAAgB/E,OAEzEwE,EAAOF,SAAShJ,GAChBkJ,EAAOa,oBAEP,IAAIC,EAAiBd,EAAO7B,KAAKrH,EAAQ0E,GACzCwE,EAAOjG,OAAS+G,EAEO,mBAAZX,GACPA,GACItD,WAAYmD,EAAOnD,WACnB9C,MAAO+G,EACP5B,MAAOA,IAIfc,EAAOnD,eACP0D,EAEqBR,EAAQzJ,OACzByK,WAAWL,EAAYhC,KAAKsB,GAAS,IAGrCQ,IACAb,QAAQjE,IAAI,UAAYsE,EAAO3B,OAAS,WAAa2B,EAAOjG,MAAQwG,QAA+BnI,GAAb4H,EAAOxF,GAAkB,GAAK,cAAgBwF,EAAO1B,QAAUiC,IAEjJC,EAAgBnC,EAChBoC,KAEAT,EAAOvC,OAAO9E,QAAQ,SAAUJ,GAC5B,OAAOA,EAAMF,MAAQ,gBAEzBgI,OAKZI,SAIRnJ,IAAK,OACLgB,MAAO,SAAc0I,GACjB,IAAIC,EAASpJ,KAEb,OAAO,IAAIuI,QAAQ,SAAUC,EAASC,QAElBlI,IAAZ4I,GAAqC,OAAZA,GACzBV,EAAO,oBAGX,IAAIY,EAAa,EACbC,EAAgB,GAEJ,SAASC,IAErB,IAAI5F,EAASyF,EAAOpB,QAAQmB,EAAQG,GAAejC,OAC/CpI,EAASkK,EAAQG,GAAetH,UAAYmH,EAAQG,GAAe3F,OAEvE0F,GAAcD,EAAO9C,KAAKrH,EAAQ0E,GAElCmE,QAAQjE,IAAI,oBAAqByF,EAAgB,EAAGD,GAAcC,EAAgB,MAElFA,EAEoBH,EAAQ1K,OAAQyK,WAAWK,EAAU1C,KAAKuC,GAAS,GAAQZ,EAAQa,EAAaF,EAAQ1K,gBAMxHgB,IAAK,oBACLgB,MAAO,WACHT,KAAK4F,OAAO9E,QAAQ,SAAUJ,EAAOmF,GACjCA,GAAMnF,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAO2B,aAAe3B,EAAOgB,QAAQ5B,IAAI,SAAUqJ,GAC/C,OAAO,WAMvB/J,IAAK,oBACLgB,MAAO,WACH,IAAIgJ,EAASzJ,KAEbA,KAAK4F,OAAO9E,QAAQ,SAAUJ,EAAOmF,GACjCA,GAAMnF,EAAMT,QAAQa,QAAQ,SAAUC,GAClCA,EAAO2B,aAAa5B,QAAQ,SAAU0I,EAAIE,QAErBnJ,GAAbkJ,EAAO9G,KACP8G,EAAOhD,SAAW,GAAMgD,EAAO9G,GAAKpB,KAAK4B,IAAIpC,EAAOgB,QAAQ2H,GAAM,SAGrDnJ,GAAbkJ,EAAO7G,KACP6G,EAAO/C,SAAW+C,EAAO7G,GAAKrB,KAAK+B,IAAIvC,EAAOgB,QAAQ2H,KAG1D3I,EAAOgB,QAAQ2H,GAAOD,EAAO7C,eAAeC,KAAK4C,EAAQ1I,EAAOgB,QAAQ2H,GAAMF,EAAIzI,EAAQ2I,UAEpEnJ,GAAlBkJ,EAAO/D,UACP+D,EAAOhE,cAAgBlE,KAAK4B,IAAIpC,EAAOgB,QAAQ2H,GAAM,MAG7D3I,EAAOa,KAAO6H,EAAO7C,eAAeC,KAAK4C,EAAQ1I,EAAOa,KAAMb,EAAOoB,UAAWpB,cAIpER,GAAhBP,KAAK0F,UACL1F,KAAKyF,aAAelE,KAAKqD,KAAK5E,KAAKyF,cACnC1C,QAAQ2C,QAAQmB,KAAK7G,YAI7BP,IAAK,SACLgB,MAAO,WACH,OACImF,OAAQ5F,KAAK4F,OAAOzF,IAAI,SAAUO,GAC9B,OACIT,QAASS,EAAMT,QAAQE,IAAI,SAAUY,GACjC,OACIa,KAAMb,EAAOa,KACbG,QAAShB,EAAOgB,kBAQxCtC,IAAK,WACLgB,MAAO,SAAkBW,GAErB,QAAab,IAATa,GAA+B,OAATA,EACtB,MAAM,IAAIgG,MAAM,iCAGpBpH,KAAK4F,OAASxE,EAAKwE,OAAOzF,IAAI,SAAUO,GACpC,OAAO,IAAIb,MAAMa,EAAMT,QAAQxB,OAAQiC,EAAMT,WAEjDD,KAAKQ,MAAQ,cACbR,KAAKkH,iBAINnB,KAGM,oBAAVlD,SAA0BC,OAAOiD,QAAUA,SAGlD,IAAIzF,OAAS,WACT,SAASA,EAAOP,GACZpB,gBAAgBqB,KAAMM,GAElBP,IACAC,KAAK2J,UAAW,EAChB3J,KAAK+B,QAAUhC,EAAagC,YAC5B/B,KAAK4B,KAAO7B,EAAa6B,MA6DjC,OAzDA7C,aAAauB,IACTb,IAAK,OACLgB,MAAO,SAAcX,GACjB,IAAI8J,EAAQ3D,UAAUxH,OAAS,QAAsB8B,IAAjB0F,UAAU,GAAmBA,UAAU,MACvEhF,EAAa2I,EAAM3I,WACnBC,EAAmB0I,EAAM1I,iBACzBC,EAAWyI,EAAMzI,SAarB,OAXKnB,KAAK2J,WACN3J,KAAK+B,WAAa7B,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU8E,GACxE,MAAuB,GAAhB1D,KAAKC,SAAiB,KAEjCxB,KAAK4B,KAAuB,GAAhBL,KAAKC,SAAiB,IAGtCxB,KAAK0C,aAAe1C,KAAK+B,QAAQ5B,IAAI,SAAU8E,GAC3C,OAAO,IAGHhE,GACJ,IAAK,OACDjB,KAAKwE,eAAiBtE,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU8E,GAC5E,OAAO,IAEXjF,KAAKuE,SAAW,EAChB,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACDvE,KAAK2E,UAAY,EACjB3E,KAAK0E,gBAAkBxE,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU8E,GAC7E,OAAO,IAGO,YAAdhE,IACAjB,KAAKoF,iBAAmBlF,OAAO/B,mBAAmB,IAAIE,MAAMyB,KAAQK,IAAI,SAAU8E,GAC9E,OAAO,IAEXjF,KAAKsF,kBAAoB,GAE7B,MAEJ,IAAK,OACDtF,KAAK8E,EAAI,EACT9E,KAAKiF,EAAI,EAIO,SAApB/D,EACAlB,KAAKuD,WAA6B,KAAhBhC,KAAKC,SACI,OAApBN,IACPlB,KAAKmB,SAAWA,OAKrBb,KAGM,oBAAVuC,SAA0BC,OAAOxC,OAASA","sourcesContent":["\"use strict\";\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Layer = function () {\n    function Layer(size, importedData) {\n        _classCallCheck(this, Layer);\n\n        this.size = size;\n        this.neurons = [].concat(_toConsumableArray(new Array(size))).map(function (n, ni) {\n            return new Neuron(importedData ? importedData[ni] : undefined);\n        });\n        this.state = \"not-initialised\";\n    }\n\n    _createClass(Layer, [{\n        key: \"assignNext\",\n        value: function assignNext(layer) {\n            this.nextLayer = layer;\n        }\n    }, {\n        key: \"assignPrev\",\n        value: function assignPrev(layer) {\n            var _this = this;\n\n            this.prevLayer = layer;\n            this.neurons.forEach(function (neuron) {\n                return neuron.init(layer.size, {\n                    adaptiveLR: _this.adaptiveLR,\n                    activationConfig: _this.activationConfig,\n                    eluAlpha: _this.eluAlpha\n                });\n            });\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n            var _this2 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (_this2.state == \"training\" && (neuron.dropped = Math.random() > _this2.dropout)) {\n                    neuron.activation = 0;\n                } else {\n                    neuron.sum = neuron.bias;\n                    _this2.prevLayer.neurons.forEach(function (pNeuron, pni) {\n                        return neuron.sum += pNeuron.activation * neuron.weights[pni];\n                    });\n                    neuron.activation = _this2.activation(neuron.sum, false, neuron) / (_this2.dropout | 1);\n                }\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            var _this3 = this;\n\n            this.neurons.forEach(function (neuron, ni) {\n\n                if (neuron.dropped) {\n                    neuron.error = 0;\n                    neuron.deltaBias = 0;\n                } else {\n                    if (typeof expected !== \"undefined\") {\n                        neuron.error = expected[ni] - neuron.activation;\n                    } else {\n                        neuron.derivative = _this3.activation(neuron.sum, true, neuron);\n                        neuron.error = neuron.derivative * _this3.nextLayer.neurons.map(function (n) {\n                            return n.error * (n.weights[ni] | 0);\n                        }).reduce(function (p, c) {\n                            return p + c;\n                        }, 0);\n                    }\n\n                    neuron.weights.forEach(function (weight, wi) {\n                        neuron.deltaWeights[wi] += neuron.error * _this3.prevLayer.neurons[wi].activation * (1 + ((_this3.l2 || 0) + (_this3.l1 || 0)) * neuron.deltaWeights[wi]);\n                    });\n\n                    neuron.deltaBias = neuron.error;\n                }\n            });\n        }\n    }]);\n\n    return Layer;\n}();\n\ntypeof window == \"undefined\" && (global.Layer = Layer);\n\"use strict\";\n\nvar NetMath = function () {\n    function NetMath() {\n        _classCallCheck(this, NetMath);\n    }\n\n    _createClass(NetMath, null, [{\n        key: \"sigmoid\",\n\n\n        // Activation functions\n        value: function sigmoid(value, prime) {\n            var val = 1 / (1 + Math.exp(-value));\n            return prime ? val * (1 - val) : val;\n        }\n    }, {\n        key: \"tanh\",\n        value: function tanh(value, prime) {\n            var exp = Math.exp(2 * value);\n            return prime ? 4 / Math.pow(Math.exp(value) + Math.exp(-value), 2) || 1e-18 : (exp - 1) / (exp + 1) || 1e-18;\n        }\n    }, {\n        key: \"relu\",\n        value: function relu(value, prime) {\n            return prime ? value > 0 ? 1 : 0 : Math.max(value, 0);\n        }\n    }, {\n        key: \"lrelu\",\n        value: function lrelu(value, prime) {\n            return prime ? value > 0 ? 1 : this.lreluSlope : Math.max(this.lreluSlope * Math.abs(value), value);\n        }\n    }, {\n        key: \"rrelu\",\n        value: function rrelu(value, prime, neuron) {\n            return prime ? value > 0 ? 1 : neuron.rreluSlope : Math.max(neuron.rreluSlope, value);\n        }\n    }, {\n        key: \"lecuntanh\",\n        value: function lecuntanh(value, prime) {\n            return prime ? 1.15333 * Math.pow(NetMath.sech(2 / 3 * value), 2) : 1.7159 * NetMath.tanh(2 / 3 * value);\n        }\n    }, {\n        key: \"elu\",\n        value: function elu(value, prime, neuron) {\n            return prime ? value >= 0 ? 1 : NetMath.elu(value, false, neuron) + neuron.eluAlpha : value >= 0 ? value : neuron.eluAlpha * (Math.exp(value) - 1);\n        }\n\n        // Cost functions\n\n    }, {\n        key: \"crossEntropy\",\n        value: function crossEntropy(target, output) {\n            return output.map(function (value, vi) {\n                return target[vi] * Math.log(value + 1e-15) + (1 - target[vi]) * Math.log(1 + 1e-15 - value);\n            }).reduce(function (p, c) {\n                return p - c;\n            }, 0);\n        }\n    }, {\n        key: \"meanSquaredError\",\n        value: function meanSquaredError(calculated, desired) {\n            return calculated.map(function (output, index) {\n                return Math.pow(output - desired[index], 2);\n            }).reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0) / calculated.length;\n        }\n\n        // Weight updating functions\n\n    }, {\n        key: \"noAdaptiveLR\",\n        value: function noAdaptiveLR(value, deltaValue) {\n            return value + this.learningRate * deltaValue;\n        }\n    }, {\n        key: \"gain\",\n        value: function gain(value, deltaValue, neuron, weightI) {\n\n            var newVal = value + this.learningRate * deltaValue * (weightI == null ? neuron.biasGain : neuron.weightGains[weightI]);\n\n            if (newVal <= 0 && value > 0 || newVal >= 0 && value < 0) {\n                if (weightI != null) neuron.weightGains[weightI] = Math.max(neuron.weightGains[weightI] * 0.95, 0.5);else neuron.biasGain = Math.max(neuron.biasGain * 0.95, 0.5);\n            } else {\n                if (weightI != null) neuron.weightGains[weightI] = Math.min(neuron.weightGains[weightI] + 0.05, 5);else neuron.biasGain = Math.min(neuron.biasGain + 0.05, 5);\n            }\n\n            return newVal;\n        }\n    }, {\n        key: \"adagrad\",\n        value: function adagrad(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) neuron.weightsCache[weightI] += Math.pow(deltaValue, 2);else neuron.biasCache += Math.pow(deltaValue, 2);\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"RMSProp\",\n        value: function RMSProp(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) neuron.weightsCache[weightI] = this.rmsDecay * neuron.weightsCache[weightI] + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);else neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2);\n\n            return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI != null ? neuron.weightsCache[weightI] : neuron.biasCache));\n        }\n    }, {\n        key: \"adam\",\n        value: function adam(value, deltaValue, neuron) {\n\n            neuron.m = 0.9 * neuron.m + (1 - 0.9) * deltaValue;\n            var mt = neuron.m / (1 - Math.pow(0.9, this.iterations + 1));\n\n            neuron.v = 0.999 * neuron.v + (1 - 0.999) * Math.pow(deltaValue, 2);\n            var vt = neuron.v / (1 - Math.pow(0.999, this.iterations + 1));\n\n            return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8);\n        }\n    }, {\n        key: \"adadelta\",\n        value: function adadelta(value, deltaValue, neuron, weightI) {\n\n            if (weightI != null) {\n                neuron.weightsCache[weightI] = this.rho * neuron.weightsCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var newVal = value + Math.sqrt((neuron.adadeltaCache[weightI] + 1e-6) / (neuron.weightsCache[weightI] + 1e-6)) * deltaValue;\n                neuron.adadeltaCache[weightI] = this.rho * neuron.adadeltaCache[weightI] + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return newVal;\n            } else {\n                neuron.biasCache = this.rho * neuron.biasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                var _newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6) / (neuron.biasCache + 1e-6)) * deltaValue;\n                neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1 - this.rho) * Math.pow(deltaValue, 2);\n                return _newVal;\n            }\n        }\n\n        // Other\n\n    }, {\n        key: \"softmax\",\n        value: function softmax(values) {\n            var total = values.reduce(function (prev, curr) {\n                return prev + curr;\n            }, 0);\n            return values.map(function (value) {\n                return value / total;\n            });\n        }\n    }, {\n        key: \"sech\",\n        value: function sech(value) {\n            return 2 * Math.exp(-value) / (1 + Math.exp(-2 * value));\n        }\n    }, {\n        key: \"maxNorm\",\n        value: function maxNorm() {\n\n            if (this.maxNormTotal > this.maxNorm) {\n\n                var multiplier = this.maxNorm / (1e-18 + this.maxNormTotal);\n\n                this.layers.forEach(function (layer, li) {\n                    li && layer.neurons.forEach(function (neuron) {\n                        neuron.weights.forEach(function (w, wi) {\n                            neuron.weights[wi] *= multiplier;\n                        });\n                    });\n                });\n            }\n\n            this.maxNormTotal = 0;\n        }\n    }]);\n\n    return NetMath;\n}();\n\ntypeof window == \"undefined\" && (global.NetMath = NetMath);\n\"use strict\";\n\nvar Network = function () {\n    function Network() {\n        var _ref = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n            learningRate = _ref.learningRate,\n            _ref$layers = _ref.layers,\n            layers = _ref$layers === undefined ? [] : _ref$layers,\n            _ref$adaptiveLR = _ref.adaptiveLR,\n            adaptiveLR = _ref$adaptiveLR === undefined ? \"noAdaptiveLR\" : _ref$adaptiveLR,\n            _ref$activation = _ref.activation,\n            activation = _ref$activation === undefined ? \"sigmoid\" : _ref$activation,\n            _ref$cost = _ref.cost,\n            cost = _ref$cost === undefined ? \"crossEntropy\" : _ref$cost,\n            rmsDecay = _ref.rmsDecay,\n            rho = _ref.rho,\n            lreluSlope = _ref.lreluSlope,\n            eluAlpha = _ref.eluAlpha,\n            _ref$dropout = _ref.dropout,\n            dropout = _ref$dropout === undefined ? 0.5 : _ref$dropout,\n            l2 = _ref.l2,\n            l1 = _ref.l1,\n            maxNorm = _ref.maxNorm;\n\n        _classCallCheck(this, Network);\n\n        this.state = \"not-defined\";\n        this.layers = [];\n        this.epochs = 0;\n        this.iterations = 0;\n        this.dropout = dropout == false ? 1 : dropout;\n        this.error = 0;\n\n        if (learningRate != null) {\n            this.learningRate = learningRate;\n        }\n\n        if (l2) {\n            this.l2 = typeof l2 == \"boolean\" && l2 ? 0.001 : l2;\n            this.l2Error = 0;\n        }\n\n        if (l1) {\n            this.l1 = typeof l1 == \"boolean\" && l1 ? 0.005 : l1;\n            this.l1Error = 0;\n        }\n\n        if (maxNorm) {\n            this.maxNorm = typeof maxNorm == \"boolean\" && maxNorm ? 1000 : maxNorm;\n            this.maxNormTotal = 0;\n        }\n\n        switch (true) {\n\n            case adaptiveLR == \"RMSProp\":\n                this.learningRate = this.learningRate == undefined ? 0.001 : this.learningRate;\n                break;\n\n            case adaptiveLR == \"adam\":\n                this.learningRate = this.learningRate == undefined ? 0.01 : this.learningRate;\n                break;\n\n            case adaptiveLR == \"adadelta\":\n                this.rho = rho == null ? 0.95 : rho;\n                break;\n\n            default:\n\n                if (this.learningRate == undefined) {\n                    switch (activation) {\n                        case \"relu\":\n                        case \"lrelu\":\n                        case \"rrelu\":\n                        case \"elu\":\n                            this.learningRate = 0.01;\n                            break;\n                        case \"tanh\":\n                        case \"lecuntanh\":\n                            this.learningRate = 0.001;\n                            break;\n                        default:\n                            this.learningRate = 0.2;\n                    }\n                }\n        }\n\n        this.adaptiveLR = [false, null, undefined].includes(adaptiveLR) ? \"noAdaptiveLR\" : adaptiveLR;\n        this.weightUpdateFn = NetMath[this.adaptiveLR];\n        this.activation = NetMath[activation].bind(this);\n        this.activationConfig = activation;\n        this.cost = NetMath[cost];\n\n        if (this.adaptiveLR == \"RMSProp\") {\n            this.rmsDecay = rmsDecay == undefined ? 0.99 : rmsDecay;\n        }\n\n        if (activation == \"lrelu\") {\n            this.lreluSlope = lreluSlope == undefined ? -0.0005 : lreluSlope;\n        } else if (activation == \"elu\") {\n            this.eluAlpha = eluAlpha == undefined ? 1 : eluAlpha;\n        }\n\n        if (layers.length) {\n\n            switch (true) {\n\n                case layers.every(function (item) {\n                    return Number.isInteger(item);\n                }):\n                    this.layers = layers.map(function (size) {\n                        return new Layer(size);\n                    });\n                    this.state = \"constructed\";\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item instanceof Layer;\n                }):\n                    this.state = \"constructed\";\n                    this.layers = layers;\n                    this.initLayers();\n                    break;\n\n                case layers.every(function (item) {\n                    return item === Layer;\n                }):\n                    this.state = \"defined\";\n                    this.definedLayers = layers;\n                    break;\n\n                default:\n                    throw new Error(\"There was an error constructing from the layers given.\");\n            }\n        }\n    }\n\n    _createClass(Network, [{\n        key: \"initLayers\",\n        value: function initLayers(input, expected) {\n            var _this4 = this;\n\n            switch (this.state) {\n\n                case \"initialised\":\n                    return;\n\n                case \"defined\":\n                    this.layers = this.definedLayers.map(function (layer, li) {\n\n                        if (!li) return new layer(input);\n\n                        if (li == _this4.definedLayers.length - 1) return new layer(expected);\n\n                        var hidden = _this4.definedLayers.length - 2;\n                        var size = input / expected > 5 ? expected + (expected + Math.abs(input - expected) / 4) * (hidden - li + 1) / (hidden / 2) : input >= expected ? input + expected * (hidden - li) / (hidden / 2) : expected + input * (hidden - li) / (hidden / 2);\n\n                        return new layer(Math.max(Math.round(size), 0));\n                    });\n                    break;\n\n                case \"not-defined\":\n                    this.layers[0] = new Layer(input);\n                    this.layers[1] = new Layer(Math.ceil(input / expected > 5 ? expected + Math.abs(input - expected) / 4 : input + expected));\n                    this.layers[2] = new Layer(Math.ceil(expected));\n                    break;\n            }\n\n            this.layers.forEach(this.joinLayer.bind(this));\n            this.state = \"initialised\";\n        }\n    }, {\n        key: \"joinLayer\",\n        value: function joinLayer(layer, layerIndex) {\n\n            layer.activation = this.activation;\n            layer.adaptiveLR = this.adaptiveLR;\n            layer.activationConfig = this.activationConfig;\n            layer.dropout = this.dropout;\n\n            if (this.rho != undefined) {\n                layer.rho = this.rho;\n            }\n\n            if (this.eluAlpha != undefined) {\n                layer.eluAlpha = this.eluAlpha;\n            }\n\n            if (this.l2 != undefined) {\n                layer.l2 = this.l2;\n            }\n\n            if (this.l1 != undefined) {\n                layer.l1 = this.l1;\n            }\n\n            if (layerIndex) {\n                this.layers[layerIndex - 1].assignNext(layer);\n                layer.assignPrev(this.layers[layerIndex - 1]);\n            }\n        }\n    }, {\n        key: \"forward\",\n        value: function forward(data) {\n\n            if (this.state != \"initialised\") {\n                throw new Error(\"The network layers have not been initialised.\");\n            }\n\n            if (data === undefined) {\n                throw new Error(\"No data passed to Network.forward()\");\n            }\n\n            if (data.length != this.layers[0].neurons.length) {\n                console.warn(\"Input data length did not match input layer neurons count.\");\n            }\n\n            this.layers[0].neurons.forEach(function (neuron, ni) {\n                return neuron.activation = data[ni];\n            });\n            this.layers.forEach(function (layer, li) {\n                return li && layer.forward(data);\n            });\n            return this.layers[this.layers.length - 1].neurons.map(function (n) {\n                return n.activation;\n            });\n        }\n    }, {\n        key: \"backward\",\n        value: function backward(expected) {\n            if (expected === undefined) {\n                throw new Error(\"No data passed to Network.backward()\");\n            }\n\n            if (expected.length != this.layers[this.layers.length - 1].neurons.length) {\n                console.warn(\"Expected data length did not match output layer neurons count.\");\n            }\n\n            this.layers[this.layers.length - 1].backward(expected);\n\n            for (var layerIndex = this.layers.length - 2; layerIndex > 0; layerIndex--) {\n                this.layers[layerIndex].backward();\n            }\n        }\n    }, {\n        key: \"train\",\n        value: function train(dataSet) {\n            var _this5 = this;\n\n            var _ref2 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                _ref2$epochs = _ref2.epochs,\n                epochs = _ref2$epochs === undefined ? 1 : _ref2$epochs,\n                callback = _ref2.callback;\n\n            return new Promise(function (resolve, reject) {\n\n                if (dataSet === undefined || dataSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                if (_this5.state != \"initialised\") {\n                    _this5.initLayers(dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length);\n                }\n\n                _this5.layers.forEach(function (layer) {\n                    return layer.state = \"training\";\n                });\n\n                var iterationIndex = 0;\n                var epochsCounter = 0;\n\n                var doEpoch = function doEpoch() {\n                    _this5.epochs++;\n                    _this5.error = 0;\n                    iterationIndex = 0;\n\n                    if (_this5.l2Error != undefined) {\n                        _this5.l2Error = 0;\n                    }\n\n                    if (_this5.l1Error != undefined) {\n                        _this5.l1Error = 0;\n                    }\n\n                    doIteration();\n                };\n\n                var doIteration = function doIteration() {\n\n                    if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || !dataSet[iterationIndex].hasOwnProperty(\"expected\") && !dataSet[iterationIndex].hasOwnProperty(\"output\")) {\n                        return reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\");\n                    }\n\n                    _this5.resetDeltaWeights();\n\n                    var input = dataSet[iterationIndex].input;\n                    var output = _this5.forward(input);\n                    var target = dataSet[iterationIndex].expected || dataSet[iterationIndex].output;\n\n                    _this5.backward(target);\n                    _this5.applyDeltaWeights();\n\n                    var iterationError = _this5.cost(target, output);\n                    _this5.error += iterationError;\n\n                    if (typeof callback == \"function\") {\n                        callback({\n                            iterations: _this5.iterations,\n                            error: iterationError,\n                            input: input\n                        });\n                    }\n\n                    _this5.iterations++;\n                    iterationIndex++;\n\n                    if (iterationIndex < dataSet.length) {\n                        setTimeout(doIteration.bind(_this5), 0);\n                    } else {\n\n                        epochsCounter++;\n                        console.log(\"Epoch: \" + _this5.epochs + \" Error: \" + _this5.error / iterationIndex + (_this5.l2 == undefined ? \"\" : \" L2 Error: \" + _this5.l2Error / iterationIndex));\n\n                        if (epochsCounter < epochs) {\n                            doEpoch();\n                        } else {\n                            _this5.layers.forEach(function (layer) {\n                                return layer.state = \"initialised\";\n                            });\n                            resolve();\n                        }\n                    }\n                };\n\n                doEpoch();\n            });\n        }\n    }, {\n        key: \"test\",\n        value: function test(testSet) {\n            var _this6 = this;\n\n            return new Promise(function (resolve, reject) {\n\n                if (testSet === undefined || testSet === null) {\n                    reject(\"No data provided\");\n                }\n\n                var totalError = 0;\n                var testIteration = 0;\n\n                var testInput = function testInput() {\n\n                    var output = _this6.forward(testSet[testIteration].input);\n                    var target = testSet[testIteration].expected || testSet[testIteration].output;\n\n                    totalError += _this6.cost(target, output);\n\n                    console.log(\"Testing iteration\", testIteration + 1, totalError / (testIteration + 1));\n\n                    testIteration++;\n\n                    if (testIteration < testSet.length) setTimeout(testInput.bind(_this6), 0);else resolve(totalError / testSet.length);\n                };\n                testInput();\n            });\n        }\n    }, {\n        key: \"resetDeltaWeights\",\n        value: function resetDeltaWeights() {\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    neuron.deltaWeights = neuron.weights.map(function (dw) {\n                        return 0;\n                    });\n                });\n            });\n        }\n    }, {\n        key: \"applyDeltaWeights\",\n        value: function applyDeltaWeights() {\n            var _this7 = this;\n\n            this.layers.forEach(function (layer, li) {\n                li && layer.neurons.forEach(function (neuron) {\n                    neuron.deltaWeights.forEach(function (dw, dwi) {\n\n                        if (_this7.l2 != undefined) {\n                            _this7.l2Error += 0.5 * _this7.l2 * Math.pow(neuron.weights[dwi], 2);\n                        }\n\n                        if (_this7.l1 != undefined) {\n                            _this7.l1Error += _this7.l1 * Math.abs(neuron.weights[dwi]);\n                        }\n\n                        neuron.weights[dwi] = _this7.weightUpdateFn.bind(_this7, neuron.weights[dwi], dw, neuron, dwi)();\n\n                        if (_this7.maxNorm != undefined) {\n                            _this7.maxNormTotal += Math.pow(neuron.weights[dwi], 2);\n                        }\n                    });\n                    neuron.bias = _this7.weightUpdateFn.bind(_this7, neuron.bias, neuron.deltaBias, neuron)();\n                });\n            });\n\n            if (this.maxNorm != undefined) {\n                this.maxNormTotal = Math.sqrt(this.maxNormTotal);\n                NetMath.maxNorm.bind(this)();\n            }\n        }\n    }, {\n        key: \"toJSON\",\n        value: function toJSON() {\n            return {\n                layers: this.layers.map(function (layer) {\n                    return {\n                        neurons: layer.neurons.map(function (neuron) {\n                            return {\n                                bias: neuron.bias,\n                                weights: neuron.weights\n                            };\n                        })\n                    };\n                })\n            };\n        }\n    }, {\n        key: \"fromJSON\",\n        value: function fromJSON(data) {\n\n            if (data === undefined || data === null) {\n                throw new Error(\"No JSON data given to import.\");\n            }\n\n            this.layers = data.layers.map(function (layer) {\n                return new Layer(layer.neurons.length, layer.neurons);\n            });\n            this.state = \"constructed\";\n            this.initLayers();\n        }\n    }]);\n\n    return Network;\n}();\n\ntypeof window == \"undefined\" && (global.Network = Network);\n\"use strict\";\n\nvar Neuron = function () {\n    function Neuron(importedData) {\n        _classCallCheck(this, Neuron);\n\n        if (importedData) {\n            this.imported = true;\n            this.weights = importedData.weights || [];\n            this.bias = importedData.bias;\n        }\n    }\n\n    _createClass(Neuron, [{\n        key: \"init\",\n        value: function init(size) {\n            var _ref3 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n                adaptiveLR = _ref3.adaptiveLR,\n                activationConfig = _ref3.activationConfig,\n                eluAlpha = _ref3.eluAlpha;\n\n            if (!this.imported) {\n                this.weights = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                    return Math.random() * 0.2 - 0.1;\n                });\n                this.bias = Math.random() * 0.2 - 0.1;\n            }\n\n            this.deltaWeights = this.weights.map(function (v) {\n                return 0;\n            });\n\n            switch (adaptiveLR) {\n                case \"gain\":\n                    this.weightGains = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 1;\n                    });\n                    this.biasGain = 1;\n                    break;\n\n                case \"adagrad\":\n                case \"RMSProp\":\n                case \"adadelta\":\n                    this.biasCache = 0;\n                    this.weightsCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                        return 0;\n                    });\n\n                    if (adaptiveLR == \"adadelta\") {\n                        this.adadeltaCache = [].concat(_toConsumableArray(new Array(size))).map(function (v) {\n                            return 0;\n                        });\n                        this.adadeltaBiasCache = 0;\n                    }\n                    break;\n\n                case \"adam\":\n                    this.m = 0;\n                    this.v = 0;\n                    break;\n            }\n\n            if (activationConfig == \"rrelu\") {\n                this.rreluSlope = Math.random() * 0.001;\n            } else if (activationConfig == \"elu\") {\n                this.eluAlpha = eluAlpha;\n            }\n        }\n    }]);\n\n    return Neuron;\n}();\n\ntypeof window == \"undefined\" && (global.Neuron = Neuron);\n//# sourceMappingURL=Network.concat.js.map\n//# sourceMappingURL=Network.min.js.map\n"]}