{"version":3,"sources":["jsNet.concat.js"],"names":["ConvLayer","[object Object]","size","filterSize","zeroPadding","stride","activation","this","undefined","NetMath","NetUtil","format","bind","state","layer","nextLayer","layerIndex","prevLayer","net","conv","FCLayer","channels","PoolLayer","activations","length","Math","floor","prevLayerOutWidth","max","sqrt","outMapSize","inMapValuesCount","pow","inZPMapValuesCount","Error","filters","Array","map","f","Filter","forEach","filter","weights","channelWeights","weightsRow","weightsInitFn","weightsConfig","activationMap","row","v","errorMap","bias","random","dropout","dropoutMap","init","updateFn","activationConfig","eluAlpha","getActivations","filterI","sumMap","convolve","input","sumY","sumX","emY","emX","weightIndex","neuronI","neurons","neuron","error","buildConvErrorMap","col","errors","buildConvDWeights","channel","deltaWeights","l2","l2Error","l1","l1Error","abs","weightUpdateFn","maxNorm","maxNormTotal","deltaBias","data","fi","window","exports","n","Neuron","weightsCount","constructor","name","ni","dropped","sum","ai","expected","derivative","reduce","p","c","wi","miniBatchSize","dwi","Layer","wRow","w","biasGain","weightGains","getWeightGain","column","setWeightGain","biasCache","weightsCache","getWeightsCache","setWeightsCache","adadeltaBiasCache","adadeltaCache","getAdadeltaCache","setAdadeltaCache","m","rreluSlope","value","prime","val","exp","lreluSlope","sech","tanh","elu","target","output","vi","log","calculated","desired","index","prev","curr","deltaValue","learningRate","weightI","newVal","min","rmsDecay","mt","iterations","vt","rho","limit","values","i","push","mean","stdDeviation","x1","x2","r","fanIn","fanOut","gaussian","lecunnormal","uniform","lecununiform","rowStart","colStart","filterRow","filterCol","indeces","total","arr","avg","diffs","multiplier","layers","li","setWeight","getWeight","type","replace","toLowerCase","date","Date","formatted","getMilliseconds","getSeconds","getHours","getMinutes","join","j","x","zP","slice","extraRows","splice","vol","mapValues","d","inputVol","arrayToVolume","outputMap","paddedLength","fSSpread","di","addZeroPadding","inputY","inputX","weightsY","weightsX","outY","outX","paddedRow","nlFilterI","errMap","emXI","channelsCount","deltaDeltaWeights","channelI","inputValues","inputMap","arrayToMap","eY","eX","mapStartI","mapSize","returnArr","arguments","rowI","colI","Network","cost","pool","epochs","includes","distribution","every","item","Number","isInteger","initLayers","ceil","joinLayer","Object","assign","assignNext","assignPrev","console","warn","forward","backward","dataSet","callback","shuffle","Promise","resolve","reject","iterationIndex","epochsCounter","startTime","now","doEpoch","doIteration","hasOwnProperty","applyDeltaWeights","resetDeltaWeights","iterationError","elapsed","setTimeout","testSet","totalError","testInput","toJSON","fromJSON","version","maxPool","errs"],"mappings":"AAAA,mBAEMA,UAEFC,YAAaC,MAAMC,WAACA,WAAUC,YAAEA,YAAWC,OAAEA,OAAMC,WAAEA,gBAE7CH,aAAgBI,KAAKJ,WAAaA,YAClCE,SAAgBE,KAAKF,OAASA,QAC9BH,OAAgBK,KAAKL,KAAOA,MAEhCK,KAAKH,YAAcA,iBAEHI,GAAZF,aAKIC,KAAKD,aAHc,kBAAZA,aAA0BA,cAGI,mBAAZA,WAAyBA,WAAaG,QAAQC,QAAQC,OAAOL,aAAaM,KAAKL,QAIhHA,KAAKM,MAAQ,kBAGjBZ,WAAYa,OACRP,KAAKQ,UAAYD,MAGrBb,WAAYa,MAAOE,YASf,OAPAT,KAAKU,UAAYH,MAEjBP,KAAKS,WAAaA,WAClBT,KAAKL,KAAOK,KAAKL,MAAQ,EACzBK,KAAKJ,WAAaI,KAAKJ,YAAcI,KAAKW,IAAIC,KAAKhB,YAAc,EACjEI,KAAKF,OAASE,KAAKF,QAAUE,KAAKW,IAAIC,KAAKd,QAAU,GAE7C,GACJ,KAAKS,iBAAiBM,QAClBb,KAAKc,SAAWd,KAAKW,IAAIG,UAAW,EACpC,MAEJ,KAAKP,iBAAiBd,UAClBO,KAAKc,SAAWP,MAAMZ,KACtB,MAEJ,KAAKY,iBAAiBQ,UAClBf,KAAKc,SAAWP,MAAMS,YAAYC,YAIpBhB,GAAlBD,KAAKH,cACLG,KAAKH,iBAAyCI,GAA3BD,KAAKW,IAAIC,KAAKf,YAAyBqB,KAAKC,MAAMnB,KAAKJ,WAAW,GAAKI,KAAKW,IAAIC,KAAKf,aAI5G,MAAMuB,kBAAoBb,iBAAiBM,QAAUK,KAAKG,IAAIH,KAAKC,MAAMD,KAAKI,KAAKf,MAAMZ,KAAKK,KAAKc,WAAY,GAC1DP,MAAMgB,WAM3D,GAJAvB,KAAKwB,iBAAmBN,KAAKO,IAAIL,kBAAmB,GACpDpB,KAAK0B,mBAAqBR,KAAKO,IAAIL,kBAAqC,EAAjBpB,KAAKH,YAAe,GAC3EG,KAAKuB,YAAcH,kBAAoBpB,KAAKJ,WAAa,EAAEI,KAAKH,aAAeG,KAAKF,OAAS,EAEzFE,KAAKuB,WAAW,GAAG,EACnB,MAAM,IAAII,8EAA8E3B,KAAKuB,qCAAqCd,cAGtIT,KAAK4B,YAAc,IAAIC,MAAM7B,KAAKL,OAAOmC,IAAIC,GAAK,IAAIC,QAG1DtC,OACIM,KAAK4B,QAAQK,QAAQC,SAEjBA,OAAOC,YAAc,IAAIN,MAAM7B,KAAKc,WAAWgB,IAAIM,oBACpC,IAAIP,MAAM7B,KAAKJ,aAAakC,IAAIO,YAAcrC,KAAKW,IAAI2B,cAActC,KAAKJ,YAAcI,KAAKU,UAAUI,UAAU,GAAId,KAAKuC,iBAGzIL,OAAOM,kBAAoB,IAAIX,MAAM7B,KAAKuB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM7B,KAAKuB,aAAaO,IAAIY,GAAK,IAC3GR,OAAOS,aAAe,IAAId,MAAM7B,KAAKuB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM7B,KAAKuB,aAAaO,IAAIY,GAAK,IACtGR,OAAOU,KAAqB,GAAd1B,KAAK2B,SAAa,GAER,GAApB7C,KAAKW,IAAImC,UACTZ,OAAOa,WAAab,OAAOM,cAAcV,IAAIW,KAAOA,IAAIX,IAAIY,IAAK,KAGrER,OAAOc,MACHC,SAAUjD,KAAKW,IAAIsC,SACnBlD,WAAYC,KAAKW,IAAIuC,iBACrBC,SAAUnD,KAAKW,IAAIwC,aAK/BzD,UAEI,MAAMsB,YAAcb,QAAQiD,eAAepD,KAAKU,WAEhD,IAAK,IAAI2C,QAAQ,EAAGA,QAAQrD,KAAKL,KAAM0D,UAAW,CAE9C,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5BnB,OAAOoB,OAASnD,QAAQoD,UACpBC,MAAOxC,YACPnB,YAAaG,KAAKH,YAClBsC,QAASD,OAAOC,QAChBrB,SAAUd,KAAKc,SACfhB,OAAQE,KAAKF,OACb8C,KAAMV,OAAOU,OAGjB,IAAK,IAAIa,KAAK,EAAGA,KAAKvB,OAAOoB,OAAOrC,OAAQwC,OACxC,IAAK,IAAIC,KAAK,EAAGA,KAAKxB,OAAOoB,OAAOrC,OAAQyC,OACxB,YAAZ1D,KAAKM,OAAqB4B,OAAOa,aAAeb,OAAOa,WAAWU,MAAMC,MAAQxC,KAAK2B,SAAW7C,KAAKW,IAAImC,SACzGZ,OAAOM,cAAciB,MAAMC,MAAQ,EAC5B1D,KAAKD,WACZmC,OAAOM,cAAciB,MAAMC,MAAQ1D,KAAKD,WAAWmC,OAAOoB,OAAOG,MAAMC,OAAO,EAAOxB,SAAWlC,KAAKW,IAAImC,SAAS,GAElHZ,OAAOM,cAAciB,MAAMC,MAAQxB,OAAOoB,OAAOG,MAAMC,OAO3EhE,WAGI,GAAIM,KAAKQ,qBAAqBK,QAG1B,IAAK,IAAIwC,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAAW,CAExD,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5B,IAAK,IAAIM,IAAI,EAAGA,IAAIzB,OAAOS,SAAS1B,OAAQ0C,MACxC,IAAK,IAAIC,IAAI,EAAGA,IAAI1B,OAAOS,SAAS1B,OAAQ2C,MAAO,CAE/C,MAAMC,YAAcR,QAAUrD,KAAKuB,YAAY,EAAIoC,IAAMzB,OAAOS,SAAS1B,OAAS2C,IAElF,IAAK,IAAIE,QAAQ,EAAGA,QAAQ9D,KAAKQ,UAAUuD,QAAQ9C,OAAQ6C,UAAW,CAElE,MAAME,OAAShE,KAAKQ,UAAUuD,QAAQD,SACtC5B,OAAOS,SAASgB,KAAKC,MAAQI,OAAOC,MAAQD,OAAO7B,QAAQ0B,oBAMxE,GAAI7D,KAAKQ,qBAAqBf,UAEjC,IAAK,IAAI4D,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAC7ClD,QAAQ+D,kBAAkBlE,KAAKQ,UAAWR,KAAK4B,QAAQyB,SAASV,SAAUU,cAK9E,IAAK,IAAIA,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAAW,CAExD,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5B,IAAK,IAAIZ,IAAI,EAAGA,IAAIP,OAAOS,SAAS1B,OAAQwB,MACxC,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOS,SAAS1B,OAAQkD,MACxCjC,OAAOS,SAASF,KAAK0B,KAAOnE,KAAKQ,UAAU4D,OAAOf,SAASZ,KAAK0B,KAOhF,IAAK,IAAId,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAAW,CAExD,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5B,IAAK,IAAIZ,IAAI,EAAGA,IAAIP,OAAOS,SAAS1B,OAAQwB,MACxC,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOS,SAAS,GAAG1B,OAAQkD,MAEvCjC,OAAOa,YAAcb,OAAOa,WAAWN,KAAK0B,KAC5CjC,OAAOS,SAASF,KAAK0B,KAAO,EACrBnE,KAAKD,aACZmC,OAAOS,SAASF,KAAK0B,MAAQnE,KAAKD,WAAWmC,OAAOoB,OAAOb,KAAK0B,MAAM,EAAMjC,SAO5F/B,QAAQkE,kBAAkBrE,MAG9BN,oBACI,IAAK,IAAI2D,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAAW,CAExD,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5B,IAAK,IAAIiB,QAAQ,EAAGA,QAAQpC,OAAOqC,aAAatD,OAAQqD,UACpD,IAAK,IAAI7B,IAAI,EAAGA,IAAIP,OAAOqC,aAAa,GAAGtD,OAAQwB,MAC/C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOqC,aAAa,GAAG,GAAGtD,OAAQkD,MAClDjC,OAAOqC,aAAaD,SAAS7B,KAAK0B,KAAO,EAKrD,GAAIjC,OAAOa,WACP,IAAK,IAAIN,IAAI,EAAGA,IAAIP,OAAOa,WAAW9B,OAAQwB,MAC1C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOa,WAAW,GAAG9B,OAAQkD,MAC7CjC,OAAOa,WAAWN,KAAK0B,MAAO,GAOlDzE,oBACI,IAAK,IAAI2D,QAAQ,EAAGA,QAAQrD,KAAK4B,QAAQX,OAAQoC,UAAW,CAExD,MAAMnB,OAASlC,KAAK4B,QAAQyB,SAE5B,IAAK,IAAIiB,QAAQ,EAAGA,QAAQpC,OAAOqC,aAAatD,OAAQqD,UACpD,IAAK,IAAI7B,IAAI,EAAGA,IAAIP,OAAOqC,aAAa,GAAGtD,OAAQwB,MAC/C,IAAK,IAAI0B,IAAI,EAAGA,IAAIjC,OAAOqC,aAAa,GAAG,GAAGtD,OAAQkD,WAEjClE,GAAbD,KAAKW,IAAI6D,KAAexE,KAAKW,IAAI8D,SAAW,GAAMzE,KAAKW,IAAI6D,GAAKtC,OAAOC,QAAQmC,SAAS7B,KAAK0B,MAAM,QACtFlE,GAAbD,KAAKW,IAAI+D,KAAe1E,KAAKW,IAAIgE,SAAW3E,KAAKW,IAAI+D,GAAKxD,KAAK0D,IAAI1C,OAAOC,QAAQmC,SAAS7B,KAAK0B,OAEpGjC,OAAOC,QAAQmC,SAAS7B,KAAK0B,KAAOnE,KAAKW,IAAIkE,eAAexE,KAAKL,KAAKW,IAAKuB,OAAOC,QAAQmC,SAAS7B,KAAK0B,KAChEjC,OAAOqC,aAAaD,SAAS7B,KAAK0B,KAAMjC,QAASoC,QAAS7B,IAAK0B,KADnEnE,QAGdC,GAAlBD,KAAKW,IAAImE,UAAoB9E,KAAKW,IAAIoE,cAAgB7C,OAAOC,QAAQmC,SAAS7B,KAAK0B,MAAM,GAKzGjC,OAAOU,KAAO5C,KAAKW,IAAIkE,eAAexE,KAAKL,KAAKW,IAAKuB,OAAOU,KAAMV,OAAO8C,UAAW9C,OAAtElC,IAItBN,SACI,OACIyC,QAASnC,KAAK4B,QAAQE,IAAII,UAElBU,KAAMV,OAAOU,KACbT,QAASD,OAAOC,YAMhCzC,SAAUuF,KAAMxE,YACZT,KAAK4B,QAAQK,QAAQ,CAACC,OAAQgD,MAE1B,GAAID,KAAK9C,QAAQ+C,IAAI/C,QAAQlB,QAAUiB,OAAOC,QAAQlB,OAClD,MAAM,IAAIU,0CAA0CsD,KAAK9C,QAAQ+C,IAAI/C,QAAQlB,oBAAoBiB,OAAOC,QAAQlB,sBAAsBR,wBAAwByE,OAGlK,GAAID,KAAK9C,QAAQ+C,IAAI/C,QAAQ,GAAGlB,QAAUiB,OAAOC,QAAQ,GAAGlB,OACxD,MAAM,IAAIU,yCAAyCsD,KAAK9C,QAAQ+C,IAAI/C,QAAQ,GAAGlB,oBAAoBiB,OAAOC,QAAQ,GAAGlB,sBAAsBR,wBAAwByE,OAGvKhD,OAAOU,KAAOqC,KAAK9C,QAAQ+C,IAAItC,KAC/BV,OAAOC,QAAU8C,KAAK9C,QAAQ+C,IAAI/C,WAK/B,oBAARgD,SAAwBC,QAAQ3F,UAAYA,iBAG7CoB,QAEFnB,YAAaC,MACTK,KAAKL,KAAOA,KACZK,KAAK+D,YAAc,IAAIlC,MAAMlC,OAAOmC,IAAIuD,GAAK,IAAIC,QACjDtF,KAAKM,MAAQ,kBAGjBZ,WAAYa,OACRP,KAAKQ,UAAYD,MAGrBb,WAAYa,MAAOE,YACfT,KAAKU,UAAYH,MACjBP,KAAKS,WAAaA,WAGtBf,OACIM,KAAK+D,QAAQ9B,QAAQ+B,SAEjB,IAAIuB,aAEJ,OAAQvF,KAAKU,UAAU8E,YAAYC,MAC/B,IAAK,UACDF,aAAevF,KAAKU,UAAUf,KAC9B,MAEJ,IAAK,YACD4F,aAAevF,KAAKU,UAAUkB,QAAQX,OAASjB,KAAKU,UAAUa,YAAY,EAC1E,MAEJ,IAAK,YACDgE,aAAevF,KAAKU,UAAUM,YAAYC,OAASjB,KAAKU,UAAUa,YAAY,EAItFyC,OAAO7B,QAAUnC,KAAKW,IAAI2B,cAAciD,aAAcvF,KAAKuC,eAC3DyB,OAAOpB,KAAqB,GAAd1B,KAAK2B,SAAa,GAEhCmB,OAAOhB,MACHC,SAAUjD,KAAKW,IAAIsC,SACnBC,iBAAkBlD,KAAKW,IAAIuC,iBAC3BC,SAAUnD,KAAKW,IAAIwC,aAK/BzD,UACIM,KAAK+D,QAAQ9B,QAAQ,CAAC+B,OAAQ0B,MAC1B,GAAgB,YAAZ1F,KAAKM,QAAsB0D,OAAO2B,QAAUzE,KAAK2B,SAAW7C,KAAKW,IAAImC,SACrEkB,OAAOjE,WAAa,MACjB,CACHiE,OAAO4B,IAAM5B,OAAOpB,KAEpB,MAAM5B,YAAcb,QAAQiD,eAAepD,KAAKU,WAEhD,IAAK,IAAImF,GAAG,EAAGA,GAAG7E,YAAYC,OAAQ4E,KAClC7B,OAAO4B,KAAO5E,YAAY6E,IAAM7B,OAAO7B,QAAQ0D,IAGnD7B,OAAOjE,WAAaC,KAAKD,WAAWiE,OAAO4B,KAAK,EAAO5B,SAAWhE,KAAKW,IAAImC,SAAS,MAKhGpD,SAAUoG,UACN9F,KAAK+D,QAAQ9B,QAAQ,CAAC+B,OAAQ0B,MAE1B,GAAI1B,OAAO2B,QACP3B,OAAOC,MAAQ,EACfD,OAAOgB,UAAY,MAChB,MACqB,IAAbc,SACP9B,OAAOC,MAAQ6B,SAASJ,IAAM1B,OAAOjE,YAErCiE,OAAO+B,WAAa/F,KAAKD,WAAWiE,OAAO4B,KAAK,EAAM5B,QACtDA,OAAOC,MAAQD,OAAO+B,WAAa/F,KAAKQ,UAAUuD,QAAQjC,IAAIuD,GAAKA,EAAEpB,OAAuB,EAAdoB,EAAElD,QAAQuD,MAC9BM,OAAO,CAACC,EAAEC,IAAMD,EAAEC,EAAG,IAGnF,MAAMlF,YAAcb,QAAQiD,eAAepD,KAAKU,WAEhD,IAAK,IAAIyF,GAAG,EAAGA,GAAGnC,OAAO7B,QAAQlB,OAAQkF,KACrCnC,OAAOO,aAAa4B,KAAQnC,OAAOC,MAAQjD,YAAYmF,KAClD,IAAOnG,KAAKW,IAAI6D,IAAI,IAAIxE,KAAKW,IAAI+D,IAAI,IAAI1E,KAAKW,IAAIyF,cAAiBpC,OAAOO,aAAa4B,KAGhGnC,OAAOgB,UAAYhB,OAAOC,SAKtCvE,oBACI,IAAK,IAAI2F,EAAE,EAAGA,EAAErF,KAAK+D,QAAQ9C,OAAQoE,IACjC,IAAK,IAAIgB,IAAI,EAAGA,IAAIrG,KAAK+D,QAAQsB,GAAGd,aAAatD,OAAQoF,MACrDrG,KAAK+D,QAAQsB,GAAGd,aAAa8B,KAAO,EAKhD3G,oBACI,IAAK,IAAI2F,EAAE,EAAGA,EAAErF,KAAK+D,QAAQ9C,OAAQoE,IAAK,CAEtC,MAAMrB,OAAShE,KAAK+D,QAAQsB,GAE5B,IAAK,IAAIgB,IAAI,EAAGA,IAAIrG,KAAK+D,QAAQsB,GAAGd,aAAatD,OAAQoF,WAEpCpG,GAAbD,KAAKW,IAAI6D,KAAexE,KAAKW,IAAI8D,SAAW,GAAMzE,KAAKW,IAAI6D,GAAKR,OAAO7B,QAAQkE,MAAM,QACxEpG,GAAbD,KAAKW,IAAI+D,KAAe1E,KAAKW,IAAIgE,SAAW3E,KAAKW,IAAI+D,GAAKxD,KAAK0D,IAAIZ,OAAO7B,QAAQkE,OAEtFrC,OAAO7B,QAAQkE,KAAOrG,KAAKW,IAAIkE,eAAexE,KAAKL,KAAKW,IAAKqD,OAAO7B,QAAQkE,KAAMrC,OAAOO,aAAa8B,KAAMrC,OAAQqC,IAA9FrG,QAEAC,GAAlBD,KAAKW,IAAImE,UAAoB9E,KAAKW,IAAIoE,cAAgBf,OAAO7B,QAAQkE,MAAM,GAGnFrC,OAAOpB,KAAO5C,KAAKW,IAAIkE,eAAexE,KAAKL,KAAKW,IAAKqD,OAAOpB,KAAMoB,OAAOgB,UAAWhB,OAAtEhE,IAItBN,SACI,OACIyC,QAASnC,KAAK+D,QAAQjC,IAAIkC,UAElBpB,KAAMoB,OAAOpB,KACbT,QAAS6B,OAAO7B,YAMhCzC,SAAUuF,KAAMxE,YACZT,KAAK+D,QAAQ9B,QAAQ,CAAC+B,OAAQ0B,MAE1B,GAAIT,KAAK9C,QAAQuD,IAAIvD,QAAQlB,QAAQ+C,OAAO7B,QAAQlB,OAChD,MAAM,IAAIU,0CAA0CsD,KAAK9C,QAAQuD,IAAIvD,QAAQlB,oBAAoB+C,OAAO7B,QAAQlB,qBAAqBR,wBAAwBiF,OAGjK1B,OAAOpB,KAAOqC,KAAK9C,QAAQuD,IAAI9C,KAC/BoB,OAAO7B,QAAU8C,KAAK9C,QAAQuD,IAAIvD,WAK9C,MAAMmE,MAAQzF,QAEC,oBAARsE,SAAwBC,QAAQvE,QAAUuE,QAAQkB,MAAQzF,eAG3DmB,OAEFtC,eAEAA,MAAMuD,SAACA,SAAQlD,WAAEA,WAAUoD,SAAEA,cAEZnD,KAAKmC,QAAQlB,OAK1B,OAHAjB,KAAKuE,aAAevE,KAAKmC,QAAQL,IAAIwC,SAAWA,QAAQxC,IAAIyE,MAAQA,KAAKzE,IAAI0E,GAAK,KAClFxG,KAAKgF,UAAY,EAET/B,UAEJ,IAAK,OACDjD,KAAKyG,SAAW,EAChBzG,KAAK0G,YAAc1G,KAAKmC,QAAQL,IAAIwC,SAAWA,QAAQxC,IAAIyE,MAAQA,KAAKzE,IAAI0E,GAAK,KACjFxG,KAAK2G,cAAgB,GAAErC,QAAS7B,IAAKmE,UAAY5G,KAAK0G,YAAYpC,SAAS7B,KAAKmE,SAChF5G,KAAK6G,cAAgB,GAAEvC,QAAS7B,IAAKmE,QAASlE,IAAM1C,KAAK0G,YAAYpC,SAAS7B,KAAKmE,QAAUlE,GAC7F,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACD1C,KAAK8G,UAAY,EACjB9G,KAAK+G,aAAe/G,KAAKmC,QAAQL,IAAIwC,SAAWA,QAAQxC,IAAIyE,MAAQA,KAAKzE,IAAI0E,GAAK,KAClFxG,KAAKgH,gBAAkB,GAAE1C,QAAS7B,IAAKmE,UAAY5G,KAAK+G,aAAazC,SAAS7B,KAAKmE,SACnF5G,KAAKiH,gBAAkB,GAAE3C,QAAS7B,IAAKmE,QAASlE,IAAM1C,KAAK+G,aAAazC,SAAS7B,KAAKmE,QAAUlE,GAElF,YAAVO,WACAjD,KAAKkH,kBAAoB,EACzBlH,KAAKmH,cAAgBnH,KAAKmC,QAAQL,IAAIwC,SAAWA,QAAQxC,IAAIyE,MAAQA,KAAKzE,IAAI0E,GAAK,KACnFxG,KAAKoH,iBAAmB,GAAE9C,QAAS7B,IAAKmE,UAAY5G,KAAKmH,cAAc7C,SAAS7B,KAAKmE,SACrF5G,KAAKqH,iBAAmB,GAAE/C,QAAS7B,IAAKmE,QAASlE,IAAM1C,KAAKmH,cAAc7C,SAAS7B,KAAKmE,QAAUlE,IAEtG,MAEJ,IAAK,OACD1C,KAAKsH,EAAI,EACTtH,KAAK0C,EAAI,EAGD,SAAZ3C,WACAC,KAAKuH,WAA6B,KAAhBrG,KAAK2B,SAEJ,OAAZ9C,aACPC,KAAKmD,SAAWA,UAIxBzD,WAAY4E,QAAS7B,IAAKmE,SACtB,OAAO5G,KAAKmC,QAAQmC,SAAS7B,KAAKmE,QAGtClH,WAAY4E,QAAS7B,IAAKmE,QAASlE,GAC/B1C,KAAKmC,QAAQmC,SAAS7B,KAAKmE,QAAUlE,EAGzChD,gBAAiB4E,QAAS7B,IAAKmE,SAC3B,OAAO5G,KAAKuE,aAAaD,SAAS7B,KAAKmE,QAG3ClH,gBAAiB4E,QAAS7B,IAAKmE,QAASlE,GACpC1C,KAAKuE,aAAaD,SAAS7B,KAAKmE,QAAUlE,GAInC,oBAARyC,SAAwBC,QAAQpD,OAASA,cAM1C9B,QAGFR,eAAgB8H,MAAOC,OACnB,MAAMC,IAAM,GAAG,EAAExG,KAAKyG,KAAKH,QAC3B,OAAOC,MAAQC,KAAK,EAAEA,KACPA,IAGnBhI,YAAa8H,MAAOC,OAChB,MAAME,IAAMzG,KAAKyG,IAAI,EAAEH,OACvB,OAAOC,MAAQ,EAAEvG,KAAKO,IAAIP,KAAKyG,IAAIH,OAAOtG,KAAKyG,KAAKH,OAAQ,IAAM,OAClDG,IAAI,IAAIA,IAAI,IAAM,MAGtCjI,YAAa8H,MAAOC,OAChB,OAAOA,MAAQD,MAAQ,EAAI,EAAI,EAChBtG,KAAKG,IAAImG,MAAO,GAGnC9H,aAAc8H,MAAOC,OACjB,OAAOA,MAAQD,MAAQ,EAAI,EAAKxH,KAAK4H,aAAe,KACrC1G,KAAKG,KAAKrB,KAAK4H,aAAe,MAAQ1G,KAAK0D,IAAI4C,OAAQA,OAG1E9H,aAAc8H,MAAOC,MAAOzD,QACxB,OAAOyD,MAAQD,MAAQ,EAAI,EAAIxD,OAAOuD,WACvBrG,KAAKG,IAAI2C,OAAOuD,WAAYC,OAG/C9H,iBAAkB8H,MAAOC,OACrB,OAAOA,MAAQ,QAAUvG,KAAKO,IAAIvB,QAAQ2H,KAAM,EAAE,EAAKL,OAAQ,GAChD,OAAStH,QAAQ4H,KAAM,EAAE,EAAKN,OAGjD9H,WAAY8H,MAAOC,MAAOzD,QACtB,OAAOyD,MAAQD,OAAQ,EAAI,EAAItH,QAAQ6H,IAAIP,OAAO,EAAOxD,QAAUA,OAAOb,SAC3DqE,OAAQ,EAAIA,MAAQxD,OAAOb,UAAYjC,KAAKyG,IAAIH,OAAS,GAI5E9H,oBAAqBsI,OAAQC,QACzB,OAAOA,OAAOnG,IAAI,CAAC0F,MAAOU,KAAOF,OAAOE,IAAMhH,KAAKiH,IAAIX,MAAM,QAAW,EAAEQ,OAAOE,KAAOhH,KAAKiH,IAAK,EAAE,MAAOX,QAC7FxB,OAAO,CAACC,EAAEC,IAAMD,EAAEC,EAAG,GAGvCxG,wBAAyB0I,WAAYC,SACjC,OAAOD,WAAWtG,IAAI,CAACmG,OAAQK,QAAUpH,KAAKO,IAAIwG,OAASI,QAAQC,OAAQ,IACzDtC,OAAO,CAACuC,KAAMC,OAASD,KAAKC,KAAM,GAAKJ,WAAWnH,OAIxEvB,uBAAwB8H,MAAOiB,YAC3B,OAAOjB,MAAQxH,KAAK0I,aAAeD,WAGvC/I,YAAa8H,MAAOiB,WAAYzE,OAAQ2E,SAEpC,MAAMC,OAASpB,MAAQxH,KAAK0I,aAAeD,YAAuB,MAATE,QAAgB3E,OAAOyC,SAAWzC,OAAO2C,cAAcgC,UAgBhH,OAdIC,QAAQ,GAAKpB,MAAM,GAAKoB,QAAQ,GAAKpB,MAAM,EAC9B,MAATmB,QACA3E,OAAO6C,cAAc8B,QAASzH,KAAKG,IAAkC,IAA9B2C,OAAO2C,cAAcgC,SAAe,KAE3E3E,OAAOyC,SAAWvF,KAAKG,IAAoB,IAAhB2C,OAAOyC,SAAe,IAGxC,MAATkC,QACA3E,OAAO6C,cAAc8B,QAASzH,KAAK2H,IAAI7E,OAAO2C,cAAcgC,SAAS,IAAM,IAE3E3E,OAAOyC,SAAWvF,KAAK2H,IAAI7E,OAAOyC,SAAS,IAAM,GAIlDmC,OAGXlJ,eAAgB8H,MAAOiB,WAAYzE,OAAQ2E,SAQvC,OANa,MAATA,QACA3E,OAAOiD,gBAAgB0B,QAAS3E,OAAOgD,gBAAgB2B,SAAWzH,KAAKO,IAAIgH,WAAY,IAEvFzE,OAAO8C,WAAa5F,KAAKO,IAAIgH,WAAY,GAGtCjB,MAAQxH,KAAK0I,aAAeD,YAAc,KAAOvH,KAAKI,KAAc,MAATqH,QAAgB3E,OAAOgD,gBAAgB2B,SACvB3E,OAAO8C,YAG7FpH,eAAgB8H,MAAOiB,WAAYzE,OAAQ2E,SAQvC,OANa,MAATA,QACA3E,OAAOiD,gBAAgB0B,QAAS3I,KAAK8I,SAAW9E,OAAOgD,gBAAgB2B,UAAY,EAAI3I,KAAK8I,UAAY5H,KAAKO,IAAIgH,WAAY,IAE7HzE,OAAO8C,UAAY9G,KAAK8I,SAAW9E,OAAO8C,WAAa,EAAI9G,KAAK8I,UAAY5H,KAAKO,IAAIgH,WAAY,GAG9FjB,MAAQxH,KAAK0I,aAAeD,YAAc,KAAOvH,KAAKI,KAAc,MAATqH,QAAgB3E,OAAOgD,gBAAgB2B,SACvB3E,OAAO8C,YAG7FpH,YAAa8H,MAAOiB,WAAYzE,QAE5BA,OAAOsD,EAAI,GAAItD,OAAOsD,GAAK,EAAE,IAAOmB,WACpC,MAAMM,GAAK/E,OAAOsD,GAAK,EAAEpG,KAAKO,IAAI,GAAKzB,KAAKgJ,WAAa,IAEzDhF,OAAOtB,EAAI,KAAMsB,OAAOtB,GAAK,EAAE,MAASxB,KAAKO,IAAIgH,WAAY,GAC7D,MAAMQ,GAAKjF,OAAOtB,GAAK,EAAExB,KAAKO,IAAI,KAAOzB,KAAKgJ,WAAa,IAE3D,OAAOxB,MAAQxH,KAAK0I,aAAeK,IAAM7H,KAAKI,KAAK2H,IAAM,MAG7DvJ,gBAAiB8H,MAAOiB,WAAYzE,OAAQ2E,SAExC,GAAa,MAATA,QAAe,CACf3E,OAAOiD,gBAAgB0B,QAAS3I,KAAKkJ,IAAMlF,OAAOgD,gBAAgB2B,UAAY,EAAE3I,KAAKkJ,KAAOhI,KAAKO,IAAIgH,WAAY,IACjH,MAAMG,OAASpB,MAAQtG,KAAKI,MAAM0C,OAAOoD,iBAAiBuB,SAAW,OAAO3E,OAAOgD,gBAAgB2B,SAAW,OAASF,WAEvH,OADAzE,OAAOqD,iBAAiBsB,QAAS3I,KAAKkJ,IAAMlF,OAAOoD,iBAAiBuB,UAAY,EAAE3I,KAAKkJ,KAAOhI,KAAKO,IAAIgH,WAAY,IAC5GG,OAEJ,CACH5E,OAAO8C,UAAY9G,KAAKkJ,IAAMlF,OAAO8C,WAAa,EAAE9G,KAAKkJ,KAAOhI,KAAKO,IAAIgH,WAAY,GACrF,MAAMG,OAASpB,MAAQtG,KAAKI,MAAM0C,OAAOkD,kBAAoB,OAAOlD,OAAO8C,UAAY,OAAS2B,WAEhG,OADAzE,OAAOkD,kBAAoBlH,KAAKkJ,IAAMlF,OAAOkD,mBAAqB,EAAElH,KAAKkJ,KAAOhI,KAAKO,IAAIgH,WAAY,GAC9FG,QAKflJ,eAAgBC,MAAMwJ,MAACA,QACnB,MAAMC,UAEN,IAAK,IAAIC,EAAE,EAAGA,EAAE1J,KAAM0J,IAClBD,OAAOE,KAAmB,EAAdpI,KAAK2B,SAAWsG,MAAMA,OAGtC,OAAOC,OAGX1J,gBAAiBC,MAAM4J,KAACA,KAAIC,aAAEA,eAC1B,MAAMJ,UAGN,IAAK,IAAIC,EAAE,EAAGA,EAAE1J,KAAM0J,IAAK,CACvB,IAAII,GAAIC,GAAIC,EAEZ,GAGIA,GAFAF,GAAK,EAAIvI,KAAK2B,SAAU,IAEhB,GADR6G,GAAK,EAAIxI,KAAK2B,SAAU,IACR,QACX8G,GAAK,IAAMA,GAEpBP,OAAOE,KAAKC,KAAQE,GAAMvI,KAAKI,MAAM,EAAIJ,KAAKiH,IAAIwB,GAAKA,GAAOH,cAGlE,OAAOJ,OAGX1J,oBAAqBC,MAAMiK,MAACA,MAAKC,OAAEA,SAC/B,OAAOA,QAAkB,GAARA,OAAY3J,QAAQ4J,SAASnK,MAAO4J,KAAM,EAAGC,aAActI,KAAKI,KAAK,GAAGsI,MAAMC,WAClE3J,QAAQ6J,YAAYpK,MAAOiK,MAAAA,QAG5DlK,qBAAsBC,MAAMiK,MAACA,MAAKC,OAAEA,SAChC,OAAOA,QAAkB,GAARA,OAAY3J,QAAQ8J,QAAQrK,MAAOwJ,MAAOjI,KAAKI,KAAK,GAAGsI,MAAMC,WACjD3J,QAAQ+J,aAAatK,MAAOiK,MAAAA,QAG7DlK,mBAAoBC,MAAMiK,MAACA,QACvB,OAAO1J,QAAQ4J,SAASnK,MAAO4J,KAAM,EAAGC,aAActI,KAAKI,KAAK,EAAEsI,SAGtElK,oBAAqBC,MAAMiK,MAACA,QACxB,OAAO1J,QAAQ8J,QAAQrK,MAAOwJ,MAAOjI,KAAKI,KAAK,EAAEsI,SAIrDlK,eAAgBa,MAAO+D,SAEnB,MAAMtD,YAAcb,QAAQiD,eAAe7C,MAAMG,UAAW4D,QAAS/D,MAAMiB,kBAE3E,IAAK,IAAIiB,IAAI,EAAGA,IAAIlC,MAAMgB,WAAYkB,MAClC,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMgB,WAAY4C,MAAO,CAEzC,MAAM+F,SAAWzH,IAAMlC,MAAMT,OACvBqK,SAAWhG,IAAM5D,MAAMT,OAG7B,IAAIC,WAAaiB,YAAYkJ,SAAS3J,MAAMa,kBAAoB+I,UAEhE,IAAK,IAAIC,UAAU,EAAGA,UAAU7J,MAAMZ,KAAMyK,YACxC,IAAK,IAAIC,UAAU,EAAGA,UAAU9J,MAAMZ,KAAM0K,YAAa,CAErD,MAAM7C,MAAQxG,aAAekJ,SAASE,WAAa7J,MAAMa,mBAAsB+I,SAASE,YAEpF7C,MAAQzH,aACRA,WAAayH,MACbjH,MAAM+J,QAAQhG,SAAS7B,KAAK0B,MAAQiG,UAAWC,YAK3D9J,MAAMS,YAAYsD,SAAS7B,KAAK0B,KAAOpE,YAMnDL,eAAgB0J,QACZ,IAAImB,MAAQ,EAEZ,IAAK,IAAIlB,EAAE,EAAGA,EAAED,OAAOnI,OAAQoI,IAC3BkB,OAASnB,OAAOC,GAGpB,IAAK,IAAIA,EAAE,EAAGA,EAAED,OAAOnI,OAAQoI,IACvBkB,QACAnB,OAAOC,IAAMkB,OAIrB,OAAOnB,OAGX1J,YAAa8H,OACT,OAAQ,EAAEtG,KAAKyG,KAAKH,QAAS,EAAEtG,KAAKyG,KAAK,EAAEH,QAG/C9H,yBAA0B8K,KACtB,MAAMC,IAAMD,IAAIxE,OAAO,CAACC,EAAEC,IAAMD,EAAEC,GAAKsE,IAAIvJ,OACrCyJ,MAAQF,IAAI1I,IAAIY,GAAKA,EAAI+H,KAAK3I,IAAIY,GAAKA,GAAG,GAChD,OAAOxB,KAAKI,KAAKoJ,MAAM1E,OAAO,CAACC,EAAEC,IAAMD,EAAEC,GAAKwE,MAAMzJ,QAGxDvB,iBAEI,GAAIM,KAAK+E,aAAe/E,KAAK8E,QAAS,CAElC,MAAM6F,WAAa3K,KAAK8E,SAAW,MAAQ9E,KAAK+E,cAEhD/E,KAAK4K,OAAO3I,QAAQ,CAAC1B,MAAOsK,MACxBA,IAAMtK,MAAMwD,QAAQ9B,QAAQ+B,SACxBA,OAAO7B,QAAQF,QAAQ,CAACuE,EAAGL,KAAOnC,OAAO8G,UAAU3E,GAAInC,OAAO+G,UAAU5E,IAAMwE,iBAK1F3K,KAAK+E,aAAe,GAIb,oBAARI,SAAwBC,QAAQlF,QAAUA,eAG3CC,QAEFT,cAAe8H,MAAOwD,KAAK,UACvB,QAAQ,GAEJ,IAAW,UAANA,MAAgC,iBAAPxD,MAC1BA,MAAQA,MAAMyD,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAW,QAANF,MAA8B,iBAAPxD,MACxB,MAAM2D,KAAO,IAAIC,KAAK5D,OAChB6D,aAEF7D,MAAQ,IACR6D,UAAU/B,QAAQ6B,KAAKG,uBAEhB9D,MAAQ,IACf6D,UAAU/B,QAAQ6B,KAAKI,gBAAgBJ,KAAKG,uBAIxC9D,OAAS,MAAS6D,UAAU/B,QAAQ6B,KAAKK,eAE7CH,UAAU/B,QAAQ6B,KAAKM,iBACvBJ,UAAU/B,QAAQ6B,KAAKI,kBAG3B/D,MAAQ6D,UAAUK,KAAK,KAI/B,OAAOlE,MAGX9H,eAAgB8K,KACZ,IAAK,IAAInB,EAAEmB,IAAIvJ,OAAQoI,EAAGA,IAAK,CAC3B,MAAMsC,EAAIzK,KAAKC,MAAMD,KAAK2B,SAAWwG,GAC/BuC,EAAIpB,IAAInB,EAAE,GAChBmB,IAAInB,EAAE,GAAKmB,IAAImB,GACfnB,IAAImB,GAAKC,GAIjBlM,sBAAuBoC,IAAK+J,IAExB,MAAM5G,QAEN,IAAK,IAAIxC,IAAI,EAAGA,IAAIX,IAAIb,OAAQwB,MAC5BwC,KAAKqE,KAAKxH,IAAIW,KAAKqJ,MAAM,IAG7B,MAAMC,aAEN,IAAK,IAAI1C,EAAE,EAAGA,EAAEpE,KAAKhE,OAAO,EAAE4K,GAAIxC,IAC9B0C,UAAUzC,KAAK,GAGnB,IAAK,IAAInF,IAAI,EAAGA,IAAIc,KAAKhE,OAAQkD,MAC7B,IAAK,IAAIkF,EAAE,EAAGA,EAAEwC,GAAIxC,IAChBpE,KAAKd,KAAK6H,OAAO,EAAG,EAAG,GACvB/G,KAAKd,KAAK6H,OAAO/G,KAAKhE,OAAO,EAAGgE,KAAKhE,OAAQ,GAIrD,IAAK,IAAIoI,EAAE,EAAGA,EAAEwC,GAAIxC,IAChBpE,KAAK+G,OAAO,EAAG,EAAGD,UAAUD,MAAM,IAClC7G,KAAK+G,OAAO/G,KAAKhE,OAAQgE,KAAKhE,OAAO,EAAG8K,UAAUD,MAAM,IAG5D,OAAO7G,KAGXvF,kBAAmB8K,IAAK7K,MACpB,MAAMmC,OAEN,IAAK,IAAIuH,EAAE,EAAGA,EAAE1J,KAAM0J,IAAK,CACvBvH,IAAIuH,MAEJ,IAAK,IAAIsC,EAAE,EAAGA,EAAEhM,KAAMgM,IAClB7J,IAAIuH,GAAGsC,GAAKnB,IAAInB,EAAE1J,KAAKgM,GAI/B,OAAO7J,IAGXpC,qBAAsB8K,IAAK1J,UAEvB,MAAMmL,OACAtM,KAAOuB,KAAKI,KAAKkJ,IAAIvJ,OAAOH,UAC5BoL,UAAYvM,MAAM,EAExB,IAAK,IAAIwM,EAAE,EAAGA,EAAEjL,KAAKC,MAAMqJ,IAAIvJ,OAAOiL,WAAYC,IAAK,CAEnD,MAAMrK,OAEN,IAAK,IAAIuH,EAAE,EAAGA,EAAE1J,KAAM0J,IAAK,CACvBvH,IAAIuH,MAEJ,IAAK,IAAIsC,EAAE,EAAGA,EAAEhM,KAAMgM,IAClB7J,IAAIuH,GAAGsC,GAAKnB,IAAI2B,EAAED,UAAa7C,EAAE1J,KAAKgM,GAI9CM,IAAIE,GAAKrK,IAGb,OAAOmK,IAGXvM,iBAAiB8D,MAACA,MAAK3D,YAAEA,YAAWsC,QAAEA,QAAOrB,SAAEA,SAAQhB,OAAEA,OAAM8C,KAAEA,OAE7D,MAAMwJ,SAAWjM,QAAQkM,cAAc7I,MAAO1C,UACxCwL,aAEAC,aAAeH,SAAS,GAAGnL,OAAqB,EAAZpB,YACpC2M,SAAWtL,KAAKC,MAAMgB,QAAQ,GAAGlB,OAAS,GAGhD,IAAK,IAAIwL,GAAG,EAAGA,GAAG3L,SAAU2L,KAAM,CAC9BL,SAASK,IAAMtM,QAAQuM,eAAeN,SAASK,IAAK5M,aAEpD,IAAK,IAAI8M,OAAOH,SAAUG,OAAOJ,aAAaC,SAAUG,QAAQ7M,OAAQ,CACpEwM,WAAWK,OAAOH,UAAU1M,QAAUwM,WAAWK,OAAOH,UAAU1M,YAElE,IAAK,IAAI8M,OAAOJ,SAAUI,OAAOL,aAAaC,SAAUI,QAAQ9M,OAAQ,CACpE,IAAI8F,IAAM,EAEV,IAAK,IAAIiH,SAAS,EAAGA,SAAS1K,QAAQ,GAAGlB,OAAQ4L,WAE7C,IAAK,IAAIC,SAAS,EAAGA,SAAS3K,QAAQ,GAAGlB,OAAQ6L,WAC7ClH,KAAOwG,SAASK,IAAIE,QAAQE,SAASL,WAAWI,QAAQE,SAASN,WAAarK,QAAQsK,IAAII,UAAUC,UAI5GR,WAAWK,OAAOH,UAAU1M,SAAS8M,OAAOJ,UAAU1M,SAAWwM,WAAWK,OAAOH,UAAU1M,SAAS8M,OAAOJ,UAAU1M,SAAS,GAAK8F,MAMjJ,IAAK,IAAImH,KAAK,EAAGA,KAAKT,UAAUrL,OAAQ8L,OACpC,IAAK,IAAIC,KAAK,EAAGA,KAAKV,UAAUrL,OAAQ+L,OACpCV,UAAUS,MAAMC,OAASpK,KAIjC,OAAO0J,UAGX5M,yBAA0Bc,UAAWmC,SAAUU,SAG3C,MAAMxD,YAAcW,UAAUX,YACxB0M,aAAe5J,SAAS1B,OAAqB,EAAZpB,YACjC2M,SAAWtL,KAAKC,MAAMX,UAAUZ,WAAa,GAG7CqN,aAEN,IAAK,IAAIvF,IAAI,EAAGA,IAAI6E,aAAc7E,MAC9BuF,UAAU3D,KAAK,GAGnB,IAAK,IAAI7G,IAAI,EAAGA,IAAI8J,aAAc9J,MAC9BE,SAASF,KAAOwK,UAAUnB,MAAM,GAIpC,IAAK,IAAIoB,UAAU,EAAGA,UAAU1M,UAAUb,KAAMuN,YAAa,CAEzD,MAAM/K,QAAU3B,UAAUoB,QAAQsL,WAAW/K,QAAQkB,SAC/C8J,OAAS3M,UAAUoB,QAAQsL,WAAWvK,SAG5C,IAAK,IAAIgK,OAAOH,SAAUG,OAAOJ,aAAeC,SAAUG,QAAQnM,UAAUV,OACxE,IAAK,IAAI8M,OAAOJ,SAAUI,OAAOL,aAAeC,SAAUI,QAAQpM,UAAUV,OAExE,IAAK,IAAI+M,SAAS,EAAGA,SAASrM,UAAUZ,WAAYiN,WAChD,IAAK,IAAIC,SAAS,EAAGA,SAAStM,UAAUZ,WAAYkN,WAChDnK,SAASgK,QAAQE,SAASL,WAAWI,QAAQE,SAASN,YAAcrK,QAAQ0K,UAAUC,UAChFK,QAAQR,OAAOH,UAAUhM,UAAUV,SAAS8M,OAAOJ,UAAUhM,UAAUV,QAQjG6C,SAASqJ,OAAO,EAAGnM,aACnB8C,SAASqJ,OAAOrJ,SAAS1B,OAAOpB,YAAa8C,SAAS1B,QAGtD,IAAK,IAAImM,KAAK,EAAGA,KAAKzK,SAAS1B,OAAQmM,OACnCzK,SAASyK,MAAQzK,SAASyK,MAAMpB,OAAOnM,YAAa8C,SAASyK,MAAMnM,OAAqB,EAAZpB,aAIpFH,yBAA0Ba,OAEtB,MAAMgF,aAAehF,MAAMqB,QAAQ,GAAGO,QAAQ,GAAGlB,OAC3CuL,SAAWtL,KAAKC,MAAMoE,aAAe,GACrC8H,cAAgB9M,MAAMqB,QAAQ,GAAGO,QAAQlB,OAGzCqM,qBAGN,IAAK,IAAIT,SAAS,EAAGA,SAAStH,aAAcsH,WAAY,CACpDS,kBAAkBT,aAClB,IAAK,IAAIC,SAAS,EAAGA,SAASvH,aAAcuH,WACxCQ,kBAAkBT,UAAUC,UAAY,EAKhD,IAAK,IAAIzJ,QAAQ,EAAGA,QAAQ9C,MAAMqB,QAAQX,OAAQoC,UAAW,CAEzD,MAAMnB,OAAS3B,MAAMqB,QAAQyB,SAG7B,IAAK,IAAIkK,SAAS,EAAGA,SAASF,cAAeE,WAAY,CAErD,MAAMC,YAAcrN,QAAQiD,eAAe7C,MAAMG,UAAW6M,SAAUhN,MAAMiB,kBACtEiM,SAAWtN,QAAQuM,eAAevM,QAAQuN,WAAWF,YAAatM,KAAKI,KAAKf,MAAMiB,mBAAoBjB,MAAMV,aAGlH,IAAK,IAAI8M,OAAOH,SAAUG,OAAOc,SAASxM,OAAOuL,SAAUG,QAAQpM,MAAMT,OACrE,IAAK,IAAI8M,OAAOJ,SAAUI,OAAOa,SAASxM,OAAOuL,SAAUI,QAAQrM,MAAMT,OAAQ,CAG7E,IAAK,IAAI+M,SAAS,EAAGA,SAAStH,aAAcsH,WACxC,IAAK,IAAIC,SAAS,EAAGA,SAASvH,aAAcuH,WAAY,CAEpD,MAAM/M,WAAa0N,SAASd,OAAOH,SAASK,UAAUD,OAAOJ,SAASM,UAGtEQ,kBAAkBT,UAAUC,WAAa/M,YACnC,IAAOQ,MAAMI,IAAI6D,IAAI,IAAIjE,MAAMI,IAAI+D,IAAI,IAAInE,MAAMI,IAAIyF,cAAiBlE,OAAOC,QAAQoL,UAAUV,UAAUC,WAIvH,MAAM7I,MAAQ/B,OAAOS,UAAUgK,OAAOH,UAAUjM,MAAMT,SAAS8M,OAAOJ,UAAUjM,MAAMT,QAGtF,IAAK,IAAI+M,SAAS,EAAGA,SAAStH,aAAcsH,WACxC,IAAK,IAAIC,SAAS,EAAGA,SAASvH,aAAcuH,WACxC5K,OAAOqC,aAAagJ,UAAUV,UAAUC,WAAaQ,kBAAkBT,UAAUC,UAAY7I,MAC7FqJ,kBAAkBT,UAAUC,UAAY,GAQ5D,IAAK,IAAIa,GAAG,EAAGA,GAAGzL,OAAOS,SAAS1B,OAAQ0M,KACtC,IAAK,IAAIC,GAAG,EAAGA,GAAG1L,OAAOS,SAAS1B,OAAQ2M,KACtC1L,OAAO8C,WAAa9C,OAAOS,SAASgL,IAAIC,KAMxDlO,sBAAuBa,MAAOsN,UAAWC,SAErC,MAAMC,aAEN,GAAsB,GAAlBC,UAAU/M,OAEV,GAAIV,iBAAiBM,QAEjB,IAAK,IAAI6E,GAAG,EAAGA,GAAGnF,MAAMwD,QAAQ9C,OAAQyE,KACpCqI,UAAUzE,KAAK/I,MAAMwD,QAAQ2B,IAAI3F,iBAGlC,GAAIQ,iBAAiBd,UAExB,IAAK,IAAIyF,GAAG,EAAGA,GAAG3E,MAAMqB,QAAQX,OAAQiE,KACpC,IAAK,IAAI+I,KAAK,EAAGA,KAAK1N,MAAMqB,QAAQsD,IAAI1C,cAAcvB,OAAQgN,OAC1D,IAAK,IAAIC,KAAK,EAAGA,KAAK3N,MAAMqB,QAAQsD,IAAI1C,cAAcyL,MAAMhN,OAAQiN,OAChEH,UAAUzE,KAAK/I,MAAMqB,QAAQsD,IAAI1C,cAAcyL,MAAMC,YAOjE,IAAK,IAAI5J,QAAQ,EAAGA,QAAQ/D,MAAMS,YAAYC,OAAQqD,UAClD,IAAK,IAAI7B,IAAI,EAAGA,IAAIlC,MAAMS,YAAY,GAAGC,OAAQwB,MAC7C,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMS,YAAY,GAAGC,OAAQkD,MAC7C4J,UAAUzE,KAAK/I,MAAMS,YAAYsD,SAAS7B,KAAK0B,WAQ/D,GAAI5D,iBAAiBM,QAEjB,IAAK,IAAIwI,EAAEwE,UAAUC,QAASzE,GAAGwE,UAAU,GAAGC,QAASzE,IACnD0E,UAAUzE,KAAK/I,MAAMwD,QAAQsF,GAAGtJ,iBAGjC,GAAIQ,iBAAiBd,UAExB,IAAK,IAAIgD,IAAI,EAAGA,IAAIlC,MAAMqB,QAAQiM,WAAWrL,cAAcvB,OAAQwB,MAC/D,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMqB,QAAQiM,WAAWrL,cAAcC,KAAKxB,OAAQkD,MACpE4J,UAAUzE,KAAK/I,MAAMqB,QAAQiM,WAAWrL,cAAcC,KAAK0B,WAMnE,IAAK,IAAI1B,IAAI,EAAGA,IAAIlC,MAAMS,YAAY6M,WAAW5M,OAAQwB,MACrD,IAAK,IAAI0B,IAAI,EAAGA,IAAI5D,MAAMS,YAAY6M,WAAW5M,OAAQkD,MACrD4J,UAAUzE,KAAK/I,MAAMS,YAAY6M,WAAWpL,KAAK0B,MAMjE,OAAO4J,WAIA,oBAAR5I,SAAwBC,QAAQjF,QAAUA,eAG3CgO,QAEFzO,aAAagJ,aAACA,aAAYkC,OAAEA,UAAS3H,SAAEA,SAAS,kBAAiBlD,WAAEA,WAAW,UAASqO,KAAEA,KAAK,mBAAkBtF,SAC5GA,SAAQI,IAAEA,IAAGtB,WAAEA,WAAUzE,SAAEA,SAAQL,QAAEA,QAAQ,EAAC0B,GAAEA,IAAG,EAAIE,GAAEA,IAAG,EAAII,QAAEA,QAAOvC,cAAEA,cAAazB,SAAEA,SAAQF,KAAEA,KAAIyN,KAAEA,UA4C1G,OA1CArO,KAAKM,MAAQ,cACbN,KAAK4K,UACL5K,KAAKY,QACLZ,KAAKqO,QACLrO,KAAKsO,OAAS,EACdtO,KAAKgJ,WAAa,EAClBhJ,KAAK8C,QAAmB,GAATA,QAAiB,EAAIA,QACpC9C,KAAKiE,MAAQ,EACblE,WAAaI,QAAQC,OAAOL,YAC5BkD,SAAW9C,QAAQC,OAAO6C,UAC1BmL,KAAOjO,QAAQC,OAAOgO,MAElB5J,KACAxE,KAAKwE,GAAgB,kBAAJA,GAAgB,KAAQA,GACzCxE,KAAKyE,QAAU,GAGfC,KACA1E,KAAK0E,GAAgB,kBAAJA,GAAgB,KAAQA,GACzC1E,KAAK2E,QAAU,GAGfG,UACA9E,KAAK8E,QAA0B,kBAATA,SAAsBA,QAAU,IAAOA,QAC7D9E,KAAK+E,aAAe,GAGpB2D,eAAgB1I,KAAK0I,aAAeA,cACpC5H,WAAgBd,KAAKc,SAAWA,UAEhCF,YACqBX,GAAjBW,KAAKhB,aAA2BI,KAAKY,KAAKhB,WAAagB,KAAKhB,iBAC1CK,GAAlBW,KAAKf,cAA2BG,KAAKY,KAAKf,YAAce,KAAKf,kBAChDI,GAAbW,KAAKd,SAA2BE,KAAKY,KAAKd,OAASc,KAAKd,SAG5DuO,OACIA,KAAK1O,OAAWK,KAAKqO,KAAK1O,KAAO0O,KAAK1O,MACtC0O,KAAKvO,SAAWE,KAAKqO,KAAKvO,OAASuO,KAAKvO,SAIxCmD,UAEJ,IAAK,UACDjD,KAAK0I,kBAAkCzI,GAAnBD,KAAK0I,aAA0B,KAAQ1I,KAAK0I,aAChE,MAEJ,IAAK,OACD1I,KAAK0I,kBAAkCzI,GAAnBD,KAAK0I,aAA0B,IAAO1I,KAAK0I,aAC/D,MAEJ,IAAK,WACD1I,KAAKkJ,IAAW,MAALA,IAAY,IAAOA,IAC9B,MAEJ,QAEI,QAAuBjJ,GAAnBD,KAAK0I,aAEL,OAAQ3I,YAEJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACDC,KAAK0I,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACD1I,KAAK0I,aAAe,KACpB,MAEJ,QACI1I,KAAK0I,aAAe,IAuCxC,GAlCA1I,KAAKiD,WAAY,EAAO,UAAMhD,GAAWsO,SAAStL,UAAY,kBAAoBA,SAClFjD,KAAK6E,eAAiB3E,QAAQF,KAAKiD,UACnCjD,KAAKD,WAAgC,mBAAZA,WAAyBA,WAAaG,QAAQH,YAAYM,KAAKL,MACxFA,KAAKkD,iBAAmBnD,WACxBC,KAAKoO,KAAoB,mBAANA,KAAmBA,KAAOlO,QAAQkO,MAElC,WAAfpO,KAAKiD,WACLjD,KAAK8I,cAAqB7I,GAAV6I,SAAsB,IAAOA,UAGjD9I,KAAK4H,gBAAyB3H,GAAZ2H,YAAyB,KAASA,WACpD5H,KAAKmD,cAAqBlD,GAAVkD,SAAsB,EAAIA,SAG1CnD,KAAKuC,eAAiBiM,aAAc,sBAEfvO,GAAjBsC,eAA8BA,cAAciM,eAC5CxO,KAAKuC,cAAciM,aAAerO,QAAQC,OAAOmC,cAAciM,eAG5B,WAAnCxO,KAAKuC,cAAciM,aACnBxO,KAAKuC,cAAc4G,MAAQ5G,oBAAsCtC,GAArBsC,cAAc4G,MAAmB5G,cAAc4G,MAAQ,GAEzD,YAAnCnJ,KAAKuC,cAAciM,eAC1BxO,KAAKuC,cAAcgH,KAAOhH,cAAcgH,MAAQ,EAChDvJ,KAAKuC,cAAciH,aAAejH,cAAciH,cAAgB,KAGxB,mBAAjCxJ,KAAKuC,cAAciM,aAC1BxO,KAAKsC,cAAgBtC,KAAKuC,cAAciM,aAExCxO,KAAKsC,cAAgBpC,QAAQF,KAAKuC,cAAciM,cAGhD5D,OAAO3J,OAEP,QAAQ,GAEJ,KAAK2J,OAAO6D,MAAMC,MAAQC,OAAOC,UAAUF,OACvC1O,KAAK4K,OAASA,OAAO9I,IAAInC,MAAQ,IAAIkB,QAAQlB,OAC7CK,KAAKM,MAAQ,cACbN,KAAK6O,aACL,MAEJ,KAAKjE,OAAO6D,MAAMlO,OAASA,iBAAiBM,SAAWN,iBAAiBd,WAAac,iBAAiBQ,WAClGf,KAAKM,MAAQ,cACbN,KAAK4K,OAASA,OACd5K,KAAK6O,aACL,MAEJ,QACI,MAAM,IAAIlN,MAAM,2DAKhCjC,WAAY8D,MAAOsC,UAEf,OAAQ9F,KAAKM,OAET,IAAK,cACD,OAEJ,IAAK,cACDN,KAAK4K,OAAO,GAAK,IAAI/J,QAAQ2C,OAC7BxD,KAAK4K,OAAO,GAAK,IAAI/J,QAAQK,KAAK4N,KAAKtL,MAAMsC,SAAW,EAAIA,SAAY5E,KAAK0D,IAAIpB,MAAMsC,UAAW,EACtCtC,MAAQsC,WACpE9F,KAAK4K,OAAO,GAAK,IAAI/J,QAAQK,KAAK4N,KAAKhJ,WAI/C9F,KAAK4K,OAAO3I,QAAQjC,KAAK+O,UAAU1O,KAAKL,OACxCA,KAAKM,MAAQ,cAGjBZ,UAAWa,MAAOE,YAEdF,MAAMI,IAAMX,KACZO,MAAMR,gBAA+BE,GAAlBM,MAAMR,WAAwBC,KAAKD,WAAaQ,MAAMR,WAEzEQ,MAAMgC,iBACNyM,OAAOC,OAAO1O,MAAMgC,cAAevC,KAAKuC,eAEpC9B,aACAT,KAAK4K,OAAOnK,WAAW,GAAGyO,WAAW3O,OACrCA,MAAM4O,WAAWnP,KAAK4K,OAAOnK,WAAW,GAAIA,YAE5CF,MAAMgC,cAAcqH,MAAQrJ,MAAMG,UAAUf,KAC5CY,MAAMG,UAAU6B,cAAcsH,OAAStJ,MAAMZ,KAE7CY,MAAMyC,OACNzC,MAAMD,MAAQ,eAItBZ,QAASuF,MAEL,GAAgB,eAAZjF,KAAKM,MACL,MAAM,IAAIqB,MAAM,iDAGpB,QAAa1B,IAATgF,MAA+B,OAATA,KACtB,MAAM,IAAItD,MAAM,uCASpB,OANIsD,KAAKhE,QAAUjB,KAAK4K,OAAO,GAAG7G,QAAQ9C,QACtCmO,QAAQC,KAAK,8DAGjBrP,KAAK4K,OAAO,GAAG7G,QAAQ9B,QAAQ,CAAC+B,OAAQ0B,KAAO1B,OAAOjE,WAAakF,KAAKS,KACxE1F,KAAK4K,OAAO3I,QAAQ,CAAC1B,MAAOsK,KAAOA,IAAMtK,MAAM+O,QAAQrK,OAChDjF,KAAK4K,OAAO5K,KAAK4K,OAAO3J,OAAO,GAAG8C,QAAQjC,IAAIuD,GAAKA,EAAEtF,YAGhEL,SAAUoG,UAEN,QAAiB7F,IAAb6F,SACA,MAAM,IAAInE,MAAM,wCAGhBmE,SAAS7E,QAAUjB,KAAK4K,OAAO5K,KAAK4K,OAAO3J,OAAO,GAAG8C,QAAQ9C,QAC7DmO,QAAQC,KAAK,iEAAkEvJ,UAGnF9F,KAAK4K,OAAO5K,KAAK4K,OAAO3J,OAAO,GAAGsO,SAASzJ,UAE3C,IAAK,IAAIrF,WAAWT,KAAK4K,OAAO3J,OAAO,EAAGR,WAAW,EAAGA,aACpDT,KAAK4K,OAAOnK,YAAY8O,WAIhC7P,MAAO8P,SAASlB,OAACA,OAAO,EAACmB,SAAEA,SAAQtH,IAAEA,KAAI,EAAI/B,cAAEA,cAAc,EAACsJ,QAAEA,SAAQ,OAIpE,OAFA1P,KAAKoG,cAAsC,kBAAfA,eAA4BA,cAAgBoJ,QAAQ,GAAG1J,SAAS7E,OAASmF,cAE9F,IAAIuJ,QAAQ,CAACC,QAASC,UAUzB,GARIH,SACAvP,QAAQuP,QAAQF,SAGhBrH,KACAiH,QAAQjH,iCAAiCmG,sBAAsBtO,KAAKoG,sBAGxDnG,IAAZuP,SAAqC,OAAZA,QACzB,YAAYK,OAAO,oBAGL,eAAd7P,KAAKM,OAELN,KAAK6O,WAAWxO,KAAKL,KAAMwP,QAAQ,GAAGhM,MAAMvC,QAASuO,QAAQ,GAAG1J,UAAY0J,QAAQ,GAAGvH,QAAQhH,OAA/FjB,GAGJA,KAAK4K,OAAO3I,QAAQ1B,OAASA,MAAMD,MAAQ,YAE3C,IAAIwP,eAAiB,EACjBC,cAAgB,EACpB,MAAMC,UAAY5E,KAAK6E,MAEjBC,QAAU,KACZlQ,KAAKsO,SACLtO,KAAKiE,MAAQ,EACb6L,eAAiB,OAEC7P,GAAdD,KAAKyE,UAAoBzE,KAAKyE,QAAU,QAC1BxE,GAAdD,KAAK2E,UAAoB3E,KAAK2E,QAAU,GAE5CwL,eAGEA,YAAc,KAEhB,IAAKX,QAAQM,gBAAgBM,eAAe,WAAcZ,QAAQM,gBAAgBM,eAAe,cAAgBZ,QAAQM,gBAAgBM,eAAe,UACpJ,YAAYP,OAAO,sFAGvB,MAAMrM,MAAQgM,QAAQM,gBAAgBtM,MAChCyE,OAASjI,KAAKsP,QAAQ9L,OACtBwE,OAASwH,QAAQM,gBAAgBhK,UAAY0J,QAAQM,gBAAgB7H,OAE3EjI,KAAKuP,SAASvH,UAER8H,eAAe9P,KAAKoG,eAAe,GACrCpG,KAAKqQ,oBACLrQ,KAAKsQ,qBACER,gBAAkBN,QAAQvO,QACjCjB,KAAKqQ,oBAGT,MAAME,eAAiBvQ,KAAKoO,KAAKpG,OAAQC,QACnCuI,QAAUpF,KAAK6E,MAAQD,UAC7BhQ,KAAKiE,OAASsM,eACdvQ,KAAKgJ,aAEgB,mBAAVyG,UACPA,UACIzG,WAAYhJ,KAAKgJ,WACjB/E,MAAOsM,eACPC,QAAAA,QAAShN,MAAAA,QAIbsM,eAAiBN,QAAQvO,OACzBwP,WAAWN,YAAY9P,KAAKL,MAAO,IAGnC+P,gBAEI5H,KACAiH,QAAQjH,cAAcnI,KAAKsO,iBAAiBtO,KAAKiE,MAAM6L,sBAA0B7P,GAATD,KAAKwE,GAAgB,iBAAkBxE,KAAKyE,QAAQqL,iCAClG3P,QAAQC,OAAOoQ,QAAS,6BAA6BrQ,QAAQC,OAAOoQ,QAAQT,cAAe,WAGrHA,cAAgBzB,OAChB4B,WAEAlQ,KAAK4K,OAAO3I,QAAQ1B,OAASA,MAAMD,MAAQ,eAEvC6H,KACAiH,QAAQjH,sCAAsChI,QAAQC,OAAOoQ,QAAS,oCAAoCrQ,QAAQC,OAAOoQ,QAAQV,eAAgB,WAErJF,aAKZ5P,KAAKsQ,oBACLJ,YAIRxQ,KAAMgR,SAASvI,IAACA,KAAI,EAAIsH,SAAEA,cACtB,OAAO,IAAIE,QAAQ,CAACC,QAASC,eAET5P,IAAZyQ,SAAqC,OAAZA,SACzBb,OAAO,oBAGP1H,KACAiH,QAAQjH,IAAI,mBAGhB,IAAIwI,WAAa,EACbb,eAAiB,EACrB,MAAME,UAAY5E,KAAK6E,MAEjBW,UAAY,KAEd,MAAMpN,MAAQkN,QAAQZ,gBAAgBtM,MAChCyE,OAASjI,KAAKsP,QAAQ9L,OACtBwE,OAAS0I,QAAQZ,gBAAgBhK,UAAY4K,QAAQZ,gBAAgB7H,OACrEuI,QAAUpF,KAAK6E,MAAQD,UAEvBO,eAAiBvQ,KAAKoO,KAAKpG,OAAQC,QACzC0I,YAAcJ,eACdT,iBAEqB,mBAAVL,UACPA,UACIzG,WAAY8G,eACZ7L,MAAOsM,eACPC,QAAAA,QAAShN,MAAAA,QAIbsM,eAAiBY,QAAQzP,OACzBwP,WAAWG,UAAUvQ,KAAKL,MAAO,IAI7BmI,KACAiH,QAAQjH,qCAAqChI,QAAQC,OAAOoQ,QAAS,oCAAoCrQ,QAAQC,OAAOoQ,QAAQV,eAAgB,WAGpJF,QAAQe,WAAWD,QAAQzP,UAGnC2P,cAIRlR,oBACIM,KAAK4K,OAAO3I,QAAQ,CAAC1B,MAAOsK,KAAOA,IAAMtK,MAAM+P,qBAGnD5Q,oBAEIM,KAAK4K,OAAO3I,QAAQ,CAAC1B,MAAOsK,KAAOA,IAAMtK,MAAM8P,0BAE7BpQ,GAAdD,KAAK8E,UACL9E,KAAK+E,aAAe7D,KAAKI,KAAKtB,KAAK+E,cACnC7E,QAAQ4E,QAAQzE,KAAKL,KAArBE,IAIRR,SACI,OACIkL,OAAQ5K,KAAK4K,OAAO9I,IAAIvB,OAASA,MAAMsQ,WAI/CnR,SAAUuF,MAEN,QAAahF,IAATgF,MAA+B,OAATA,KACtB,MAAM,IAAItD,MAAM,iCAGpB,GAAIsD,KAAK2F,OAAO3J,QAAUjB,KAAK4K,OAAO3J,OAClC,MAAM,IAAIU,4BAA4BsD,KAAK2F,OAAO3J,qCAAqCjB,KAAK4K,OAAO3J,sBAGvGjB,KAAKsQ,oBACLtQ,KAAK4K,OAAO3I,QAAQ,CAAC1B,MAAOsK,KAAOA,IAAMtK,MAAMuQ,SAAS7L,KAAK2F,OAAOC,IAAKA,KAG7EkG,qBACI,MAAO,SAIA,oBAAR5L,SAAwBC,QAAQ+I,QAAUA,eAG3C7I,OAEF5F,eAEAA,MAAMuD,SAACA,SAAQlD,WAAEA,WAAUoD,SAAEA,cAEzB,MAAMxD,KAAOK,KAAKmC,QAAQlB,OAG1B,OAFAjB,KAAKuE,aAAevE,KAAKmC,QAAQL,IAAIY,GAAK,GAElCO,UAEJ,IAAK,OACDjD,KAAKyG,SAAW,EAChBzG,KAAK0G,gBAAkB,IAAI7E,MAAMlC,OAAOmC,IAAIY,GAAK,GACjD1C,KAAK2G,cAAgB0C,CAAAA,GAAKrJ,KAAK0G,YAAY2C,IAC3CrJ,KAAK6G,cAAgB,EAACwC,EAAE3G,IAAM1C,KAAK0G,YAAY2C,GAAK3G,GACpD,MAEJ,IAAK,UACL,IAAK,UACL,IAAK,WACD1C,KAAK8G,UAAY,EACjB9G,KAAK+G,iBAAmB,IAAIlF,MAAMlC,OAAOmC,IAAIY,GAAK,GAClD1C,KAAKgH,gBAAkBqC,CAAAA,GAAKrJ,KAAK+G,aAAasC,IAC9CrJ,KAAKiH,gBAAkB,EAACoC,EAAE3G,IAAM1C,KAAK+G,aAAasC,GAAK3G,GAEzC,YAAVO,WACAjD,KAAKkH,kBAAoB,EACzBlH,KAAKmH,kBAAoB,IAAItF,MAAMlC,OAAOmC,IAAIY,GAAK,GACnD1C,KAAKoH,iBAAmBiC,CAAAA,GAAKrJ,KAAKmH,cAAckC,IAChDrJ,KAAKqH,iBAAmB,EAACgC,EAAE3G,IAAM1C,KAAKmH,cAAckC,GAAK3G,IAE7D,MAEJ,IAAK,OACD1C,KAAKsH,EAAI,EACTtH,KAAK0C,EAAI,EAID,SAAZ3C,WACAC,KAAKuH,WAA6B,KAAhBrG,KAAK2B,SAEJ,OAAZ9C,aACPC,KAAKmD,SAAWA,UAIxBzD,UAAW2J,GACP,OAAOrJ,KAAKmC,QAAQkH,GAGxB3J,UAAW2J,EAAG3G,GACV1C,KAAKmC,QAAQkH,GAAK3G,EAGtBhD,eAAgB2J,GACZ,OAAOrJ,KAAKuE,aAAa8E,GAG7B3J,eAAgB2J,EAAG3G,GACf1C,KAAKuE,aAAa8E,GAAK3G,GAIhB,oBAARyC,SAAwBC,QAAQE,OAASA,cAG1CvE,UAEFrB,YAAaC,MAAMG,OAACA,OAAMC,WAAEA,gBAEpBJ,OAAQK,KAAKL,KAAOA,MACpBG,SAAQE,KAAKF,OAASA,QAGtBE,KAAKD,gBADOE,GAAZF,YAAqC,GAAZA,aACY,mBAAZA,WAAyBA,WAAaG,QAAQC,QAAQC,OAAOL,aAAaM,KAAKL,OAMhHN,QAEAA,WAAYa,OACRP,KAAKQ,UAAYD,MAGrBb,WAAYa,MAAOE,YAEfT,KAAKU,UAAYH,MACjBP,KAAKL,KAAOK,KAAKL,MAAQK,KAAKW,IAAI0N,KAAK1O,MAAQ,EAC/CK,KAAKF,OAASE,KAAKF,QAAUE,KAAKW,IAAI0N,KAAKvO,QAAUE,KAAKL,KAC1DK,KAAKS,WAAaA,WAElB,IAAIW,kBAAoBb,MAAMgB,WAE9B,OAAQhB,MAAMiF,YAAYC,MAEtB,IAAK,UACDzF,KAAKc,SAAWd,KAAKW,IAAIG,SACzBM,kBAAoBF,KAAKG,IAAIH,KAAKC,MAAMD,KAAKI,KAAKf,MAAMZ,KAAKK,KAAKc,WAAY,GAC9E,MAEJ,IAAK,YACDd,KAAKc,SAAWP,MAAMZ,KACtB,MAEJ,IAAK,YACDK,KAAKc,SAAWP,MAAMO,SAQ9B,GAJAd,KAAKoB,kBAAoBA,kBACzBpB,KAAKuB,YAAcH,kBAAoBpB,KAAKL,MAAQK,KAAKF,OAAS,EAClEE,KAAKwB,iBAAmBJ,mBAAqB,EAEzCpB,KAAKuB,WAAW,GAAK,EACrB,MAAM,IAAII,8EAA8E3B,KAAKuB,qCAAqCd,cAGtIT,KAAKgB,gBAAkB,IAAIa,MAAM7B,KAAKc,WAAWgB,IAAIwC,aACtC,IAAIzC,MAAM7B,KAAKuB,aAAaO,IAAIW,SAAW,IAAIZ,MAAM7B,KAAKuB,aAAaO,IAAIY,GAAK,KAE/F1C,KAAKoE,WAAa,IAAIvC,MAAM7B,KAAKc,WAAWgB,IAAIwC,aACjC,IAAIzC,MAAMT,oBAAoBU,IAAIW,SAAW,IAAIZ,MAAMT,oBAAoBU,IAAIY,GAAK,KAEnG1C,KAAKsK,QAAUtK,KAAKgB,YAAYc,IAAIwC,SAAWA,QAAQxC,IAAIW,KAAOA,IAAIX,IAAIY,IAAM,EAAE,MAGtFhD,UACI,IAAK,IAAI4E,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UAKvC,GAHApE,QAAQ8Q,QAAQhR,KAAMsE,SAGlBtE,KAAKD,WACL,IAAK,IAAI0C,IAAI,EAAGA,IAAIzC,KAAKuB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKuB,WAAY4C,MACjCnE,KAAKgB,YAAYsD,SAAS7B,KAAK0B,KAAOnE,KAAKD,WAAWC,KAAKgB,YAAYsD,SAAS7B,KAAK0B,MAAM,EAAOnE,KAAKW,KAO3HjB,WAGI,IAAK,IAAI4E,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UACvC,IAAK,IAAI7B,IAAI,EAAGA,IAAIzC,KAAKoE,OAAO,GAAGnD,OAAQwB,MACvC,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKoE,OAAO,GAAGnD,OAAQkD,MACvCnE,KAAKoE,OAAOE,SAAS7B,KAAK0B,KAAO,EAK7C,GAAInE,KAAKQ,qBAAqBK,QAE1B,IAAK,IAAIyD,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UACvC,IAAK,IAAI7B,IAAI,EAAGA,IAAIzC,KAAKuB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKuB,WAAY4C,MAAO,CAExC,MAAM8J,KAAOjO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAK1B,IAAMzC,KAAKF,OACvDoO,KAAOlO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAKA,IAAMnE,KAAKF,OAGvD+D,aAFoB7D,KAAKuB,WAAsBvB,KAAKuB,WAEtC+C,QAAUtE,KAAKuB,YAAY,EAAIkB,IAAMzC,KAAKuB,WAAa4C,KAE3E,IAAK,IAAIH,OAAO,EAAGA,OAAOhE,KAAKQ,UAAUuD,QAAQ9C,OAAQ+C,SACrDhE,KAAKoE,OAAOE,SAAS2J,MAAMC,OAASlO,KAAKQ,UAAUuD,QAAQC,QAAQC,MAC7BjE,KAAKQ,UAAUuD,QAAQC,QAAQ7B,QAAQ0B,kBAM1F,GAAI7D,KAAKQ,qBAAqBf,UAEjC,IAAK,IAAI6E,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UAAW,CAElD,MAAM2M,QAEN,IAAK,IAAI9M,IAAI,EAAGA,IAAInE,KAAKuB,WAAY4C,MACjC8M,KAAK9M,KAAO,EAIhBhE,QAAQ+D,kBAAkBlE,KAAKQ,UAAWyQ,KAAM3M,SAEhD,IAAK,IAAI7B,IAAI,EAAGA,IAAIzC,KAAKuB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKuB,WAAY4C,MAAO,CAExC,MAAM8J,KAAOjO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAK1B,IAAMzC,KAAKF,OACvDoO,KAAOlO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAKA,IAAMnE,KAAKF,OAE7DE,KAAKoE,OAAOE,SAAS2J,MAAMC,OAAS+C,KAAKxO,KAAK0B,WAO1D,IAAK,IAAIG,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UACvC,IAAK,IAAI7B,IAAI,EAAGA,IAAIzC,KAAKuB,WAAYkB,MACjC,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKuB,WAAY4C,MAAO,CAExC,MAAM8J,KAAOjO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAK1B,IAAMzC,KAAKF,OACvDoO,KAAOlO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAKA,IAAMnE,KAAKF,OAE7DE,KAAKoE,OAAOE,SAAS2J,MAAMC,OAASlO,KAAKQ,UAAU4D,OAAOE,SAAS7B,KAAK0B,KAOxF,GAAInE,KAAKD,WACL,IAAK,IAAIuE,QAAQ,EAAGA,QAAQtE,KAAKc,SAAUwD,UAEvC,IAAK,IAAI7B,IAAI,EAAGA,IAAIzC,KAAKsK,QAAQhG,SAASrD,OAAQwB,MAC9C,IAAK,IAAI0B,IAAI,EAAGA,IAAInE,KAAKsK,QAAQhG,SAASrD,OAAQkD,MAAO,CAErD,MAAM8J,KAAOjO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAK1B,IAAMzC,KAAKF,OACvDoO,KAAOlO,KAAKsK,QAAQhG,SAAS7B,KAAK0B,KAAK,GAAKA,IAAMnE,KAAKF,OAE7DE,KAAKoE,OAAOE,SAAS2J,MAAMC,OAASlO,KAAKD,WAAWC,KAAKoE,OAAOE,SAAS2J,MAAMC,OAAO,EAAMlO,KAAKW,MAOrHjB,qBAEAA,qBAEAA,SAAW,SAEXA,aAGW,oBAARyF,SAAwBC,QAAQrE,UAAYA","file":"jsNet.min.js","sourcesContent":["\"use strict\"\r\n\r\nclass ConvLayer {\r\n\r\n    constructor (size, {filterSize, zeroPadding, stride, activation}={}) {\r\n\r\n        if (filterSize)     this.filterSize = filterSize\r\n        if (stride)         this.stride = stride\r\n        if (size)           this.size = size\r\n\r\n        this.zeroPadding = zeroPadding\r\n\r\n        if (activation!=undefined) {\r\n\r\n            if (typeof activation==\"boolean\" && !activation) {\r\n                this.activation = false\r\n            } else {\r\n                this.activation = typeof activation==\"function\" ? activation : NetMath[NetUtil.format(activation)].bind(this)\r\n            }\r\n        }\r\n\r\n        this.state = \"not-initialised\"\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n\r\n        this.prevLayer = layer\r\n\r\n        this.layerIndex = layerIndex\r\n        this.size = this.size || 4\r\n        this.filterSize = this.filterSize || this.net.conv.filterSize || 3\r\n        this.stride = this.stride || this.net.conv.stride || 1\r\n\r\n        switch (true) {\r\n            case layer instanceof FCLayer:\r\n                this.channels = this.net.channels ||1\r\n                break\r\n\r\n            case layer instanceof ConvLayer:\r\n                this.channels = layer.size\r\n                break\r\n\r\n            case layer instanceof PoolLayer:\r\n                this.channels = layer.activations.length\r\n                break\r\n        }\r\n\r\n        if (this.zeroPadding==undefined) {\r\n            this.zeroPadding = this.net.conv.zeroPadding==undefined ? Math.floor(this.filterSize/2) : this.net.conv.zeroPadding\r\n        }\r\n\r\n        // Caching calculations\r\n        const prevLayerOutWidth = layer instanceof FCLayer ? Math.max(Math.floor(Math.sqrt(layer.size/this.channels)), 1)\r\n                                                           : layer.outMapSize\r\n\r\n        this.inMapValuesCount = Math.pow(prevLayerOutWidth, 2)\r\n        this.inZPMapValuesCount = Math.pow(prevLayerOutWidth + this.zeroPadding*2, 2)\r\n        this.outMapSize = (prevLayerOutWidth - this.filterSize + 2*this.zeroPadding) / this.stride + 1\r\n\r\n        if (this.outMapSize%1!=0) {\r\n            throw new Error(`Misconfigured hyperparameters. Activation volume dimensions would be ${this.outMapSize} in conv layer at index ${layerIndex}`)\r\n        }\r\n\r\n        this.filters = [...new Array(this.size)].map(f => new Filter())\r\n    }\r\n\r\n    init () {\r\n        this.filters.forEach(filter => {\r\n\r\n            filter.weights = [...new Array(this.channels)].map(channelWeights => {\r\n                return [...new Array(this.filterSize)].map(weightsRow => this.net.weightsInitFn(this.filterSize * (this.prevLayer.channels||1), this.weightsConfig))\r\n            })\r\n\r\n            filter.activationMap = [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n            filter.errorMap = [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n            filter.bias = Math.random()*0.2-0.1\r\n\r\n            if (this.net.dropout != 1) {\r\n                filter.dropoutMap = filter.activationMap.map(row => row.map(v => false))\r\n            }\r\n\r\n            filter.init({\r\n                updateFn: this.net.updateFn,\r\n                activation: this.net.activationConfig,\r\n                eluAlpha: this.net.eluAlpha\r\n            })\r\n        })\r\n    }\r\n\r\n    forward () {\r\n\r\n        const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n        for (let filterI=0; filterI<this.size; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            filter.sumMap = NetUtil.convolve({\r\n                input: activations,\r\n                zeroPadding: this.zeroPadding,\r\n                weights: filter.weights,\r\n                channels: this.channels,\r\n                stride: this.stride,\r\n                bias: filter.bias\r\n            })\r\n\r\n            for (let sumY=0; sumY<filter.sumMap.length; sumY++) {\r\n                for (let sumX=0; sumX<filter.sumMap.length; sumX++) {\r\n                    if (this.state==\"training\" && filter.dropoutMap && (filter.dropoutMap[sumY][sumX] = Math.random() > this.net.dropout)) {\r\n                        filter.activationMap[sumY][sumX] = 0\r\n                    } else if (this.activation) {\r\n                        filter.activationMap[sumY][sumX] = this.activation(filter.sumMap[sumY][sumX], false, filter) / (this.net.dropout||1)\r\n                    } else {\r\n                        filter.activationMap[sumY][sumX] = filter.sumMap[sumY][sumX]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    backward () {\r\n\r\n        // First, get the filters' error maps\r\n        if (this.nextLayer instanceof FCLayer) {\r\n\r\n            // For each filter, build the errorMap from the weighted neuron errors in the next FCLayer corresponding to each value in the activation map\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n                const filter = this.filters[filterI]\r\n\r\n                for (let emY=0; emY<filter.errorMap.length; emY++) {\r\n                    for (let emX=0; emX<filter.errorMap.length; emX++) {\r\n\r\n                        const weightIndex = filterI * this.outMapSize**2 + emY * filter.errorMap.length + emX\r\n\r\n                        for (let neuronI=0; neuronI<this.nextLayer.neurons.length; neuronI++) {\r\n\r\n                            const neuron = this.nextLayer.neurons[neuronI]\r\n                            filter.errorMap[emY][emX] += neuron.error * neuron.weights[weightIndex]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else if (this.nextLayer instanceof ConvLayer) {\r\n\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n                NetUtil.buildConvErrorMap(this.nextLayer, this.filters[filterI].errorMap, filterI)\r\n            }\r\n\r\n        } else {\r\n\r\n            for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n                const filter = this.filters[filterI]\r\n\r\n                for (let row=0; row<filter.errorMap.length; row++) {\r\n                    for (let col=0; col<filter.errorMap.length; col++) {\r\n                        filter.errorMap[row][col] = this.nextLayer.errors[filterI][row][col]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Apply derivative to each error value\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            for (let row=0; row<filter.errorMap.length; row++) {\r\n                for (let col=0; col<filter.errorMap[0].length; col++) {\r\n\r\n                    if (filter.dropoutMap && filter.dropoutMap[row][col]) {\r\n                        filter.errorMap[row][col] = 0\r\n                    } else if (this.activation){\r\n                        filter.errorMap[row][col] *= this.activation(filter.sumMap[row][col], true, filter)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Then use the error map values to build the delta weights\r\n        NetUtil.buildConvDWeights(this)\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            for (let channel=0; channel<filter.deltaWeights.length; channel++) {\r\n                for (let row=0; row<filter.deltaWeights[0].length; row++) {\r\n                    for (let col=0; col<filter.deltaWeights[0][0].length; col++) {\r\n                        filter.deltaWeights[channel][row][col] = 0\r\n                    }\r\n                }\r\n            }\r\n\r\n            if (filter.dropoutMap) {\r\n                for (let row=0; row<filter.dropoutMap.length; row++) {\r\n                    for (let col=0; col<filter.dropoutMap[0].length; col++) {\r\n                        filter.dropoutMap[row][col] = false\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n        for (let filterI=0; filterI<this.filters.length; filterI++) {\r\n\r\n            const filter = this.filters[filterI]\r\n\r\n            for (let channel=0; channel<filter.deltaWeights.length; channel++) {\r\n                for (let row=0; row<filter.deltaWeights[0].length; row++) {\r\n                    for (let col=0; col<filter.deltaWeights[0][0].length; col++) {\r\n\r\n                        if (this.net.l2!=undefined) this.net.l2Error += 0.5 * this.net.l2 * filter.weights[channel][row][col]**2\r\n                        if (this.net.l1!=undefined) this.net.l1Error += this.net.l1 * Math.abs(filter.weights[channel][row][col])\r\n\r\n                        filter.weights[channel][row][col] = this.net.weightUpdateFn.bind(this.net, filter.weights[channel][row][col],\r\n                                                                filter.deltaWeights[channel][row][col], filter, [channel, row, col])()\r\n\r\n                        if (this.net.maxNorm!=undefined) this.net.maxNormTotal += filter.weights[channel][row][col]**2\r\n                    }\r\n                }\r\n            }\r\n\r\n            filter.bias = this.net.weightUpdateFn.bind(this.net, filter.bias, filter.deltaBias, filter)()\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.filters.map(filter => {\r\n                return {\r\n                    bias: filter.bias,\r\n                    weights: filter.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n        this.filters.forEach((filter, fi) => {\r\n\r\n            if (data.weights[fi].weights.length != filter.weights.length) {\r\n                throw new Error(`Mismatched weights depth. Given: ${data.weights[fi].weights.length} Existing: ${filter.weights.length}. At: layers[${layerIndex}], filters[${fi}]`)\r\n            }\r\n\r\n            if (data.weights[fi].weights[0].length != filter.weights[0].length) {\r\n                throw new Error(`Mismatched weights size. Given: ${data.weights[fi].weights[0].length} Existing: ${filter.weights[0].length}. At: layers[${layerIndex}], filters[${fi}]`)\r\n            }\r\n\r\n            filter.bias = data.weights[fi].bias\r\n            filter.weights = data.weights[fi].weights\r\n        })\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.ConvLayer = ConvLayer)\r\n\"use strict\"\r\n\r\nclass FCLayer {\r\n\r\n    constructor (size) {\r\n        this.size = size\r\n        this.neurons = [...new Array(size)].map(n => new Neuron())\r\n        this.state = \"not-initialised\"\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n        this.prevLayer = layer\r\n        this.layerIndex = layerIndex\r\n    }\r\n\r\n    init () {\r\n        this.neurons.forEach(neuron => {\r\n\r\n            let weightsCount\r\n\r\n            switch (this.prevLayer.constructor.name) {\r\n                case \"FCLayer\":\r\n                    weightsCount = this.prevLayer.size\r\n                    break\r\n\r\n                case \"ConvLayer\":\r\n                    weightsCount = this.prevLayer.filters.length * this.prevLayer.outMapSize**2\r\n                    break\r\n\r\n                case \"PoolLayer\":\r\n                    weightsCount = this.prevLayer.activations.length * this.prevLayer.outMapSize**2\r\n                    break\r\n            }\r\n\r\n            neuron.weights = this.net.weightsInitFn(weightsCount, this.weightsConfig)\r\n            neuron.bias = Math.random()*0.2-0.1\r\n\r\n            neuron.init({\r\n                updateFn: this.net.updateFn,\r\n                activationConfig: this.net.activationConfig,\r\n                eluAlpha: this.net.eluAlpha\r\n            })\r\n        })\r\n    }\r\n\r\n    forward () {\r\n        this.neurons.forEach((neuron, ni) => {\r\n            if (this.state==\"training\" && (neuron.dropped = Math.random() > this.net.dropout)) {\r\n                neuron.activation = 0\r\n            } else {\r\n                neuron.sum = neuron.bias\r\n\r\n                const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n                for (let ai=0; ai<activations.length; ai++) {\r\n                    neuron.sum += activations[ai] * neuron.weights[ai]\r\n                }\r\n\r\n                neuron.activation = this.activation(neuron.sum, false, neuron) / (this.net.dropout||1)\r\n            }\r\n        })\r\n    }\r\n\r\n    backward (expected) {\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (neuron.dropped) {\r\n                neuron.error = 0\r\n                neuron.deltaBias = 0\r\n            } else {\r\n                if (typeof expected !== \"undefined\") {\r\n                    neuron.error = expected[ni] - neuron.activation\r\n                } else {\r\n                    neuron.derivative = this.activation(neuron.sum, true, neuron)\r\n                    neuron.error = neuron.derivative * this.nextLayer.neurons.map(n => n.error * (n.weights[ni]|0))\r\n                                                                             .reduce((p,c) => p+c, 0)\r\n                }\r\n\r\n                const activations = NetUtil.getActivations(this.prevLayer)\r\n\r\n                for (let wi=0; wi<neuron.weights.length; wi++) {\r\n                    neuron.deltaWeights[wi] += (neuron.error * activations[wi]) *\r\n                        (1 + (((this.net.l2||0)+(this.net.l1||0))/this.net.miniBatchSize) * neuron.deltaWeights[wi])\r\n                }\r\n\r\n                neuron.deltaBias = neuron.error\r\n            }\r\n        })\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n            for (let dwi=0; dwi<this.neurons[n].deltaWeights.length; dwi++) {\r\n                this.neurons[n].deltaWeights[dwi] = 0\r\n            }\r\n        }\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n        for (let n=0; n<this.neurons.length; n++) {\r\n\r\n            const neuron = this.neurons[n]\r\n\r\n            for (let dwi=0; dwi<this.neurons[n].deltaWeights.length; dwi++) {\r\n\r\n                if (this.net.l2!=undefined) this.net.l2Error += 0.5 * this.net.l2 * neuron.weights[dwi]**2\r\n                if (this.net.l1!=undefined) this.net.l1Error += this.net.l1 * Math.abs(neuron.weights[dwi])\r\n\r\n                neuron.weights[dwi] = this.net.weightUpdateFn.bind(this.net, neuron.weights[dwi], neuron.deltaWeights[dwi], neuron, dwi)()\r\n\r\n                if (this.net.maxNorm!=undefined) this.net.maxNormTotal += neuron.weights[dwi]**2\r\n            }\r\n\r\n            neuron.bias = this.net.weightUpdateFn.bind(this.net, neuron.bias, neuron.deltaBias, neuron)()\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.neurons.map(neuron => {\r\n                return {\r\n                    bias: neuron.bias,\r\n                    weights: neuron.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (data.weights[ni].weights.length!=neuron.weights.length) {\r\n                throw new Error(`Mismatched weights count. Given: ${data.weights[ni].weights.length} Existing: ${neuron.weights.length}. At layers[${layerIndex}], neurons[${ni}]`)\r\n            }\r\n\r\n            neuron.bias = data.weights[ni].bias\r\n            neuron.weights = data.weights[ni].weights\r\n        })\r\n    }\r\n}\r\n\r\nconst Layer = FCLayer\r\n\r\ntypeof window==\"undefined\" && (exports.FCLayer = exports.Layer = FCLayer)\r\n\"use strict\"\r\n\r\nclass Filter {\r\n\r\n    constructor () {}\r\n\r\n    init ({updateFn, activation, eluAlpha}={}) {\r\n\r\n        const size = this.weights.length\r\n\r\n        this.deltaWeights = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n        this.deltaBias = 0\r\n\r\n        switch (updateFn) {\r\n\r\n            case \"gain\":\r\n                this.biasGain = 1\r\n                this.weightGains = this.weights.map(channel => channel.map(wRow => wRow.map(w => 1)))\r\n                this.getWeightGain = ([channel, row, column]) => this.weightGains[channel][row][column]\r\n                this.setWeightGain = ([channel, row, column], v) => this.weightGains[channel][row][column] = v\r\n                break\r\n\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n                this.biasCache = 0\r\n                this.weightsCache = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n                this.getWeightsCache = ([channel, row, column]) => this.weightsCache[channel][row][column]\r\n                this.setWeightsCache = ([channel, row, column], v) => this.weightsCache[channel][row][column] = v\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    this.adadeltaBiasCache = 0\r\n                    this.adadeltaCache = this.weights.map(channel => channel.map(wRow => wRow.map(w => 0)))\r\n                    this.getAdadeltaCache = ([channel, row, column]) => this.adadeltaCache[channel][row][column]\r\n                    this.setAdadeltaCache = ([channel, row, column], v) => this.adadeltaCache[channel][row][column] = v\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                this.m = 0\r\n                this.v = 0\r\n        }\r\n\r\n        if (activation==\"rrelu\") {\r\n            this.rreluSlope = Math.random() * 0.001\r\n\r\n        } else if (activation==\"elu\") {\r\n            this.eluAlpha = eluAlpha\r\n        }\r\n    }\r\n\r\n    getWeight ([channel, row, column]) {\r\n        return this.weights[channel][row][column]\r\n    }\r\n\r\n    setWeight ([channel, row, column], v) {\r\n        this.weights[channel][row][column] = v\r\n    }\r\n\r\n    getDeltaWeight ([channel, row, column]) {\r\n        return this.deltaWeights[channel][row][column]\r\n    }\r\n\r\n    setDeltaWeight ([channel, row, column], v) {\r\n        this.deltaWeights[channel][row][column] = v\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Filter = Filter)\r\n\r\n\r\n\r\n\"use strict\"\r\n\r\nclass NetMath {\r\n\r\n    // Activation functions\r\n    static sigmoid (value, prime) {\r\n        const val = 1/(1+Math.exp(-value))\r\n        return prime ? val*(1-val)\r\n                     : val\r\n    }\r\n\r\n    static tanh (value, prime) {\r\n        const exp = Math.exp(2*value)\r\n        return prime ? 4/Math.pow(Math.exp(value)+Math.exp(-value), 2) || 1e-18\r\n                     : (exp-1)/(exp+1) || 1e-18\r\n    }\r\n\r\n    static relu (value, prime) {\r\n        return prime ? value > 0 ? 1 : 0\r\n                     : Math.max(value, 0)\r\n    }\r\n\r\n    static lrelu (value, prime) {\r\n        return prime ? value > 0 ? 1 : (this.lreluSlope || -0.0005)\r\n                     : Math.max((this.lreluSlope || -0.0005)*Math.abs(value), value)\r\n    }\r\n\r\n    static rrelu (value, prime, neuron) {\r\n        return prime ? value > 0 ? 1 : neuron.rreluSlope\r\n                     : Math.max(neuron.rreluSlope, value)\r\n    }\r\n\r\n    static lecuntanh (value, prime) {\r\n        return prime ? 1.15333 * Math.pow(NetMath.sech((2/3) * value), 2)\r\n                     : 1.7159 * NetMath.tanh((2/3) * value)\r\n    }\r\n\r\n    static elu (value, prime, neuron) {\r\n        return prime ? value >=0 ? 1 : NetMath.elu(value, false, neuron) + neuron.eluAlpha\r\n                     : value >=0 ? value : neuron.eluAlpha * (Math.exp(value) - 1)\r\n    }\r\n\r\n    // Cost functions\r\n    static crossentropy (target, output) {\r\n        return output.map((value, vi) => target[vi] * Math.log(value+1e-15) + ((1-target[vi]) * Math.log((1+1e-15)-value)))\r\n                     .reduce((p,c) => p-c, 0)\r\n    }\r\n\r\n    static meansquarederror (calculated, desired) {\r\n        return calculated.map((output, index) => Math.pow(output - desired[index], 2))\r\n                         .reduce((prev, curr) => prev+curr, 0) / calculated.length\r\n    }\r\n\r\n    // Weight updating functions\r\n    static vanillaupdatefn (value, deltaValue) {\r\n        return value + this.learningRate * deltaValue\r\n    }\r\n\r\n    static gain (value, deltaValue, neuron, weightI) {\r\n\r\n        const newVal = value + this.learningRate * deltaValue * (weightI==null ? neuron.biasGain : neuron.getWeightGain(weightI))\r\n\r\n        if (newVal<=0 && value>0 || newVal>=0 && value<0){\r\n            if (weightI!=null) {\r\n                neuron.setWeightGain(weightI, Math.max(neuron.getWeightGain(weightI)*0.95, 0.5))\r\n            } else {\r\n                neuron.biasGain = Math.max(neuron.biasGain*0.95, 0.5)\r\n            }\r\n        } else {\r\n            if (weightI!=null) {\r\n                neuron.setWeightGain(weightI, Math.min(neuron.getWeightGain(weightI)+0.05, 5))\r\n            } else {\r\n                neuron.biasGain = Math.min(neuron.biasGain+0.05, 5)\r\n            }\r\n        }\r\n\r\n        return newVal\r\n    }\r\n\r\n    static adagrad (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, neuron.getWeightsCache(weightI) + Math.pow(deltaValue, 2))\r\n        } else {\r\n            neuron.biasCache += Math.pow(deltaValue, 2)\r\n        }\r\n\r\n        return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI!=null ? neuron.getWeightsCache(weightI)\r\n                                                                                        : neuron.biasCache))\r\n    }\r\n\r\n    static rmsprop (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, this.rmsDecay * neuron.getWeightsCache(weightI) + (1 - this.rmsDecay) * Math.pow(deltaValue, 2))\r\n        } else {\r\n            neuron.biasCache = this.rmsDecay * neuron.biasCache + (1 - this.rmsDecay) * Math.pow(deltaValue, 2)\r\n        }\r\n\r\n        return value + this.learningRate * deltaValue / (1e-6 + Math.sqrt(weightI!=null ? neuron.getWeightsCache(weightI)\r\n                                                                                        : neuron.biasCache))\r\n    }\r\n\r\n    static adam (value, deltaValue, neuron) {\r\n\r\n        neuron.m = 0.9*neuron.m + (1-0.9) * deltaValue\r\n        const mt = neuron.m / (1-Math.pow(0.9, this.iterations + 1))\r\n\r\n        neuron.v = 0.999*neuron.v + (1-0.999) * Math.pow(deltaValue, 2)\r\n        const vt = neuron.v / (1-Math.pow(0.999, this.iterations + 1))\r\n\r\n        return value + this.learningRate * mt / (Math.sqrt(vt) + 1e-8)\r\n    }\r\n\r\n    static adadelta (value, deltaValue, neuron, weightI) {\r\n\r\n        if (weightI!=null) {\r\n            neuron.setWeightsCache(weightI, this.rho * neuron.getWeightsCache(weightI) + (1-this.rho) * Math.pow(deltaValue, 2))\r\n            const newVal = value + Math.sqrt((neuron.getAdadeltaCache(weightI) + 1e-6)/(neuron.getWeightsCache(weightI) + 1e-6)) * deltaValue\r\n            neuron.setAdadeltaCache(weightI, this.rho * neuron.getAdadeltaCache(weightI) + (1-this.rho) * Math.pow(deltaValue, 2))\r\n            return newVal\r\n\r\n        } else {\r\n            neuron.biasCache = this.rho * neuron.biasCache + (1-this.rho) * Math.pow(deltaValue, 2)\r\n            const newVal = value + Math.sqrt((neuron.adadeltaBiasCache + 1e-6)/(neuron.biasCache + 1e-6)) * deltaValue\r\n            neuron.adadeltaBiasCache = this.rho * neuron.adadeltaBiasCache + (1-this.rho) * Math.pow(deltaValue, 2)\r\n            return newVal\r\n        }\r\n    }\r\n\r\n    // Weights init\r\n    static uniform (size, {limit}) {\r\n        const values = []\r\n\r\n        for (let i=0; i<size; i++) {\r\n            values.push(Math.random()*2*limit-limit)\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static gaussian (size, {mean, stdDeviation}) {\r\n        const values = []\r\n\r\n        // Polar Box Muller\r\n        for (let i=0; i<size; i++) {\r\n            let x1, x2, r\r\n\r\n            do {\r\n                x1 = 2 * Math.random() -1\r\n                x2 = 2 * Math.random() -1\r\n                r = x1**2 + x2**2\r\n            } while (r >= 1 || !r)\r\n\r\n            values.push(mean + (x1 * (Math.sqrt(-2 * Math.log(r) / r))) * stdDeviation)\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static xaviernormal (size, {fanIn, fanOut}) {\r\n        return fanOut || fanOut==0 ? NetMath.gaussian(size, {mean: 0, stdDeviation: Math.sqrt(2/(fanIn+fanOut))})\r\n                                   : NetMath.lecunnormal(size, {fanIn})\r\n    }\r\n\r\n    static xavieruniform (size, {fanIn, fanOut}) {\r\n        return fanOut || fanOut==0 ? NetMath.uniform(size, {limit: Math.sqrt(6/(fanIn+fanOut))})\r\n                                   : NetMath.lecununiform(size, {fanIn})\r\n    }\r\n\r\n    static lecunnormal (size, {fanIn}) {\r\n        return NetMath.gaussian(size, {mean: 0, stdDeviation: Math.sqrt(1/fanIn)})\r\n    }\r\n\r\n    static lecununiform (size, {fanIn}) {\r\n        return NetMath.uniform(size, {limit: Math.sqrt(3/fanIn)})\r\n    }\r\n\r\n    // Pool\r\n    static maxPool (layer, channel) {\r\n\r\n        const activations = NetUtil.getActivations(layer.prevLayer, channel, layer.inMapValuesCount)\r\n\r\n        for (let row=0; row<layer.outMapSize; row++) {\r\n            for (let col=0; col<layer.outMapSize; col++) {\r\n\r\n                const rowStart = row * layer.stride\r\n                const colStart = col * layer.stride\r\n\r\n                // The first value\r\n                let activation = activations[rowStart*layer.prevLayerOutWidth + colStart]\r\n\r\n                for (let filterRow=0; filterRow<layer.size; filterRow++) {\r\n                    for (let filterCol=0; filterCol<layer.size; filterCol++) {\r\n\r\n                        const value = activations[ ((rowStart+filterRow) * layer.prevLayerOutWidth) + (colStart+filterCol) ]\r\n\r\n                        if (value > activation) {\r\n                            activation = value\r\n                            layer.indeces[channel][row][col] = [filterRow, filterCol]\r\n                        }\r\n                    }\r\n                }\r\n\r\n                layer.activations[channel][row][col] = activation\r\n            }\r\n        }\r\n    }\r\n\r\n    // Other\r\n    static softmax (values) {\r\n        let total = 0\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            total += values[i]\r\n        }\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            if (total) {\r\n                values[i] /= total\r\n            }\r\n        }\r\n\r\n        return values\r\n    }\r\n\r\n    static sech (value) {\r\n        return (2*Math.exp(-value))/(1+Math.exp(-2*value))\r\n    }\r\n\r\n    static standardDeviation (arr) {\r\n        const avg = arr.reduce((p,c) => p+c) / arr.length\r\n        const diffs = arr.map(v => v - avg).map(v => v**2)\r\n        return Math.sqrt(diffs.reduce((p,c) => p+c) / diffs.length)\r\n    }\r\n\r\n    static maxNorm () {\r\n\r\n        if (this.maxNormTotal > this.maxNorm) {\r\n\r\n            const multiplier = this.maxNorm / (1e-18 + this.maxNormTotal)\r\n\r\n            this.layers.forEach((layer, li) => {\r\n                li && layer.neurons.forEach(neuron => {\r\n                    neuron.weights.forEach((w, wi) => neuron.setWeight(wi, neuron.getWeight(wi) * multiplier))\r\n                })\r\n            })\r\n        }\r\n\r\n        this.maxNormTotal = 0\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetMath = NetMath)\r\n\"use strict\"\r\n\r\nclass NetUtil {\r\n\r\n    static format (value, type=\"string\") {\r\n        switch (true) {\r\n\r\n            case type==\"string\" && typeof value==\"string\":\r\n                value = value.replace(/(_|\\s)/g, \"\").toLowerCase()\r\n                break\r\n\r\n            case type==\"time\" && typeof value==\"number\":\r\n                const date = new Date(value)\r\n                const formatted = []\r\n\r\n                if (value < 1000) {\r\n                    formatted.push(`${date.getMilliseconds()}ms`)\r\n\r\n                } else if (value < 60000) {\r\n                    formatted.push(`${date.getSeconds()}.${date.getMilliseconds()}s`)\r\n\r\n                } else {\r\n\r\n                    if (value >= 3600000) formatted.push(`${date.getHours()}h`)\r\n\r\n                    formatted.push(`${date.getMinutes()}m`)\r\n                    formatted.push(`${date.getSeconds()}s`)\r\n                }\r\n\r\n                value = formatted.join(\" \")\r\n                break\r\n        }\r\n\r\n        return value\r\n    }\r\n\r\n    static shuffle (arr) {\r\n        for (let i=arr.length; i; i--) {\r\n            const j = Math.floor(Math.random() * i)\r\n            const x = arr[i-1]\r\n            arr[i-1] = arr[j]\r\n            arr[j] = x\r\n        }\r\n    }\r\n\r\n    static addZeroPadding (map, zP) {\r\n\r\n        const data = []\r\n\r\n        for (let row=0; row<map.length; row++) {\r\n            data.push(map[row].slice(0))\r\n        }\r\n\r\n        const extraRows = []\r\n\r\n        for (let i=0; i<data.length+2*zP; i++) {\r\n            extraRows.push(0)\r\n        }\r\n\r\n        for (let col=0; col<data.length; col++) {\r\n            for (let i=0; i<zP; i++) {\r\n                data[col].splice(0, 0, 0)\r\n                data[col].splice(data.length+1, data.length, 0)\r\n            }\r\n        }\r\n\r\n        for (let i=0; i<zP; i++) {\r\n            data.splice(0, 0, extraRows.slice(0))\r\n            data.splice(data.length, data.length-1, extraRows.slice(0))\r\n        }\r\n\r\n        return data\r\n    }\r\n\r\n    static arrayToMap (arr, size) {\r\n        const map = []\r\n\r\n        for (let i=0; i<size; i++) {\r\n            map[i] = []\r\n\r\n            for (let j=0; j<size; j++) {\r\n                map[i][j] = arr[i*size+j]\r\n            }\r\n        }\r\n\r\n        return map\r\n    }\r\n\r\n    static arrayToVolume (arr, channels) {\r\n\r\n        const vol = []\r\n        const size = Math.sqrt(arr.length/channels)\r\n        const mapValues = size**2\r\n\r\n        for (let d=0; d<Math.floor(arr.length/mapValues); d++) {\r\n\r\n            const map = []\r\n\r\n            for (let i=0; i<size; i++) {\r\n                map[i] = []\r\n\r\n                for (let j=0; j<size; j++) {\r\n                    map[i][j] = arr[d*mapValues  + i*size+j]\r\n                }\r\n            }\r\n\r\n            vol[d] = map\r\n        }\r\n\r\n        return vol\r\n    }\r\n\r\n    static convolve ({input, zeroPadding, weights, channels, stride, bias}) {\r\n\r\n        const inputVol = NetUtil.arrayToVolume(input, channels)\r\n        const outputMap = []\r\n\r\n        const paddedLength = inputVol[0].length + zeroPadding*2\r\n        const fSSpread = Math.floor(weights[0].length / 2)\r\n\r\n        // For each input channels,\r\n        for (let di=0; di<channels; di++) {\r\n            inputVol[di] = NetUtil.addZeroPadding(inputVol[di], zeroPadding)\r\n            // For each inputY without ZP\r\n            for (let inputY=fSSpread; inputY<paddedLength-fSSpread; inputY+=stride) {\r\n                outputMap[(inputY-fSSpread)/stride] = outputMap[(inputY-fSSpread)/stride] || []\r\n                // For each inputX without zP\r\n                for (let inputX=fSSpread; inputX<paddedLength-fSSpread; inputX+=stride) {\r\n                    let sum = 0\r\n                    // For each weightsY on input\r\n                    for (let weightsY=0; weightsY<weights[0].length; weightsY++) {\r\n                        // For each weightsX on input\r\n                        for (let weightsX=0; weightsX<weights[0].length; weightsX++) {\r\n                            sum += inputVol[di][inputY+(weightsY-fSSpread)][inputX+(weightsX-fSSpread)] * weights[di][weightsY][weightsX]\r\n                        }\r\n                    }\r\n\r\n                    outputMap[(inputY-fSSpread)/stride][(inputX-fSSpread)/stride] = (outputMap[(inputY-fSSpread)/stride][(inputX-fSSpread)/stride]||0) + sum\r\n                }\r\n            }\r\n        }\r\n\r\n        // Then add bias\r\n        for (let outY=0; outY<outputMap.length; outY++) {\r\n            for (let outX=0; outX<outputMap.length; outX++) {\r\n                outputMap[outY][outX] += bias\r\n            }\r\n        }\r\n\r\n        return outputMap\r\n    }\r\n\r\n    static buildConvErrorMap (nextLayer, errorMap, filterI) {\r\n\r\n        // Cache / convenience\r\n        const zeroPadding = nextLayer.zeroPadding\r\n        const paddedLength = errorMap.length + zeroPadding*2\r\n        const fSSpread = Math.floor(nextLayer.filterSize / 2)\r\n\r\n        // Zero pad and clear the error map, to allow easy convoling\r\n        const paddedRow = []\r\n\r\n        for (let val=0; val<paddedLength; val++) {\r\n            paddedRow.push(0)\r\n        }\r\n\r\n        for (let row=0; row<paddedLength; row++) {\r\n            errorMap[row] = paddedRow.slice(0)\r\n        }\r\n\r\n        // For each channel in filter in the next layer which corresponds to this filter\r\n        for (let nlFilterI=0; nlFilterI<nextLayer.size; nlFilterI++) {\r\n\r\n            const weights = nextLayer.filters[nlFilterI].weights[filterI]\r\n            const errMap = nextLayer.filters[nlFilterI].errorMap\r\n\r\n            // Unconvolve their error map using the weights\r\n            for (let inputY=fSSpread; inputY<paddedLength - fSSpread; inputY+=nextLayer.stride) {\r\n                for (let inputX=fSSpread; inputX<paddedLength - fSSpread; inputX+=nextLayer.stride) {\r\n\r\n                    for (let weightsY=0; weightsY<nextLayer.filterSize; weightsY++) {\r\n                        for (let weightsX=0; weightsX<nextLayer.filterSize; weightsX++) {\r\n                            errorMap[inputY+(weightsY-fSSpread)][inputX+(weightsX-fSSpread)] += weights[weightsY][weightsX]\r\n                                * errMap[(inputY-fSSpread)/nextLayer.stride][(inputX-fSSpread)/nextLayer.stride]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Take out the zero padding. Rows:\r\n        errorMap.splice(0, zeroPadding)\r\n        errorMap.splice(errorMap.length-zeroPadding, errorMap.length)\r\n\r\n        // Columns:\r\n        for (let emXI=0; emXI<errorMap.length; emXI++) {\r\n            errorMap[emXI] = errorMap[emXI].splice(zeroPadding, errorMap[emXI].length - zeroPadding*2)\r\n        }\r\n    }\r\n\r\n    static buildConvDWeights (layer) {\r\n\r\n        const weightsCount = layer.filters[0].weights[0].length\r\n        const fSSpread = Math.floor(weightsCount / 2)\r\n        const channelsCount = layer.filters[0].weights.length\r\n\r\n        // Adding an intermediary step to allow regularization to work\r\n        const deltaDeltaWeights = []\r\n\r\n        // Filling the deltaDeltaWeights with 0 values\r\n        for (let weightsY=0; weightsY<weightsCount; weightsY++) {\r\n            deltaDeltaWeights[weightsY] = []\r\n            for (let weightsX=0; weightsX<weightsCount; weightsX++) {\r\n                deltaDeltaWeights[weightsY][weightsX] = 0\r\n            }\r\n        }\r\n\r\n        // For each filter\r\n        for (let filterI=0; filterI<layer.filters.length; filterI++) {\r\n\r\n            const filter = layer.filters[filterI]\r\n\r\n            // Each channel will take the error map and the corresponding inputMap from the input...\r\n            for (let channelI=0; channelI<channelsCount; channelI++) {\r\n\r\n                const inputValues = NetUtil.getActivations(layer.prevLayer, channelI, layer.inMapValuesCount)\r\n                const inputMap = NetUtil.addZeroPadding(NetUtil.arrayToMap(inputValues, Math.sqrt(layer.inMapValuesCount)), layer.zeroPadding)\r\n\r\n                // ...slide the filter with correct stride across the zero-padded inputMap...\r\n                for (let inputY=fSSpread; inputY<inputMap.length-fSSpread; inputY+=layer.stride) {\r\n                    for (let inputX=fSSpread; inputX<inputMap.length-fSSpread; inputX+=layer.stride) {\r\n\r\n                        // ...and at each location...\r\n                        for (let weightsY=0; weightsY<weightsCount; weightsY++) {\r\n                            for (let weightsX=0; weightsX<weightsCount; weightsX++) {\r\n\r\n                                const activation = inputMap[inputY-fSSpread+weightsY][inputX-fSSpread+weightsX]\r\n\r\n                                // Increment and regularize the delta delta weights by the input activation (later multiplied by the error)\r\n                                deltaDeltaWeights[weightsY][weightsX] += activation *\r\n                                     (1 + (((layer.net.l2||0)+(layer.net.l1||0))/layer.net.miniBatchSize) * filter.weights[channelI][weightsY][weightsX])\r\n                            }\r\n                        }\r\n\r\n                        const error = filter.errorMap[(inputY-fSSpread)/layer.stride][(inputX-fSSpread)/layer.stride]\r\n\r\n                        // Applying and resetting the deltaDeltaWeights\r\n                        for (let weightsY=0; weightsY<weightsCount; weightsY++) {\r\n                            for (let weightsX=0; weightsX<weightsCount; weightsX++) {\r\n                                filter.deltaWeights[channelI][weightsY][weightsX] += deltaDeltaWeights[weightsY][weightsX] * error\r\n                                deltaDeltaWeights[weightsY][weightsX] = 0\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n            // Increment the deltaBias by the sum of all errors in the filter\r\n            for (let eY=0; eY<filter.errorMap.length; eY++) {\r\n                for (let eX=0; eX<filter.errorMap.length; eX++) {\r\n                    filter.deltaBias += filter.errorMap[eY][eX]\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    static getActivations (layer, mapStartI, mapSize){\r\n\r\n        const returnArr = []\r\n\r\n        if (arguments.length==1) {\r\n\r\n            if (layer instanceof FCLayer) {\r\n\r\n                for (let ni=0; ni<layer.neurons.length; ni++) {\r\n                    returnArr.push(layer.neurons[ni].activation)\r\n                }\r\n\r\n            } else if (layer instanceof ConvLayer) {\r\n\r\n                for (let fi=0; fi<layer.filters.length; fi++) {\r\n                    for (let rowI=0; rowI<layer.filters[fi].activationMap.length; rowI++) {\r\n                        for (let colI=0; colI<layer.filters[fi].activationMap[rowI].length; colI++) {\r\n                            returnArr.push(layer.filters[fi].activationMap[rowI][colI])\r\n                        }\r\n                    }\r\n                }\r\n\r\n            } else {\r\n\r\n                for (let channel=0; channel<layer.activations.length; channel++) {\r\n                    for (let row=0; row<layer.activations[0].length; row++) {\r\n                        for (let col=0; col<layer.activations[0].length; col++) {\r\n                            returnArr.push(layer.activations[channel][row][col])\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else {\r\n\r\n            if (layer instanceof FCLayer) {\r\n\r\n                for (let i=mapStartI*mapSize; i<(mapStartI+1)*mapSize; i++) {\r\n                    returnArr.push(layer.neurons[i].activation)\r\n                }\r\n\r\n            } else if (layer instanceof ConvLayer) {\r\n\r\n                for (let row=0; row<layer.filters[mapStartI].activationMap.length; row++) {\r\n                    for (let col=0; col<layer.filters[mapStartI].activationMap[row].length; col++) {\r\n                        returnArr.push(layer.filters[mapStartI].activationMap[row][col])\r\n                    }\r\n                }\r\n\r\n            } else {\r\n\r\n                for (let row=0; row<layer.activations[mapStartI].length; row++) {\r\n                    for (let col=0; col<layer.activations[mapStartI].length; col++) {\r\n                        returnArr.push(layer.activations[mapStartI][row][col])\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return returnArr\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetUtil = NetUtil)\r\n\"use strict\"\r\n\r\nclass Network {\r\n\r\n    constructor ({learningRate, layers=[], updateFn=\"vanillaupdatefn\", activation=\"sigmoid\", cost=\"meansquarederror\",\r\n        rmsDecay, rho, lreluSlope, eluAlpha, dropout=1, l2=true, l1=true, maxNorm, weightsConfig, channels, conv, pool}={}) {\r\n\r\n        this.state = \"not-defined\"\r\n        this.layers = []\r\n        this.conv = {}\r\n        this.pool = {}\r\n        this.epochs = 0\r\n        this.iterations = 0\r\n        this.dropout = dropout==false ? 1 : dropout\r\n        this.error = 0\r\n        activation = NetUtil.format(activation)\r\n        updateFn = NetUtil.format(updateFn)\r\n        cost = NetUtil.format(cost)\r\n\r\n        if (l2) {\r\n            this.l2 = typeof l2==\"boolean\" ? 0.001 : l2\r\n            this.l2Error = 0\r\n        }\r\n\r\n        if (l1) {\r\n            this.l1 = typeof l1==\"boolean\" ? 0.005 : l1\r\n            this.l1Error = 0\r\n        }\r\n\r\n        if (maxNorm) {\r\n            this.maxNorm = typeof maxNorm==\"boolean\" && maxNorm ? 1000 : maxNorm\r\n            this.maxNormTotal = 0\r\n        }\r\n\r\n        if (learningRate)   this.learningRate = learningRate\r\n        if (channels)       this.channels = channels\r\n\r\n        if (conv) {\r\n            if (conv.filterSize!=undefined)     this.conv.filterSize = conv.filterSize\r\n            if (conv.zeroPadding!=undefined)    this.conv.zeroPadding = conv.zeroPadding\r\n            if (conv.stride!=undefined)         this.conv.stride = conv.stride\r\n        }\r\n\r\n        if (pool) {\r\n            if (pool.size)      this.pool.size = pool.size\r\n            if (pool.stride)    this.pool.stride = pool.stride\r\n        }\r\n\r\n        // Activation function / Learning Rate\r\n        switch (updateFn) {\r\n\r\n            case \"rmsprop\":\r\n                this.learningRate = this.learningRate==undefined ? 0.001 : this.learningRate\r\n                break\r\n\r\n            case \"adam\":\r\n                this.learningRate = this.learningRate==undefined ? 0.01 : this.learningRate\r\n                break\r\n\r\n            case \"adadelta\":\r\n                this.rho = rho==null ? 0.95 : rho\r\n                break\r\n\r\n            default:\r\n\r\n                if (this.learningRate==undefined) {\r\n\r\n                    switch (activation) {\r\n\r\n                        case \"relu\":\r\n                        case \"lrelu\":\r\n                        case \"rrelu\":\r\n                        case \"elu\":\r\n                            this.learningRate = 0.01\r\n                            break\r\n\r\n                        case \"tanh\":\r\n                        case \"lecuntanh\":\r\n                            this.learningRate = 0.001\r\n                            break\r\n\r\n                        default:\r\n                            this.learningRate = 0.2\r\n                    }\r\n                }\r\n        }\r\n\r\n        this.updateFn = [false, null, undefined].includes(updateFn) ? \"vanillaupdatefn\" : updateFn\r\n        this.weightUpdateFn = NetMath[this.updateFn]\r\n        this.activation = typeof activation==\"function\" ? activation : NetMath[activation].bind(this)\r\n        this.activationConfig = activation\r\n        this.cost = typeof cost==\"function\" ? cost : NetMath[cost]\r\n\r\n        if (this.updateFn==\"rmsprop\") {\r\n            this.rmsDecay = rmsDecay==undefined ? 0.99 : rmsDecay\r\n        }\r\n\r\n        this.lreluSlope = lreluSlope==undefined ? -0.0005 : lreluSlope\r\n        this.eluAlpha = eluAlpha==undefined ? 1 : eluAlpha\r\n\r\n        // Weights distributiom\r\n        this.weightsConfig = {distribution: \"xavieruniform\"}\r\n\r\n        if (weightsConfig != undefined && weightsConfig.distribution) {\r\n            this.weightsConfig.distribution = NetUtil.format(weightsConfig.distribution)\r\n        }\r\n\r\n        if (this.weightsConfig.distribution == \"uniform\") {\r\n            this.weightsConfig.limit = weightsConfig && weightsConfig.limit!=undefined ? weightsConfig.limit : 0.1\r\n\r\n        } else if (this.weightsConfig.distribution == \"gaussian\") {\r\n            this.weightsConfig.mean = weightsConfig.mean || 0\r\n            this.weightsConfig.stdDeviation = weightsConfig.stdDeviation || 0.05\r\n        }\r\n\r\n        if (typeof this.weightsConfig.distribution==\"function\") {\r\n            this.weightsInitFn = this.weightsConfig.distribution\r\n        } else {\r\n            this.weightsInitFn = NetMath[this.weightsConfig.distribution]\r\n        }\r\n\r\n        if (layers.length) {\r\n\r\n            switch (true) {\r\n\r\n                case layers.every(item => Number.isInteger(item)):\r\n                    this.layers = layers.map(size => new FCLayer(size))\r\n                    this.state = \"constructed\"\r\n                    this.initLayers()\r\n                    break\r\n\r\n                case layers.every(layer => layer instanceof FCLayer || layer instanceof ConvLayer || layer instanceof PoolLayer):\r\n                    this.state = \"constructed\"\r\n                    this.layers = layers\r\n                    this.initLayers()\r\n                    break\r\n\r\n                default:\r\n                    throw new Error(\"There was an error constructing from the layers given.\")\r\n            }\r\n        }\r\n    }\r\n\r\n    initLayers (input, expected) {\r\n\r\n        switch (this.state) {\r\n\r\n            case \"initialised\":\r\n                return\r\n\r\n            case \"not-defined\":\r\n                this.layers[0] = new FCLayer(input)\r\n                this.layers[1] = new FCLayer(Math.ceil(input/expected > 5 ? expected + (Math.abs(input-expected))/4\r\n                                                                          : input + expected))\r\n                this.layers[2] = new FCLayer(Math.ceil(expected))\r\n                break\r\n        }\r\n\r\n        this.layers.forEach(this.joinLayer.bind(this))\r\n        this.state = \"initialised\"\r\n    }\r\n\r\n    joinLayer (layer, layerIndex) {\r\n\r\n        layer.net = this\r\n        layer.activation = layer.activation==undefined ? this.activation : layer.activation\r\n\r\n        layer.weightsConfig = {}\r\n        Object.assign(layer.weightsConfig, this.weightsConfig)\r\n\r\n        if (layerIndex) {\r\n            this.layers[layerIndex-1].assignNext(layer)\r\n            layer.assignPrev(this.layers[layerIndex-1], layerIndex)\r\n\r\n            layer.weightsConfig.fanIn = layer.prevLayer.size\r\n            layer.prevLayer.weightsConfig.fanOut = layer.size\r\n\r\n            layer.init()\r\n            layer.state = \"initialised\"\r\n        }\r\n    }\r\n\r\n    forward (data) {\r\n\r\n        if (this.state!=\"initialised\") {\r\n            throw new Error(\"The network layers have not been initialised.\")\r\n        }\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No data passed to Network.forward()\")\r\n        }\r\n\r\n        if (data.length != this.layers[0].neurons.length) {\r\n            console.warn(\"Input data length did not match input layer neurons count.\")\r\n        }\r\n\r\n        this.layers[0].neurons.forEach((neuron, ni) => neuron.activation = data[ni])\r\n        this.layers.forEach((layer, li) => li && layer.forward(data))\r\n        return this.layers[this.layers.length-1].neurons.map(n => n.activation)\r\n    }\r\n\r\n    backward (expected) {\r\n\r\n        if (expected === undefined) {\r\n            throw new Error(\"No data passed to Network.backward()\")\r\n        }\r\n\r\n        if (expected.length != this.layers[this.layers.length-1].neurons.length) {\r\n            console.warn(\"Expected data length did not match output layer neurons count.\", expected)\r\n        }\r\n\r\n        this.layers[this.layers.length-1].backward(expected)\r\n\r\n        for (let layerIndex=this.layers.length-2; layerIndex>0; layerIndex--) {\r\n            this.layers[layerIndex].backward()\r\n        }\r\n    }\r\n\r\n    train (dataSet, {epochs=1, callback, log=true, miniBatchSize=1, shuffle=false}={}) {\r\n\r\n        this.miniBatchSize = typeof miniBatchSize==\"boolean\" && miniBatchSize ? dataSet[0].expected.length : miniBatchSize\r\n\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (shuffle) {\r\n                NetUtil.shuffle(dataSet)\r\n            }\r\n\r\n            if (log) {\r\n                console.log(`Training started. Epochs: ${epochs} Batch Size: ${this.miniBatchSize}`)\r\n            }\r\n\r\n            if (dataSet === undefined || dataSet === null) {\r\n                return void reject(\"No data provided\")\r\n            }\r\n\r\n            if (this.state != \"initialised\") {\r\n                // this.initLayers(dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length)\r\n                this.initLayers.bind(this, dataSet[0].input.length, (dataSet[0].expected || dataSet[0].output).length)()\r\n            }\r\n\r\n            this.layers.forEach(layer => layer.state = \"training\")\r\n\r\n            let iterationIndex = 0\r\n            let epochsCounter = 0\r\n            const startTime = Date.now()\r\n\r\n            const doEpoch = () => {\r\n                this.epochs++\r\n                this.error = 0\r\n                iterationIndex = 0\r\n\r\n                if (this.l2Error!=undefined) this.l2Error = 0\r\n                if (this.l1Error!=undefined) this.l1Error = 0\r\n\r\n                doIteration()\r\n            }\r\n\r\n            const doIteration = () => {\r\n\r\n                if (!dataSet[iterationIndex].hasOwnProperty(\"input\") || (!dataSet[iterationIndex].hasOwnProperty(\"expected\") && !dataSet[iterationIndex].hasOwnProperty(\"output\"))) {\r\n                    return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\")\r\n                }\r\n\r\n                const input = dataSet[iterationIndex].input\r\n                const output = this.forward(input)\r\n                const target = dataSet[iterationIndex].expected || dataSet[iterationIndex].output\r\n\r\n                this.backward(target)\r\n\r\n                if (++iterationIndex%this.miniBatchSize==0) {\r\n                    this.applyDeltaWeights()\r\n                    this.resetDeltaWeights()\r\n                } else if (iterationIndex >= dataSet.length) {\r\n                    this.applyDeltaWeights()\r\n                }\r\n\r\n                const iterationError = this.cost(target, output)\r\n                const elapsed = Date.now() - startTime\r\n                this.error += iterationError\r\n                this.iterations++\r\n\r\n                if (typeof callback==\"function\") {\r\n                    callback({\r\n                        iterations: this.iterations,\r\n                        error: iterationError,\r\n                        elapsed, input\r\n                    })\r\n                }\r\n\r\n                if (iterationIndex < dataSet.length) {\r\n                    setTimeout(doIteration.bind(this), 0)\r\n\r\n                } else {\r\n                    epochsCounter++\r\n\r\n                    if (log) {\r\n                        console.log(`Epoch: ${this.epochs} Error: ${this.error/iterationIndex}${this.l2==undefined ? \"\": ` L2 Error: ${this.l2Error/iterationIndex}`}`,\r\n                                    `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/epochsCounter, \"time\")}`)\r\n                    }\r\n\r\n                    if (epochsCounter < epochs) {\r\n                        doEpoch()\r\n                    } else {\r\n                        this.layers.forEach(layer => layer.state = \"initialised\")\r\n\r\n                        if (log) {\r\n                            console.log(`Training finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/iterationIndex, \"time\")}`)\r\n                        }\r\n                        resolve()\r\n                    }\r\n                }\r\n            }\r\n\r\n            this.resetDeltaWeights()\r\n            doEpoch()\r\n        })\r\n    }\r\n\r\n    test (testSet, {log=true, callback}={}) {\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (testSet === undefined || testSet === null) {\r\n                reject(\"No data provided\")\r\n            }\r\n\r\n            if (log) {\r\n                console.log(\"Testing started\")\r\n            }\r\n\r\n            let totalError = 0\r\n            let iterationIndex = 0\r\n            const startTime = Date.now()\r\n\r\n            const testInput = () => {\r\n\r\n                const input = testSet[iterationIndex].input\r\n                const output = this.forward(input)\r\n                const target = testSet[iterationIndex].expected || testSet[iterationIndex].output\r\n                const elapsed = Date.now() - startTime\r\n\r\n                const iterationError = this.cost(target, output)\r\n                totalError += iterationError\r\n                iterationIndex++\r\n\r\n                if (typeof callback==\"function\") {\r\n                    callback({\r\n                        iterations: iterationIndex,\r\n                        error: iterationError,\r\n                        elapsed, input\r\n                    })\r\n                }\r\n\r\n                if (iterationIndex < testSet.length) {\r\n                    setTimeout(testInput.bind(this), 0)\r\n\r\n                } else {\r\n\r\n                    if (log) {\r\n                        console.log(`Testing finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/iterationIndex, \"time\")}`)\r\n                    }\r\n\r\n                    resolve(totalError/testSet.length)\r\n                }\r\n            }\r\n            testInput()\r\n        })\r\n    }\r\n\r\n    resetDeltaWeights () {\r\n        this.layers.forEach((layer, li) => li && layer.resetDeltaWeights())\r\n    }\r\n\r\n    applyDeltaWeights () {\r\n\r\n        this.layers.forEach((layer, li) => li && layer.applyDeltaWeights())\r\n\r\n        if (this.maxNorm!=undefined) {\r\n            this.maxNormTotal = Math.sqrt(this.maxNormTotal)\r\n            NetMath.maxNorm.bind(this)()\r\n        }\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            layers: this.layers.map(layer => layer.toJSON())\r\n        }\r\n    }\r\n\r\n    fromJSON (data) {\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No JSON data given to import.\")\r\n        }\r\n\r\n        if (data.layers.length != this.layers.length) {\r\n            throw new Error(`Mismatched layers (${data.layers.length} layers in import data, but ${this.layers.length} configured)`)\r\n        }\r\n\r\n        this.resetDeltaWeights()\r\n        this.layers.forEach((layer, li) => li && layer.fromJSON(data.layers[li], li))\r\n    }\r\n\r\n    static get version () {\r\n        return \"2.1.1\"\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Network = Network)\r\n\"use strict\"\r\n\r\nclass Neuron {\r\n\r\n    constructor () {}\r\n\r\n    init ({updateFn, activation, eluAlpha}={}) {\r\n\r\n        const size = this.weights.length\r\n        this.deltaWeights = this.weights.map(v => 0)\r\n\r\n        switch (updateFn) {\r\n\r\n            case \"gain\":\r\n                this.biasGain = 1\r\n                this.weightGains = [...new Array(size)].map(v => 1)\r\n                this.getWeightGain = i => this.weightGains[i]\r\n                this.setWeightGain = (i,v) => this.weightGains[i] = v\r\n                break\r\n\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n                this.biasCache = 0\r\n                this.weightsCache = [...new Array(size)].map(v => 0)\r\n                this.getWeightsCache = i => this.weightsCache[i]\r\n                this.setWeightsCache = (i,v) => this.weightsCache[i] = v\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    this.adadeltaBiasCache = 0\r\n                    this.adadeltaCache = [...new Array(size)].map(v => 0)\r\n                    this.getAdadeltaCache = i => this.adadeltaCache[i]\r\n                    this.setAdadeltaCache = (i,v) => this.adadeltaCache[i] = v\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                this.m = 0\r\n                this.v = 0\r\n                break\r\n        }\r\n\r\n        if (activation==\"rrelu\") {\r\n            this.rreluSlope = Math.random() * 0.001\r\n\r\n        } else if (activation==\"elu\") {\r\n            this.eluAlpha = eluAlpha\r\n        }\r\n    }\r\n\r\n    getWeight (i) {\r\n        return this.weights[i]\r\n    }\r\n\r\n    setWeight (i, v) {\r\n        this.weights[i] = v\r\n    }\r\n\r\n    getDeltaWeight (i) {\r\n        return this.deltaWeights[i]\r\n    }\r\n\r\n    setDeltaWeight (i, v) {\r\n        this.deltaWeights[i] = v\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Neuron = Neuron)\r\n\"use strict\"\r\n\r\nclass PoolLayer {\r\n\r\n    constructor (size, {stride, activation}={}) {\r\n\r\n        if (size)   this.size = size\r\n        if (stride) this.stride = stride\r\n\r\n        if (activation!=undefined && activation!=false) {\r\n            this.activation = typeof activation==\"function\" ? activation : NetMath[NetUtil.format(activation)].bind(this)\r\n        } else {\r\n            this.activation = false\r\n        }\r\n    }\r\n\r\n    init () {}\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (layer, layerIndex) {\r\n\r\n        this.prevLayer = layer\r\n        this.size = this.size || this.net.pool.size || 2\r\n        this.stride = this.stride || this.net.pool.stride || this.size\r\n        this.layerIndex = layerIndex\r\n\r\n        let prevLayerOutWidth = layer.outMapSize\r\n\r\n        switch (layer.constructor.name) {\r\n\r\n            case \"FCLayer\":\r\n                this.channels = this.net.channels\r\n                prevLayerOutWidth = Math.max(Math.floor(Math.sqrt(layer.size/this.channels)), 1)\r\n                break\r\n\r\n            case \"ConvLayer\":\r\n                this.channels = layer.size\r\n                break\r\n\r\n            case \"PoolLayer\":\r\n                this.channels = layer.channels\r\n                break\r\n        }\r\n\r\n        this.prevLayerOutWidth = prevLayerOutWidth\r\n        this.outMapSize = (prevLayerOutWidth - this.size) / this.stride + 1\r\n        this.inMapValuesCount = prevLayerOutWidth ** 2\r\n\r\n        if (this.outMapSize%1 != 0) {\r\n            throw new Error(`Misconfigured hyperparameters. Activation volume dimensions would be ${this.outMapSize} in pool layer at index ${layerIndex}`)\r\n        }\r\n\r\n        this.activations = [...new Array(this.channels)].map(channel => {\r\n            return [...new Array(this.outMapSize)].map(row => [...new Array(this.outMapSize)].map(v => 0))\r\n        })\r\n        this.errors = [...new Array(this.channels)].map(channel => {\r\n            return [...new Array(prevLayerOutWidth)].map(row => [...new Array(prevLayerOutWidth)].map(v => 0))\r\n        })\r\n        this.indeces = this.activations.map(channel => channel.map(row => row.map(v => [0,0])))\r\n    }\r\n\r\n    forward () {\r\n        for (let channel=0; channel<this.channels; channel++) {\r\n\r\n            NetMath.maxPool(this, channel)\r\n\r\n            // Apply activations\r\n            if (this.activation) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n                        this.activations[channel][row][col] = this.activation(this.activations[channel][row][col], false, this.net)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    backward () {\r\n\r\n        // Clear the existing error values, first\r\n        for (let channel=0; channel<this.channels; channel++) {\r\n            for (let row=0; row<this.errors[0].length; row++) {\r\n                for (let col=0; col<this.errors[0].length; col++) {\r\n                    this.errors[channel][row][col] = 0\r\n                }\r\n            }\r\n        }\r\n\r\n        if (this.nextLayer instanceof FCLayer) {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n                        const neuronI = channel * this.outMapSize**2 + row * this.outMapSize + col\r\n\r\n                        const weightIndex = channel * this.outMapSize**2 + row * this.outMapSize + col\r\n\r\n                        for (let neuron=0; neuron<this.nextLayer.neurons.length; neuron++) {\r\n                            this.errors[channel][rowI][colI] += this.nextLayer.neurons[neuron].error\r\n                                                                * this.nextLayer.neurons[neuron].weights[weightIndex]\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else if (this.nextLayer instanceof ConvLayer) {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n\r\n                const errs = []\r\n\r\n                for (let col=0; col<this.outMapSize; col++) {\r\n                    errs[col] = 0\r\n                }\r\n\r\n                // Convolve on the error map\r\n                NetUtil.buildConvErrorMap(this.nextLayer, errs, channel)\r\n\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] += errs[row][col]\r\n                    }\r\n                }\r\n            }\r\n\r\n        } else {\r\n\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n                for (let row=0; row<this.outMapSize; row++) {\r\n                    for (let col=0; col<this.outMapSize; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] += this.nextLayer.errors[channel][row][col]\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Apply derivatives\r\n        if (this.activation) {\r\n            for (let channel=0; channel<this.channels; channel++) {\r\n\r\n                for (let row=0; row<this.indeces[channel].length; row++) {\r\n                    for (let col=0; col<this.indeces[channel].length; col++) {\r\n\r\n                        const rowI = this.indeces[channel][row][col][0] + row * this.stride\r\n                        const colI = this.indeces[channel][row][col][1] + col * this.stride\r\n\r\n                        this.errors[channel][rowI][colI] *= this.activation(this.errors[channel][rowI][colI], true, this.net)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    resetDeltaWeights () {}\r\n\r\n    applyDeltaWeights () {}\r\n\r\n    toJSON () {return {}}\r\n\r\n    fromJSON () {}\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.PoolLayer = PoolLayer)\r\n//# sourceMappingURL=jsNet.concat.js.map"]}