{"version":3,"sources":["jsNetWebAssembly.concat.js"],"names":["ConvLayer","[object Object]","size","filterSize","zeroPadding","stride","activation","window","exports","FCLayer","this","neurons","Array","map","n","Neuron","layerIndex","layer","nextLayer","netInstance","prevLayer","forEach","neuron","ni","init","updateFn","net","weights","bias","data","length","Error","Layer","NetMath","values","total","i","NetUtil","func","returnType","paramTypes","params","heapIn","heapOut","returnArraySize","heapMap","HEAP8","Int8Array","HEAPU8","Uint8Array","HEAP16","Int16Array","HEAPU16","Uint16Array","HEAP32","Int32Array","HEAPU32","Uint32Array","HEAPF32","Float32Array","HEAPF64","Float64Array","res","error","returnTypeParam","parameters","parameterTypes","bufs","p","isArray","typedArray","buf","Module","_malloc","BYTES_PER_ELEMENT","set","push","undefined","ccall","e","b","_free","returnData","v","value","type","replace","toLowerCase","date","Date","formatted","getMilliseconds","getSeconds","getHours","getMinutes","join","self","prop","valTypes","getCallback","x","setCallback","Object","defineProperty","get","val","concat","returnSize","ccallArrays","Network","learningRate","cost","layers","rmsDecay","rho","lreluSlope","eluAlpha","dropout","l2","l1","maxNorm","weightsConfig","state","cwrap","bind","activationsIndeces","sigmoid","tanh","lecuntanh","relu","lrelu","rrelu","elu","activationName","format","costIndeces","meansquarederror","crossentropy","costFunctionName","updateFnIndeces","vanillaupdatefn","gain","adagrad","rmsprop","adam","adadelta","index","keys","find","key","name","weightsConfigFns","uniform","gaussian","xavieruniform","xaviernormal","lecununiform","lecunnormal","Math","round","distribution","limit","mean","stdDeviation","epochs","iterations","every","item","Number","isInteger","initLayers","PoolLayer","input","expected","ceil","abs","l","joinLayer","assignNext","assignPrev","console","warn","callback","miniBatchSize","log","shuffle","Promise","resolve","reject","output","startTime","now","dimension","itemSize","itemsCount","di","hasOwnProperty","ii","ei","elapsed","epochIndex","iterationIndex","doEpoch","l2Error","l1Error","doIteration","setTimeout","totalError","avgError","toJSON","li","fromJSON","version","neuronIndex","defineArrayProperty"],"mappings":"AAAA,mBAEMA,UAEFC,YAAaC,MAAMC,WAACA,WAAUC,YAAEA,YAAWC,OAAEA,OAAMC,WAAEA,kBAO1C,oBAARC,SAAwBC,QAAQR,UAAYA,iBAI7CS,QAEFR,YAAaC,MACTQ,KAAKR,KAAOA,KACZQ,KAAKC,YAAc,IAAIC,MAAMV,OAAOW,IAAIC,GAAK,IAAIC,QACjDL,KAAKM,WAAa,EAGtBf,WAAYgB,OACRP,KAAKQ,UAAYD,MAGrBhB,WAAYkB,YAAaF,MAAOD,YAC5BN,KAAKS,YAAcA,YACnBT,KAAKU,UAAYH,MACjBP,KAAKM,WAAaA,WAGtBf,OACIS,KAAKC,QAAQU,QAAQ,CAACC,OAAQC,MAC1B,QAAQ,GAEJ,KAAKb,KAAKU,qBAAqBX,QAC3Ba,OAAOpB,KAAOQ,KAAKU,UAAUlB,KAIrCoB,OAAOE,KAAKd,KAAKS,YAAaT,KAAKM,WAAYO,IAC3CE,SAAUf,KAAKgB,IAAID,aAK/BxB,SACI,OACI0B,QAASjB,KAAKC,QAAQE,IAAIS,UAElBM,KAAMN,OAAOM,KACbD,QAASL,OAAOK,YAMhC1B,SAAU4B,KAAMb,YAEZN,KAAKC,QAAQU,QAAQ,CAACC,OAAQC,MAE1B,GAAIM,KAAKF,QAAQJ,IAAII,QAAQG,QAASR,OAAe,QAACQ,OAClD,MAAM,IAAIC,0CAA0CF,KAAKF,QAAQJ,IAAII,QAAQG,oBAAoBR,OAAOK,QAAQG,qBAAqBd,wBAAwBO,OAGjKD,OAAOM,KAAOC,KAAKF,QAAQJ,IAAIK,KAC/BN,OAAOK,QAAUE,KAAKF,QAAQJ,IAAII,WAK9C,MAAMK,MAAQvB,QAEC,oBAARF,SAAwBC,QAAQC,QAAUD,QAAQwB,MAAQvB,eAG3DwB,QACFhC,eAAgBiC,QACZ,IAAIC,MAAQ,EAEZ,IAAK,IAAIC,EAAE,EAAGA,EAAEF,OAAOJ,OAAQM,IAC3BD,OAASD,OAAOE,GAGpB,IAAK,IAAIA,EAAE,EAAGA,EAAEF,OAAOJ,OAAQM,IACvBD,QACAD,OAAOE,IAAMD,OAIrB,OAAOD,QAIA,oBAAR3B,SAAwBC,QAAQyB,QAAUA,eAG3CI,QAEFpC,mBAAoBqC,KAAMC,WAAYC,WAAYC,QAAQC,OAACA,OAAO,UAASC,QAAEA,QAAQ,UAASC,gBAAEA,gBAAgB,OAE5G,MAAMC,WACNA,QAAQC,MAAQC,UAChBF,QAAQG,OAASC,WACjBJ,QAAQK,OAASC,WACjBN,QAAQO,QAAUC,YAClBR,QAAQS,OAASC,WACjBV,QAAQW,QAAUC,YAClBZ,QAAQa,QAAUC,aAClBd,QAAQe,QAAUC,aAElB,IAAIC,IACAC,MACJvB,WAAaA,eACb,MAAMwB,gBAA8B,SAAZzB,WAAsB,SAAWA,WACnD0B,cACAC,kBACAC,QAEN,IACI,GAAI1B,OACA,IAAK,IAAI2B,EAAE,EAAGA,EAAE3B,OAAOX,OAAQsC,IAE3B,GAAqB,SAAjB5B,WAAW4B,IAAiBxD,MAAMyD,QAAQ5B,OAAO2B,IAAK,CAEtD,MAAME,WAAa,IAAIzB,QAAQH,QAAQD,OAAO2B,GAAGtC,QAEjD,IAAK,IAAIM,EAAE,EAAGA,EAAEK,OAAO2B,GAAGtC,OAAQM,IAC9BkC,WAAWlC,GAAKK,OAAO2B,GAAGhC,GAG9B,MAAMmC,IAAMlC,QAAQmC,OAAOC,QAAQH,WAAWxC,OAASwC,WAAWI,mBAElE,OAAQhC,QACJ,IAAK,QAAS,IAAK,SACfL,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KACvC,MACJ,IAAK,SAAU,IAAK,UAChBlC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAC9C,MACJ,IAAK,SAAU,IAAK,UAAW,IAAK,UAChClC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAC9C,MACJ,IAAK,UACDlC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAItDJ,KAAKS,KAAKL,KACVN,WAAWW,KAAKL,KAChBN,WAAWW,KAAKnC,OAAO2B,GAAGtC,QAC1BoC,eAAeU,KAAK,UACpBV,eAAeU,KAAK,eAGpBX,WAAWW,KAAKnC,OAAO2B,IACvBF,eAAeU,UAAoBC,GAAfrC,WAAW4B,GAAgB,SAAW5B,WAAW4B,IAKjFN,IAAMzB,QAAQmC,OAAOM,MAAMxC,KAAM0B,gBAAiBE,eAAgBD,YACpE,MAAOc,GACLhB,MAAQgB,EACV,QACE,IAAK,IAAIC,EAAE,EAAGA,EAAEb,KAAKrC,OAAQkD,IACzB3C,QAAQmC,OAAOS,MAAMd,KAAKa,IAIlC,GAAIjB,MAAO,MAAMA,MAGjB,GAAgB,SAAZxB,WAAqB,CACrB,MAAM2C,cAEN,IAAK,IAAIC,EAAE,EAAGA,EAAEvC,gBAAiBuC,IAC7BD,WAAWN,KAAKvC,QAAQmC,OAAO7B,SAASmB,IAAIjB,QAAQF,SAAS+B,kBAAkBS,IAGnF,OAAOD,WAEP,OAAOpB,IAIf7D,cAAemF,MAAOC,KAAK,UACvB,QAAQ,GAEJ,IAAW,UAANA,MAAgC,iBAAPD,MAC1BA,MAAQA,MAAME,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAW,QAANF,MAA8B,iBAAPD,MACxB,MAAMI,KAAO,IAAIC,KAAKL,OAChBM,aAEFN,MAAQ,IACRM,UAAUd,QAAQY,KAAKG,uBAEhBP,MAAQ,IACfM,UAAUd,QAAQY,KAAKI,gBAAgBJ,KAAKG,uBAIxCP,OAAS,MAASM,UAAUd,QAAQY,KAAKK,eAE7CH,UAAUd,QAAQY,KAAKM,iBACvBJ,UAAUd,QAAQY,KAAKI,kBAG3BR,MAAQM,UAAUK,KAAK,KAI/B,OAAOX,MAGXnF,sBAAuB+F,KAAMC,KAAMC,YAAahE,WAAWiE,YAACA,YAAYC,CAAAA,GAAGA,GAACC,YAAEA,YAAYD,CAAAA,GAAGA,QACzFE,OAAOC,eAAeP,KAAMC,MACxBO,IAAK,IAAML,YAAYzF,KAAK8D,OAAOM,aAAamB,OAAQ,SAAUC,SAAUhE,SAC5EyC,IAAK8B,KAAO/F,KAAK8D,OAAOM,aAAamB,OAAQ,KAAMC,SAASQ,OAAO,UAAWxE,OAAOwE,OAAOL,YAAYI,SAIhHxG,2BAA4B+F,KAAMC,KAAMC,SAAUhE,OAAQyE,YACtDL,OAAOC,eAAeP,KAAMC,MACxBO,IAAK,IAAMnE,QAAQuE,mBAAmBX,OAAQ,QAASC,SAAUhE,QAASU,gBAAiB+D,WAAYhE,QAAS,YAChHgC,IAAMS,OAAU/C,QAAQuE,mBAAmBX,OAAQ,KAAMC,SAASQ,OAAO,SAAUxE,OAAOwE,QAAQtB,SAAU1C,OAAQ,eAMjH,oBAARnC,SAAwBC,QAAQ6B,QAAUA,eAG3CwE,QAEF5G,aAAauE,OAACA,OAAMsC,aAAEA,aAAYxG,WAAEA,WAAW,UAASmB,SAAEA,SAAS,kBAAiBsF,KAAEA,KAAK,mBAAkBC,OAAEA,UAASC,SACpHA,SAAQC,IAAEA,IAAGC,WAAEA,WAAUC,SAAEA,SAAQC,QAAEA,QAAQ,EAACC,GAAEA,IAAG,EAAIC,GAAEA,IAAG,EAAIC,QAAEA,QAAOC,cAAEA,gBAE3E,IAAKjD,OACD,MAAM,IAAIzC,MAAM,4BAGpB,GAAyB,mBAAdzB,YAA2C,mBAARyG,KAC1C,MAAM,IAAIhF,MAAM,uDAGpBM,QAAQmC,OAASA,OACjB9D,KAAK8D,OAASA,OACd9D,KAAKS,YAAcT,KAAK8D,OAAOM,MAAM,aAAc,KAAM,KAAM,MAC/DpE,KAAKgH,MAAQ,cAGbpB,OAAOC,eAAe7F,KAAM,gBACxB8F,IAAK9F,KAAK8D,OAAOmD,MAAM,kBAAmB,KAAM,MAAMC,KAAKlH,KAAMA,KAAKS,aACtEwD,IAAKjE,KAAK8D,OAAOmD,MAAM,kBAAmB,SAAU,MAAMC,KAAKlH,KAAMA,KAAKS,eAG1E2F,eAAcpG,KAAKoG,aAAeA,cAEtCzE,QAAQkE,eAAe7F,KAAM,WAAY,WAAYA,KAAKS,cAC1DT,KAAK2G,QAAmB,GAATA,QAAiB,EAAIA,QAEhCC,KACAjF,QAAQkE,eAAe7F,KAAM,MAAO,WAAYA,KAAKS,cACrDkB,QAAQkE,eAAe7F,KAAM,WAAY,WAAYA,KAAKS,cAC1DT,KAAK4G,GAAgB,kBAAJA,GAAgB,KAAQA,IAGzCC,KACAlF,QAAQkE,eAAe7F,KAAM,MAAO,WAAYA,KAAKS,cACrDkB,QAAQkE,eAAe7F,KAAM,WAAY,WAAYA,KAAKS,cAC1DT,KAAK6G,GAAgB,kBAAJA,GAAgB,KAAQA,IAGzCC,UACAnF,QAAQkE,eAAe7F,KAAM,WAAY,WAAYA,KAAKS,cAC1DkB,QAAQkE,eAAe7F,KAAM,gBAAiB,WAAYA,KAAKS,cAC/DT,KAAK8G,QAA0B,kBAATA,SAAsBA,QAAU,IAAOA,SAGjElB,OAAOC,eAAe7F,KAAM,SACxB8F,IAAK,IAAMhC,OAAOM,MAAM,WAAY,UAAW,WAAYpE,KAAKS,gBAIpE,MAAM0G,oBACFC,QAAS,EACTC,KAAM,EACNC,UAAW,EACXC,KAAM,EACNC,MAAO,EACPC,MAAO,EACPC,IAAK,GAET,IAAIC,eAAiBhG,QAAQiG,OAAOhI,YACpCgG,OAAOC,eAAe7F,KAAM,cACxB8F,IAAK,YAAc6B,iBACnB1D,IAAKrE,aAED,QAAsCuE,GAAlCgD,mBAAmBvH,YACnB,MAAM,IAAIyB,aAAazB,iDAE3B+H,eAAiB/H,WACjBI,KAAK8D,OAAOM,MAAM,gBAAiB,MAAO,SAAU,WAAYpE,KAAKS,YAAa0G,mBAAmBvH,iBAG7GI,KAAKJ,WAAa+H,eAGlB,MAAME,aACFC,iBAAkB,EAClBC,aAAc,GAElB,IAAIC,iBAAmBrG,QAAQiG,OAAOvB,MACtCT,OAAOC,eAAe7F,KAAM,QACxB8F,IAAK,YAAckC,mBACnB/D,IAAKoC,OACD,QAAyBlC,GAArB0D,YAAYxB,MACZ,MAAM,IAAIhF,aAAagF,gCAE3B2B,iBAAmB3B,KACnBrG,KAAK8D,OAAOM,MAAM,kBAAmB,MAAO,SAAU,WAAYpE,KAAKS,YAAaoH,YAAYxB,WAGxGrG,KAAKqG,KAAO2B,iBAEZ,MAAMC,iBACFC,gBAAiB,EACjBC,KAAM,EACNC,QAAS,EACTC,QAAS,EACTC,KAAM,EACNC,SAAU,GAEd5G,QAAQkE,eAAe7F,KAAM,YAAa,WAAYA,KAAKS,cACvDgF,YAAa+C,OAAS5C,OAAO6C,KAAKR,iBAAiBS,KAAKC,KAAOV,gBAAgBU,MAAMH,OACrF7C,YAAaiD,MAAQX,gBAAgBW,QAEzC5I,KAAKe,SAAWY,QAAQiG,OAAO7G,UAI/B,MAAM8H,kBACFC,QAAS,EACTC,SAAU,EACVC,cAAe,EACfC,aAAc,EACdC,aAAc,EACdC,YAAa,GAcjB,GAZAnJ,KAAK+G,iBAELpF,QAAQkE,eAAe7F,KAAK+G,cAAe,gBAAiB,WAAY/G,KAAKS,cACzEgF,YAAa+C,OAAS5C,OAAO6C,KAAKI,kBAAkBH,KAAKC,KAAOE,iBAAiBF,MAAMS,KAAKC,MAAMb,QAClG7C,YAAaiD,MAAQC,iBAAiBD,QAE1CjH,QAAQkE,eAAe7F,KAAK+G,cAAe,SAAU,WAAY/G,KAAKS,cACtEkB,QAAQkE,eAAe7F,KAAK+G,cAAe,QAAS,WAAY/G,KAAKS,cACrEkB,QAAQkE,eAAe7F,KAAK+G,cAAe,gBAAiB,WAAY/G,KAAKS,cAE7ET,KAAK+G,cAAcuC,aAAe,qBAEfnF,GAAf4C,eAA4BA,cAAcuC,aAAc,CAExD,GAAyC,mBAA9BvC,cAAcuC,aACrB,MAAM,IAAIjI,MAAM,oEAGpBrB,KAAK+G,cAAcuC,aAAe3H,QAAQiG,OAAOb,cAAcuC,cAOnE,OAJAtJ,KAAK+G,cAAcwC,MAAQxC,oBAAsC5C,GAArB4C,cAAcwC,MAAmBxC,cAAcwC,MAAQ,GACnGvJ,KAAK+G,cAAcyC,KAAOzC,oBAAqC5C,GAApB4C,cAAcyC,KAAkBzC,cAAcyC,KAAO,EAChGxJ,KAAK+G,cAAc0C,aAAe1C,oBAA6C5C,GAA5B4C,cAAc0C,aAA0B1C,cAAc0C,aAAe,IAEhH9H,QAAQiG,OAAO7G,WAEnB,IAAK,UACDf,KAAKoG,kBAAkCjC,GAAnBnE,KAAKoG,aAA0B,KAAQpG,KAAKoG,aAChE,MAEJ,IAAK,OACDpG,KAAKoG,kBAAkCjC,GAAnBnE,KAAKoG,aAA0B,IAAOpG,KAAKoG,aAC/D,MAEJ,IAAK,WACDzE,QAAQkE,eAAe7F,KAAM,OAAQ,WAAYA,KAAKS,cACtDT,KAAKwG,IAAW,MAALA,IAAY,IAAOA,IAC9B,MAEJ,QAEI,QAAkBrC,GAAdiC,aAEA,OAAQuB,gBACJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACD3H,KAAKoG,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACDpG,KAAKoG,aAAe,KACpB,MAEJ,QACIpG,KAAKoG,aAAe,IAuBxC,GAlBmB,WAAfpG,KAAKe,WACLY,QAAQkE,eAAe7F,KAAM,YAAa,WAAYA,KAAKS,cAC3DT,KAAKuG,cAAsBpC,IAAXoC,SAAuB,IAAOA,UAG9B,SAAhBoB,gBACAhG,QAAQkE,eAAe7F,KAAM,cAAe,WAAYA,KAAKS,cAC7DT,KAAKyG,gBAAyBtC,GAAZsC,YAAyB,KAASA,YAC7B,OAAhBkB,iBACPhG,QAAQkE,eAAe7F,KAAM,YAAa,WAAYA,KAAKS,cAC3DT,KAAK0G,cAAqBvC,GAAVuC,SAAsB,EAAIA,UAG9C1G,KAAKsG,UACLtG,KAAK0J,OAAS,EACd1J,KAAK2J,WAAa,EAGdrD,OAAOlF,OAIP,OAFApB,KAAKgH,MAAQ,eAEL,GACJ,KAAKV,OAAOsD,MAAMC,MAAQC,OAAOC,UAAUF,OACvC7J,KAAKsG,OAASA,OAAOnG,IAAIX,MAAQ,IAAIO,QAAQP,OAC7CQ,KAAKgK,aACL,MAEJ,KAAK1D,OAAOsD,MAAMrJ,OAASA,iBAAiBR,SAAWQ,iBAAiBjB,WAAaiB,iBAAiB0J,WAClGjK,KAAKsG,OAASA,OACdtG,KAAKgK,aACL,MAEJ,QACI,MAAM,IAAI3I,MAAM,2DAMhC9B,WAAY2K,MAAOC,UAEf,GAAkB,eAAdnK,KAAKgH,MAAT,CAIkB,eAAdhH,KAAKgH,QACLhH,KAAKsG,OAAO,GAAK,IAAIvG,QAAQmK,OAC7BlK,KAAKsG,OAAO,GAAK,IAAIvG,QAAQqJ,KAAKgB,KAAKF,MAAMC,SAAW,EAAIA,SAAYf,KAAKiB,IAAIH,MAAMC,UAAW,EACtCD,MAAQC,WACpEnK,KAAKsG,OAAO,GAAK,IAAIvG,QAAQqJ,KAAKgB,KAAKD,YAG3CnK,KAAKgH,MAAQ,cAEb,IAAK,IAAIsD,EAAE,EAAGA,EAAEtK,KAAKsG,OAAOlF,OAAQkJ,IAAK,CAErC,MAAM/J,MAAQP,KAAKsG,OAAOgE,GAEtB/J,iBAAiBR,UACjBC,KAAK8D,OAAOM,MAAM,aAAc,MAAO,SAAU,WAAYpE,KAAKS,YAAaF,MAAMf,OACrFQ,KAAKuK,UAAUhK,MAAO+J,IAI9BtK,KAAK8D,OAAOM,MAAM,aAAc,MAAO,WAAYpE,KAAKS,eAG5DlB,UAAWgB,MAAOD,YAEdC,MAAMS,IAAMhB,KACZO,MAAMD,WAAaA,WAEfA,aACAN,KAAKsG,OAAOhG,WAAW,GAAGkK,WAAWjK,OACrCA,MAAMkK,WAAWzK,KAAKS,YAAaT,KAAKsG,OAAOhG,WAAW,GAAIA,YAC9DC,MAAMO,QAIdvB,QAAS4B,MAEL,GAAgB,eAAZnB,KAAKgH,MACL,MAAM,IAAI3F,MAAM,iDAGpB,QAAa8C,IAAThD,MAA+B,OAATA,KACtB,MAAM,IAAIE,MAAM,uCAOpB,OAJIF,KAAKC,QAAUpB,KAAKsG,OAAO,GAAGrG,QAAQmB,QACtCsJ,QAAQC,KAAK,8DAGVhJ,QAAQuE,YAAY,UAAW,SAAU,SAAU,UAAWlG,KAAKS,YAAaU,OACnFc,QAAS,UACTC,gBAAiBlC,KAAKsG,OAAOtG,KAAKsG,OAAOlF,OAAO,GAAGnB,QAAQmB,SAInE7B,MAAO4B,MAAMuI,OAACA,OAAO,EAACkB,SAAEA,SAAQC,cAAEA,cAAc,EAACC,IAAEA,KAAI,EAAIC,QAAEA,SAAQ,OAKjE,OAHAF,cAAsC,kBAAfA,eAA4BA,cAAgB1J,KAAK,GAAGgJ,SAAS/I,OAASyJ,cAC7F7K,KAAK8D,OAAOM,MAAM,oBAAqB,MAAO,SAAU,WAAYpE,KAAKS,YAAaoK,gBAE/E,IAAIG,QAAQ,CAACC,QAASC,UAEzB,QAAa/G,IAAThD,MAA+B,OAATA,KACtB,YAAY+J,OAAO,oBAGL,eAAdlL,KAAKgH,OACLhH,KAAKgK,WAAW7I,KAAK,GAAG+I,MAAM9I,QAASD,KAAK,GAAGgJ,UAAYhJ,KAAK,GAAGgK,QAAQ/J,QAG/E,MAAMgK,UAAYrG,KAAKsG,MAEjBC,UAAYnK,KAAK,GAAG+I,MAAM9I,OAC1BmK,SAAWD,WAAanK,KAAK,GAAGgJ,UAAYhJ,KAAK,GAAGgK,QAAQ/J,OAC5DoK,WAAaD,SAAWpK,KAAKC,OAE7BwC,WAAa,IAAIX,aAAauI,YAEhCV,KACAJ,QAAQI,iCAAiCpB,sBAAsBmB,iBAGnE,IAAK,IAAIY,GAAG,EAAGA,GAAGtK,KAAKC,OAAQqK,KAAM,CAEjC,IAAKtK,KAAKsK,IAAIC,eAAe,WAAcvK,KAAKsK,IAAIC,eAAe,cAAgBvK,KAAKsK,IAAIC,eAAe,UACvG,YAAYR,OAAO,sFAGvB,IAAI1C,MAAQ+C,SAASE,GAErB,IAAK,IAAIE,GAAG,EAAGA,GAAGxK,KAAKsK,IAAIvB,MAAM9I,OAAQuK,KACrC/H,WAAW4E,OAASrH,KAAKsK,IAAIvB,MAAMyB,IACnCnD,QAGJ,IAAK,IAAIoD,GAAG,EAAGA,IAAIzK,KAAKsK,IAAItB,UAAYhJ,KAAKsK,IAAIN,QAAQ/J,OAAQwK,KAC7DhI,WAAW4E,QAAUrH,KAAKsK,IAAItB,UAAYhJ,KAAKsK,IAAIN,QAAQS,IAC3DpD,QAIR,MAAM3E,IAAM7D,KAAK8D,OAAOC,QAAQH,WAAWxC,OAAOwC,WAAWI,mBAC7DhE,KAAK8D,OAAOd,QAAQiB,IAAIL,WAAYC,KAAO,GAE3C,IAAIgI,QAOJ,GALA7L,KAAK8D,OAAOM,MAAM,mBAAoB,UAAW,SAAU,SAAU,SAAU,SAAU,WACxDpE,KAAKS,YAAaoD,IAAK2H,WAAYD,SAAUD,YAE9EtL,KAAK8D,OAAOM,MAAM,sBAAuB,MAAO,WAAYpE,KAAKS,cAE7DmK,SAAU,CAEV,IAAIkB,WAAa,EACbC,eAAiB,EAErB,MAAMC,QAAU,KAERhM,KAAK4G,KAAI5G,KAAKiM,QAAU,GACxBjM,KAAK6G,KAAI7G,KAAKkM,QAAU,GAE5BH,eAAiB,EACjBI,eAGEA,YAAc,KAEhBnM,KAAK8D,OAAOM,MAAM,QAAS,UAAW,SAAU,SAAU,WAAYpE,KAAKS,YAAaoK,cAAekB,iBAEvGnB,UACIjB,WAAaoC,eAAe,EAC5B1I,MAAOrD,KAAKqD,MACZwI,QAAS9G,KAAKsG,MAAQD,UACtBlB,MAAO/I,KAAKnB,KAAK2J,YAAYO,SAGjC6B,gBAAkBlB,eAEG1J,KAAKC,OACtBgL,WAAWD,YAAYjF,KAAKlH,MAAO,IAEnC8L,aAEAD,QAAU9G,KAAKsG,MAAQD,UAEvBN,KAAOJ,QAAQI,aAAagB,qBAAqB9L,KAAKqD,aAAiBc,GAATnE,KAAK4G,GAAgB,iBAAkB5G,KAAKiM,QAAQF,iCACxFpK,QAAQiG,OAAOiE,QAAS,6BAA6BlK,QAAQiG,OAAOiE,QAAQC,WAAY,WAE9GA,WAAapC,OACbsC,WAEAhM,KAAK8D,OAAOS,MAAMV,KAClBoH,aAIZe,cAEG,CACH,IAAK,IAAI3H,EAAE,EAAGA,EAAEqF,OAAQrF,IAEhBrE,KAAK4G,KAAI5G,KAAKiM,QAAU,GACxBjM,KAAK6G,KAAI7G,KAAKkM,QAAU,GAE5BlM,KAAK8D,OAAOM,MAAM,QAAS,UAAW,SAAU,SAAU,WAAYpE,KAAKS,aAAc,EAAG,IAC5FoL,QAAU9G,KAAKsG,MAAQD,UACnBN,KACAJ,QAAQI,aAAazG,EAAE,YAAYrE,KAAKqD,aAAiBc,GAATnE,KAAK4G,GAAgB,iBAAkB5G,KAAKiM,QAAQ9K,KAAKC,yBAC/EO,QAAQiG,OAAOiE,QAAS,6BAA6BlK,QAAQiG,OAAOiE,SAASxH,EAAE,GAAI,WAGrHrE,KAAK8D,OAAOS,MAAMV,KACdiH,KACAJ,QAAQI,sCAAsCnJ,QAAQiG,OAAOiE,QAAS,WAE1EZ,aAKZ1L,KAAM4B,MAAM2J,IAACA,KAAI,EAAIF,SAAEA,cACnB,OAAO,IAAII,QAAQ,CAACC,QAASC,eAEZ/G,IAAThD,MAA+B,OAATA,MACtB+J,OAAO,oBAGPJ,KACAJ,QAAQI,IAAI,mBAGhB,MAAMM,UAAYrG,KAAKsG,MACjBC,UAAYnK,KAAK,GAAG+I,MAAM9I,OAC1BmK,SAAWD,WAAanK,KAAK,GAAGgJ,UAAYhJ,KAAK,GAAGgK,QAAQ/J,OAC5DoK,WAAaD,SAAWpK,KAAKC,OAC7BwC,WAAa,IAAIX,aAAauI,YAEpC,IAAK,IAAIC,GAAG,EAAGA,GAAGtK,KAAKC,OAAQqK,KAAM,CAEjC,IAAIjD,MAAQ+C,SAASE,GAErB,IAAK,IAAIE,GAAG,EAAGA,GAAGxK,KAAKsK,IAAIvB,MAAM9I,OAAQuK,KACrC/H,WAAW4E,OAASrH,KAAKsK,IAAIvB,MAAMyB,IACnCnD,QAGJ,IAAK,IAAIoD,GAAG,EAAGA,IAAIzK,KAAKsK,IAAItB,UAAYhJ,KAAKsK,IAAIN,QAAQ/J,OAAQwK,KAC7DhI,WAAW4E,QAAUrH,KAAKsK,IAAItB,UAAYhJ,KAAKsK,IAAIN,QAAQS,IAC3DpD,QAIR,MAAM3E,IAAM7D,KAAK8D,OAAOC,QAAQH,WAAWxC,OAAOwC,WAAWI,mBAM7D,GALAhE,KAAK8D,OAAOd,QAAQiB,IAAIL,WAAYC,KAAO,GAE3C7D,KAAK8D,OAAOM,MAAM,kBAAmB,UAAW,SAAU,SAAU,SAAU,SAAU,WACvDpE,KAAKS,YAAaoD,IAAK2H,WAAYD,SAAUD,YAE1EV,SAAU,CAEV,IAAImB,eAAiB,EACjBM,WAAa,EAEjB,MAAMF,YAAc,KAWhB,GATAE,YAAcrM,KAAK8D,OAAOM,MAAM,OAAQ,UAAW,SAAU,SAAU,WAAYpE,KAAKS,YAAa,EAAGsL,iBAExGnB,UACIjB,WAAaoC,eAAe,EAC5B1I,MAAOgJ,YAAYN,eAAe,GAClCF,QAAS9G,KAAKsG,MAAQD,UACtBlB,MAAO/I,KAAK4K,gBAAgB7B,UAG1B6B,eAAiB5K,KAAKC,OACxBgL,WAAWD,YAAYjF,KAAKlH,MAAO,OAChC,CAGH,MAAM6L,QAAU9G,KAAKsG,MAAQD,UAC7BN,KAAOJ,QAAQI,qCAAqCnJ,QAAQiG,OAAOiE,QAAS,oCAAoClK,QAAQiG,OAAOiE,QAAQE,eAAgB,WAEvJ/L,KAAK8D,OAAOS,MAAMV,KAClBoH,QAAQoB,WAAWlL,KAAKC,UAIhC+K,kBAEG,CAEH,MAAMG,SAAWtM,KAAK8D,OAAOM,MAAM,OAAQ,UAAW,SAAU,WAAYpE,KAAKS,aAAc,EAAG,IAClGT,KAAK8D,OAAOS,MAAMV,KAElB,MAAMgI,QAAU9G,KAAKsG,MAAQD,UAEzBN,KACAJ,QAAQI,qCAAqCnJ,QAAQiG,OAAOiE,QAAS,oCAAoClK,QAAQiG,OAAOiE,QAAQ1K,KAAKC,OAAQ,WAGjJ6J,QAAQqB,aAKpB/M,SACI,OACI+G,OAAQtG,KAAKsG,OAAOnG,IAAII,OAASA,MAAMgM,WAI/ChN,SAAU4B,MAEN,QAAagD,IAAThD,MAA+B,OAATA,KACtB,MAAM,IAAIE,MAAM,iCAGpB,GAAIF,KAAKmF,OAAOlF,QAAUpB,KAAKsG,OAAOlF,OAClC,MAAM,IAAIC,4BAA4BF,KAAKmF,OAAOlF,qCAAqCpB,KAAKsG,OAAOlF,sBAGvGpB,KAAK8D,OAAOM,MAAM,oBAAqB,MAAO,WAAYpE,KAAKS,cAC/DT,KAAKsG,OAAO3F,QAAQ,CAACJ,MAAOiM,KAAOA,IAAMjM,MAAMkM,SAAStL,KAAKmF,OAAOkG,IAAKA,KAG7EE,qBACI,MAAO,SAIA,oBAAR7M,SAAwBC,QAAQqG,QAAUA,eAG3C9F,OAEFd,eAEAA,KAAMkB,YAAaH,WAAYqM,aAAa5L,SAACA,WAMzC,OAJAY,QAAQiL,oBAAoB5M,KAAM,WAAY,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,aAAc3M,KAAKR,MAC1HmC,QAAQkE,eAAe7F,KAAM,QAAS,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,cAC/FhL,QAAQiL,oBAAoB5M,KAAM,gBAAiB,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,aAAc3M,KAAKR,MAEvHuB,UACJ,IAAK,OACDY,QAAQkE,eAAe7F,KAAM,YAAa,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,cACnGhL,QAAQiL,oBAAoB5M,KAAM,cAAe,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,aAAc3M,KAAKR,MAC7H,MACJ,IAAK,UACL,IAAK,UACL,IAAK,WACDmC,QAAQkE,eAAe7F,KAAM,aAAc,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,cACpGhL,QAAQiL,oBAAoB5M,KAAM,gBAAiB,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,aAAc3M,KAAKR,MAEjH,YAAVuB,WACAY,QAAQkE,eAAe7F,KAAM,qBAAsB,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,cAC5GhL,QAAQiL,oBAAoB5M,KAAM,iBAAkB,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,aAAc3M,KAAKR,OAEpI,MAEJ,IAAK,OACDmC,QAAQkE,eAAe7F,KAAM,KAAM,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,cAC5FhL,QAAQkE,eAAe7F,KAAM,KAAM,SAAU,SAAU,WAAYS,YAAaH,WAAYqM,gBAQ7F,oBAAR9M,SAAwBC,QAAQO,OAASA,cAG1C4J,WAIS,oBAARpK,SAAwBC,QAAQmK,UAAYA","file":"jsNetWebAssembly.min.js","sourcesContent":["\"use strict\"\r\n\r\nclass ConvLayer {\r\n\r\n    constructor (size, {filterSize, zeroPadding, stride, activation}={}) {\r\n\r\n\r\n    }\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.ConvLayer = ConvLayer)\r\n\r\n\"use strict\"\r\n\r\nclass FCLayer {\r\n\r\n    constructor (size) {\r\n        this.size = size\r\n        this.neurons = [...new Array(size)].map(n => new Neuron())\r\n        this.layerIndex = 0\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (netInstance, layer, layerIndex) {\r\n        this.netInstance = netInstance\r\n        this.prevLayer = layer\r\n        this.layerIndex = layerIndex\r\n    }\r\n\r\n    init () {\r\n        this.neurons.forEach((neuron, ni) => {\r\n            switch (true) {\r\n\r\n                case this.prevLayer instanceof FCLayer:\r\n                    neuron.size = this.prevLayer.size\r\n                    break\r\n            }\r\n\r\n            neuron.init(this.netInstance, this.layerIndex, ni, {\r\n                updateFn: this.net.updateFn\r\n            })\r\n        })\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.neurons.map(neuron => {\r\n                return {\r\n                    bias: neuron.bias,\r\n                    weights: neuron.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (data.weights[ni].weights.length!=(neuron.weights).length) {\r\n                throw new Error(`Mismatched weights count. Given: ${data.weights[ni].weights.length} Existing: ${neuron.weights.length}. At layers[${layerIndex}], neurons[${ni}]`)\r\n            }\r\n\r\n            neuron.bias = data.weights[ni].bias\r\n            neuron.weights = data.weights[ni].weights\r\n        })\r\n    }\r\n}\r\n\r\nconst Layer = FCLayer\r\n\r\ntypeof window==\"undefined\" && (exports.FCLayer = exports.Layer = FCLayer)\r\n\"use strict\"\r\n\r\nclass NetMath {\r\n    static softmax (values) {\r\n        let total = 0\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            total += values[i]\r\n        }\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            if (total) {\r\n                values[i] /= total\r\n            }\r\n        }\r\n\r\n        return values\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetMath = NetMath)\r\n\"use strict\"\r\n\r\nclass NetUtil {\r\n\r\n    static ccallArrays (func, returnType, paramTypes, params, {heapIn=\"HEAPF32\", heapOut=\"HEAPF32\", returnArraySize=1}={}) {\r\n\r\n        const heapMap = {}\r\n        heapMap.HEAP8 = Int8Array // int8_t\r\n        heapMap.HEAPU8 = Uint8Array // uint8_t\r\n        heapMap.HEAP16 = Int16Array // int16_t\r\n        heapMap.HEAPU16 = Uint16Array // uint16_t\r\n        heapMap.HEAP32 = Int32Array // int32_t\r\n        heapMap.HEAPU32 = Uint32Array // uint32_t\r\n        heapMap.HEAPF32 = Float32Array // float\r\n        heapMap.HEAPF64 = Float64Array // double\r\n\r\n        let res\r\n        let error\r\n        paramTypes = paramTypes || []\r\n        const returnTypeParam = returnType==\"array\" ? \"number\" : returnType\r\n        const parameters = []\r\n        const parameterTypes = []\r\n        const bufs = []\r\n\r\n        try {\r\n            if (params) {\r\n                for (let p=0; p<params.length; p++) {\r\n\r\n                    if (paramTypes[p] == \"array\" || Array.isArray(params[p])) {\r\n\r\n                        const typedArray = new heapMap[heapIn](params[p].length)\r\n\r\n                        for (let i=0; i<params[p].length; i++) {\r\n                            typedArray[i] = params[p][i]\r\n                        }\r\n\r\n                        const buf = NetUtil.Module._malloc(typedArray.length * typedArray.BYTES_PER_ELEMENT)\r\n\r\n                        switch (heapIn) {\r\n                            case \"HEAP8\": case \"HEAPU8\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf)\r\n                                break\r\n                            case \"HEAP16\": case \"HEAPU16\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 1)\r\n                                break\r\n                            case \"HEAP32\": case \"HEAPU32\": case \"HEAPF32\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 2)\r\n                                break\r\n                            case \"HEAPF64\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 3)\r\n                                break\r\n                        }\r\n\r\n                        bufs.push(buf)\r\n                        parameters.push(buf)\r\n                        parameters.push(params[p].length)\r\n                        parameterTypes.push(\"number\")\r\n                        parameterTypes.push(\"number\")\r\n\r\n                    } else {\r\n                        parameters.push(params[p])\r\n                        parameterTypes.push(paramTypes[p]==undefined ? \"number\" : paramTypes[p])\r\n                    }\r\n                }\r\n            }\r\n\r\n            res = NetUtil.Module.ccall(func, returnTypeParam, parameterTypes, parameters)\r\n        } catch (e) {\r\n            error = e\r\n        } finally {\r\n            for (let b=0; b<bufs.length; b++) {\r\n                NetUtil.Module._free(bufs[b])\r\n            }\r\n        }\r\n\r\n        if (error) throw error\r\n\r\n\r\n        if (returnType==\"array\") {\r\n            const returnData = []\r\n\r\n            for (let v=0; v<returnArraySize; v++) {\r\n                returnData.push(NetUtil.Module[heapOut][res/heapMap[heapOut].BYTES_PER_ELEMENT+v])\r\n            }\r\n\r\n            return returnData\r\n        } else {\r\n            return res\r\n        }\r\n    }\r\n\r\n    static format (value, type=\"string\") {\r\n        switch (true) {\r\n\r\n            case type==\"string\" && typeof value==\"string\":\r\n                value = value.replace(/(_|\\s)/g, \"\").toLowerCase()\r\n                break\r\n\r\n            case type==\"time\" && typeof value==\"number\":\r\n                const date = new Date(value)\r\n                const formatted = []\r\n\r\n                if (value < 1000) {\r\n                    formatted.push(`${date.getMilliseconds()}ms`)\r\n\r\n                } else if (value < 60000) {\r\n                    formatted.push(`${date.getSeconds()}.${date.getMilliseconds()}s`)\r\n\r\n                } else {\r\n\r\n                    if (value >= 3600000) formatted.push(`${date.getHours()}h`)\r\n\r\n                    formatted.push(`${date.getMinutes()}m`)\r\n                    formatted.push(`${date.getSeconds()}s`)\r\n                }\r\n\r\n                value = formatted.join(\" \")\r\n                break\r\n        }\r\n\r\n        return value\r\n    }\r\n\r\n    static defineProperty (self, prop, valTypes=[], values=[], {getCallback=x=>x, setCallback=x=>x}={}) {\r\n        Object.defineProperty(self, prop, {\r\n            get: () => getCallback(this.Module.ccall(`get_${prop}`, \"number\", valTypes, values)),\r\n            set: val => this.Module.ccall(`set_${prop}`, null, valTypes.concat(\"number\"), values.concat(setCallback(val)))\r\n        })\r\n    }\r\n\r\n    static defineArrayProperty (self, prop, valTypes, values, returnSize) {\r\n        Object.defineProperty(self, prop, {\r\n            get: () => NetUtil.ccallArrays(`get_${prop}`, \"array\", valTypes, values, {returnArraySize: returnSize, heapOut: \"HEAPF64\"}),\r\n            set: (value) => NetUtil.ccallArrays(`set_${prop}`, null, valTypes.concat(\"array\"), values.concat([value]), {heapIn: \"HEAPF64\"})\r\n        })\r\n    }\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetUtil = NetUtil)\r\n\"use strict\"\r\n\r\nclass Network {\r\n\r\n    constructor ({Module, learningRate, activation=\"sigmoid\", updateFn=\"vanillaupdatefn\", cost=\"meansquarederror\", layers=[],\r\n        rmsDecay, rho, lreluSlope, eluAlpha, dropout=1, l2=true, l1=true, maxNorm, weightsConfig}) {\r\n\r\n        if (!Module) {\r\n            throw new Error(\"WASM module not provided\")\r\n        }\r\n\r\n        if (typeof activation == \"function\" || typeof cost == \"function\") {\r\n            throw new Error(\"Custom functions are not (yet) supported with WASM.\")\r\n        }\r\n\r\n        NetUtil.Module = Module\r\n        this.Module = Module\r\n        this.netInstance = this.Module.ccall(\"newNetwork\", null, null, null)\r\n        this.state = \"not-defined\"\r\n\r\n        // Learning Rate get / set\r\n        Object.defineProperty(this, \"learningRate\", {\r\n            get: this.Module.cwrap(\"getLearningRate\", null, null).bind(this, this.netInstance),\r\n            set: this.Module.cwrap(\"setLearningRate\", \"number\", null).bind(this, this.netInstance)\r\n        })\r\n\r\n        if (learningRate) this.learningRate = learningRate\r\n\r\n        NetUtil.defineProperty(this, \"dropout\", [\"number\"], [this.netInstance])\r\n        this.dropout = dropout==false ? 1 : dropout\r\n\r\n        if (l2) {\r\n            NetUtil.defineProperty(this, \"l2\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"l2Error\", [\"number\"], [this.netInstance])\r\n            this.l2 = typeof l2==\"boolean\" ? 0.001 : l2\r\n        }\r\n\r\n        if (l1) {\r\n            NetUtil.defineProperty(this, \"l1\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"l1Error\", [\"number\"], [this.netInstance])\r\n            this.l1 = typeof l1==\"boolean\" ? 0.005 : l1\r\n        }\r\n\r\n        if (maxNorm) {\r\n            NetUtil.defineProperty(this, \"maxNorm\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"maxNormTotal\", [\"number\"], [this.netInstance])\r\n            this.maxNorm = typeof maxNorm==\"boolean\" && maxNorm ? 1000 : maxNorm\r\n        }\r\n\r\n        Object.defineProperty(this, \"error\", {\r\n            get: () => Module.ccall(\"getError\", \"number\", [\"number\"], [this.netInstance])\r\n        })\r\n\r\n        // Activation function get / set\r\n        const activationsIndeces = {\r\n            sigmoid: 0,\r\n            tanh: 1,\r\n            lecuntanh: 2,\r\n            relu: 3,\r\n            lrelu: 4,\r\n            rrelu: 5,\r\n            elu: 6\r\n        }\r\n        let activationName = NetUtil.format(activation)\r\n        Object.defineProperty(this, \"activation\", {\r\n            get: () => `WASM ${activationName}`,\r\n            set: activation => {\r\n\r\n                if (activationsIndeces[activation] == undefined) {\r\n                    throw new Error(`The ${activation} activation function does not exist`)\r\n                }\r\n                activationName = activation\r\n                this.Module.ccall(\"setActivation\", null, [\"number\", \"number\"], [this.netInstance, activationsIndeces[activation]])\r\n            }\r\n        })\r\n        this.activation = activationName\r\n\r\n        // Cost function get / set\r\n        const costIndeces = {\r\n            meansquarederror: 0,\r\n            crossentropy: 1\r\n        }\r\n        let costFunctionName = NetUtil.format(cost)\r\n        Object.defineProperty(this, \"cost\", {\r\n            get: () => `WASM ${costFunctionName}`,\r\n            set: cost => {\r\n                if (costIndeces[cost] == undefined) {\r\n                    throw new Error(`The ${cost} function does not exist`)\r\n                }\r\n                costFunctionName = cost\r\n                this.Module.ccall(\"setCostFunction\", null, [\"number\", \"number\"], [this.netInstance, costIndeces[cost]])\r\n            }\r\n        })\r\n        this.cost = costFunctionName\r\n\r\n        const updateFnIndeces = {\r\n            vanillaupdatefn: 0,\r\n            gain: 1,\r\n            adagrad: 2,\r\n            rmsprop: 3,\r\n            adam: 4,\r\n            adadelta: 5\r\n        }\r\n        NetUtil.defineProperty(this, \"updateFn\", [\"number\"], [this.netInstance], {\r\n            getCallback: index => Object.keys(updateFnIndeces).find(key => updateFnIndeces[key]==index),\r\n            setCallback: name => updateFnIndeces[name]\r\n        })\r\n        this.updateFn = NetUtil.format(updateFn)\r\n\r\n\r\n        // Weights init configs\r\n        const weightsConfigFns = {\r\n            uniform: 0,\r\n            gaussian: 1,\r\n            xavieruniform: 2,\r\n            xaviernormal: 3,\r\n            lecununiform: 4,\r\n            lecunnormal: 5\r\n        }\r\n        this.weightsConfig = {}\r\n\r\n        NetUtil.defineProperty(this.weightsConfig, \"distribution\", [\"number\"], [this.netInstance], {\r\n            getCallback: index => Object.keys(weightsConfigFns).find(key => weightsConfigFns[key]==Math.round(index)),\r\n            setCallback: name => weightsConfigFns[name]\r\n        })\r\n        NetUtil.defineProperty(this.weightsConfig, \"limit\", [\"number\"], [this.netInstance])\r\n        NetUtil.defineProperty(this.weightsConfig, \"mean\", [\"number\"], [this.netInstance])\r\n        NetUtil.defineProperty(this.weightsConfig, \"stdDeviation\", [\"number\"], [this.netInstance])\r\n\r\n        this.weightsConfig.distribution = \"xavieruniform\"\r\n\r\n        if (weightsConfig!=undefined && weightsConfig.distribution) {\r\n\r\n            if (typeof weightsConfig.distribution == \"function\") {\r\n                throw new Error(\"Custom weights init functions are not (yet) supported with WASM.\")\r\n            }\r\n\r\n            this.weightsConfig.distribution = NetUtil.format(weightsConfig.distribution)\r\n        }\r\n\r\n        this.weightsConfig.limit = weightsConfig && weightsConfig.limit!=undefined ? weightsConfig.limit : 0.1\r\n        this.weightsConfig.mean = weightsConfig && weightsConfig.mean!=undefined ? weightsConfig.mean : 0\r\n        this.weightsConfig.stdDeviation = weightsConfig && weightsConfig.stdDeviation!=undefined ? weightsConfig.stdDeviation : 0.05\r\n\r\n        switch (NetUtil.format(updateFn)) {\r\n\r\n            case \"rmsprop\":\r\n                this.learningRate = this.learningRate==undefined ? 0.001 : this.learningRate\r\n                break\r\n\r\n            case \"adam\":\r\n                this.learningRate = this.learningRate==undefined ? 0.01 : this.learningRate\r\n                break\r\n\r\n            case \"adadelta\":\r\n                NetUtil.defineProperty(this, \"rho\", [\"number\"], [this.netInstance])\r\n                this.rho = rho==null ? 0.95 : rho\r\n                break\r\n\r\n            default:\r\n\r\n                if (learningRate==undefined) {\r\n\r\n                    switch (activationName) {\r\n                        case \"relu\":\r\n                        case \"lrelu\":\r\n                        case \"rrelu\":\r\n                        case \"elu\":\r\n                            this.learningRate = 0.01\r\n                            break\r\n\r\n                        case \"tanh\":\r\n                        case \"lecuntanh\":\r\n                            this.learningRate = 0.001\r\n                            break\r\n\r\n                        default:\r\n                            this.learningRate = 0.2\r\n                    }\r\n                }\r\n        }\r\n\r\n        if (this.updateFn==\"rmsprop\") {\r\n            NetUtil.defineProperty(this, \"rmsDecay\", [\"number\"], [this.netInstance])\r\n            this.rmsDecay = rmsDecay===undefined ? 0.99 : rmsDecay\r\n        }\r\n\r\n        if (activationName==\"lrelu\") {\r\n            NetUtil.defineProperty(this, \"lreluSlope\", [\"number\"], [this.netInstance])\r\n            this.lreluSlope = lreluSlope==undefined ? -0.0005 : lreluSlope\r\n        } else if (activationName==\"elu\") {\r\n            NetUtil.defineProperty(this, \"eluAlpha\", [\"number\"], [this.netInstance])\r\n            this.eluAlpha = eluAlpha==undefined ? 1 : eluAlpha\r\n        }\r\n\r\n        this.layers = []\r\n        this.epochs = 0\r\n        this.iterations = 0\r\n\r\n\r\n        if (layers.length) {\r\n\r\n            this.state = \"constructed\"\r\n\r\n            switch (true) {\r\n                case layers.every(item => Number.isInteger(item)):\r\n                    this.layers = layers.map(size => new FCLayer(size))\r\n                    this.initLayers()\r\n                    break\r\n\r\n                case layers.every(layer => layer instanceof FCLayer || layer instanceof ConvLayer || layer instanceof PoolLayer):\r\n                    this.layers = layers\r\n                    this.initLayers()\r\n                    break\r\n\r\n                default:\r\n                    throw new Error(\"There was an error constructing from the layers given.\")\r\n\r\n            }\r\n        }\r\n    }\r\n\r\n    initLayers (input, expected) {\r\n\r\n        if (this.state == \"initialised\") {\r\n            return\r\n        }\r\n\r\n        if (this.state == \"not-defined\") {\r\n            this.layers[0] = new FCLayer(input)\r\n            this.layers[1] = new FCLayer(Math.ceil(input/expected > 5 ? expected + (Math.abs(input-expected))/4\r\n                                                                      : input + expected))\r\n            this.layers[2] = new FCLayer(Math.ceil(expected))\r\n        }\r\n\r\n        this.state = \"initialised\"\r\n\r\n        for (let l=0; l<this.layers.length; l++) {\r\n\r\n            const layer = this.layers[l]\r\n\r\n            if (layer instanceof FCLayer) {\r\n                this.Module.ccall(\"addFCLayer\", null, [\"number\", \"number\"], [this.netInstance, layer.size])\r\n                this.joinLayer(layer, l)\r\n            }\r\n        }\r\n\r\n        this.Module.ccall(\"initLayers\", null, [\"number\"], [this.netInstance])\r\n    }\r\n\r\n    joinLayer (layer, layerIndex) {\r\n\r\n        layer.net = this\r\n        layer.layerIndex = layerIndex\r\n\r\n        if (layerIndex) {\r\n            this.layers[layerIndex-1].assignNext(layer)\r\n            layer.assignPrev(this.netInstance, this.layers[layerIndex-1], layerIndex)\r\n            layer.init()\r\n        }\r\n    }\r\n\r\n    forward (data) {\r\n\r\n        if (this.state!=\"initialised\") {\r\n            throw new Error(\"The network layers have not been initialised.\")\r\n        }\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No data passed to Network.forward()\")\r\n        }\r\n\r\n        if (data.length != this.layers[0].neurons.length) {\r\n            console.warn(\"Input data length did not match input layer neurons count.\")\r\n        }\r\n\r\n        return NetUtil.ccallArrays(\"forward\", \"array\", [\"number\", \"array\"], [this.netInstance, data], {\r\n            heapOut: \"HEAPF64\",\r\n            returnArraySize: this.layers[this.layers.length-1].neurons.length\r\n        })\r\n    }\r\n\r\n    train (data, {epochs=1, callback, miniBatchSize=1, log=true, shuffle=false}={}) {\r\n\r\n        miniBatchSize = typeof miniBatchSize==\"boolean\" && miniBatchSize ? data[0].expected.length : miniBatchSize\r\n        this.Module.ccall(\"set_miniBatchSize\", null, [\"number\", \"number\"], [this.netInstance, miniBatchSize])\r\n\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (data === undefined || data === null) {\r\n                return void reject(\"No data provided\")\r\n            }\r\n\r\n            if (this.state != \"initialised\") {\r\n                this.initLayers(data[0].input.length, (data[0].expected || data[0].output).length)\r\n            }\r\n\r\n            const startTime = Date.now()\r\n\r\n            const dimension = data[0].input.length\r\n            const itemSize = dimension + (data[0].expected || data[0].output).length\r\n            const itemsCount = itemSize * data.length\r\n\r\n            const typedArray = new Float32Array(itemsCount)\r\n\r\n            if (log) {\r\n                console.log(`Training started. Epochs: ${epochs} Batch size: ${miniBatchSize}`)\r\n            }\r\n\r\n            for (let di=0; di<data.length; di++) {\r\n\r\n                if (!data[di].hasOwnProperty(\"input\") || (!data[di].hasOwnProperty(\"expected\") && !data[di].hasOwnProperty(\"output\"))) {\r\n                    return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\")\r\n                }\r\n\r\n                let index = itemSize*di\r\n\r\n                for (let ii=0; ii<data[di].input.length; ii++) {\r\n                    typedArray[index] = data[di].input[ii]\r\n                    index++\r\n                }\r\n\r\n                for (let ei=0; ei<(data[di].expected || data[di].output).length; ei++) {\r\n                    typedArray[index] = (data[di].expected || data[di].output)[ei]\r\n                    index++\r\n                }\r\n            }\r\n\r\n            const buf = this.Module._malloc(typedArray.length*typedArray.BYTES_PER_ELEMENT)\r\n            this.Module.HEAPF32.set(typedArray, buf >> 2)\r\n\r\n            let elapsed\r\n\r\n            this.Module.ccall(\"loadTrainingData\", \"number\", [\"number\", \"number\", \"number\", \"number\", \"number\"],\r\n                                            [this.netInstance, buf, itemsCount, itemSize, dimension])\r\n\r\n            this.Module.ccall(\"shuffleTrainingData\", null, [\"number\"], [this.netInstance])\r\n\r\n            if (callback) {\r\n\r\n                let epochIndex = 0\r\n                let iterationIndex = 0\r\n\r\n                const doEpoch = () => {\r\n\r\n                    if (this.l2) this.l2Error = 0\r\n                    if (this.l1) this.l1Error = 0\r\n\r\n                    iterationIndex = 0\r\n                    doIteration()\r\n                }\r\n\r\n                const doIteration = () => {\r\n\r\n                    this.Module.ccall(\"train\", \"number\", [\"number\", \"number\", \"number\"], [this.netInstance, miniBatchSize, iterationIndex])\r\n\r\n                    callback({\r\n                        iterations: (iterationIndex+1),\r\n                        error: this.error,\r\n                        elapsed: Date.now() - startTime,\r\n                        input: data[this.iterations].input\r\n                    })\r\n\r\n                    iterationIndex += miniBatchSize\r\n\r\n                    if (iterationIndex < data.length) {\r\n                        setTimeout(doIteration.bind(this), 0)\r\n                    } else {\r\n                        epochIndex++\r\n\r\n                        elapsed = Date.now() - startTime\r\n\r\n                        log && console.log(`Epoch ${epochIndex} Error: ${this.error}${this.l2==undefined ? \"\": ` L2 Error: ${this.l2Error/iterationIndex}`}`,\r\n                                    `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/epochIndex, \"time\")}`)\r\n\r\n                        if (epochIndex < epochs) {\r\n                            doEpoch()\r\n                        } else {\r\n                            this.Module._free(buf)\r\n                            resolve()\r\n                        }\r\n                    }\r\n                }\r\n                doEpoch()\r\n\r\n            } else {\r\n                for (let e=0; e<epochs; e++) {\r\n\r\n                    if (this.l2) this.l2Error = 0\r\n                    if (this.l1) this.l1Error = 0\r\n\r\n                    this.Module.ccall(\"train\", \"number\", [\"number\", \"number\", \"number\"], [this.netInstance, -1, 0])\r\n                    elapsed = Date.now() - startTime\r\n                    if (log) {\r\n                        console.log(`Epoch ${e+1} Error: ${this.error}${this.l2==undefined ? \"\": ` L2 Error: ${this.l2Error/data.length}`}`,\r\n                                    `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/(e+1), \"time\")}`)\r\n                    }\r\n                }\r\n                this.Module._free(buf)\r\n                if (log) {\r\n                    console.log(`Training finished. Total time: ${NetUtil.format(elapsed, \"time\")}`)\r\n                }\r\n                resolve()\r\n            }\r\n        })\r\n    }\r\n\r\n    test (data, {log=true, callback}={}) {\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (data === undefined || data === null) {\r\n                reject(\"No data provided\")\r\n            }\r\n\r\n            if (log) {\r\n                console.log(\"Testing started\")\r\n            }\r\n\r\n            const startTime = Date.now()\r\n            const dimension = data[0].input.length\r\n            const itemSize = dimension + (data[0].expected || data[0].output).length\r\n            const itemsCount = itemSize * data.length\r\n            const typedArray = new Float32Array(itemsCount)\r\n\r\n            for (let di=0; di<data.length; di++) {\r\n\r\n                let index = itemSize*di\r\n\r\n                for (let ii=0; ii<data[di].input.length; ii++) {\r\n                    typedArray[index] = data[di].input[ii]\r\n                    index++\r\n                }\r\n\r\n                for (let ei=0; ei<(data[di].expected || data[di].output).length; ei++) {\r\n                    typedArray[index] = (data[di].expected || data[di].output)[ei]\r\n                    index++\r\n                }\r\n            }\r\n\r\n            const buf = this.Module._malloc(typedArray.length*typedArray.BYTES_PER_ELEMENT)\r\n            this.Module.HEAPF32.set(typedArray, buf >> 2)\r\n\r\n            this.Module.ccall(\"loadTestingData\", \"number\", [\"number\", \"number\", \"number\", \"number\", \"number\"],\r\n                                            [this.netInstance, buf, itemsCount, itemSize, dimension])\r\n\r\n            if (callback) {\r\n\r\n                let iterationIndex = 0\r\n                let totalError = 0\r\n\r\n                const doIteration = () => {\r\n\r\n                    totalError += this.Module.ccall(\"test\", \"number\", [\"number\", \"number\", \"number\"], [this.netInstance, 1, iterationIndex])\r\n\r\n                    callback({\r\n                        iterations: (iterationIndex+1),\r\n                        error: totalError/(iterationIndex+1),\r\n                        elapsed: Date.now() - startTime,\r\n                        input: data[iterationIndex].input\r\n                    })\r\n\r\n                    if (++iterationIndex < data.length) {\r\n                        setTimeout(doIteration.bind(this), 0)\r\n                    } else {\r\n                        iterationIndex\r\n\r\n                        const elapsed = Date.now() - startTime\r\n                        log && console.log(`Testing finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/iterationIndex, \"time\")}`)\r\n\r\n                        this.Module._free(buf)\r\n                        resolve(totalError/data.length)\r\n                    }\r\n                }\r\n\r\n                doIteration()\r\n\r\n            } else {\r\n\r\n                const avgError = this.Module.ccall(\"test\", \"number\", [\"number\", \"number\"], [this.netInstance, -1, 0])\r\n                this.Module._free(buf)\r\n\r\n                const elapsed = Date.now() - startTime\r\n\r\n                if (log) {\r\n                    console.log(`Testing finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/data.length, \"time\")}`)\r\n                }\r\n\r\n                resolve(avgError)\r\n            }\r\n        })\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            layers: this.layers.map(layer => layer.toJSON())\r\n        }\r\n    }\r\n\r\n    fromJSON (data) {\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No JSON data given to import.\")\r\n        }\r\n\r\n        if (data.layers.length != this.layers.length) {\r\n            throw new Error(`Mismatched layers (${data.layers.length} layers in import data, but ${this.layers.length} configured)`)\r\n        }\r\n\r\n        this.Module.ccall(\"resetDeltaWeights\", null, [\"number\"], [this.netInstance])\r\n        this.layers.forEach((layer, li) => li && layer.fromJSON(data.layers[li], li))\r\n    }\r\n\r\n    static get version () {\r\n        return \"2.1.1\"\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Network = Network)\r\n\"use strict\"\r\n\r\nclass Neuron {\r\n\r\n    constructor () {}\r\n\r\n    init (netInstance, layerIndex, neuronIndex, {updateFn}) {\r\n\r\n        NetUtil.defineArrayProperty(this, \"weights\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n        NetUtil.defineProperty(this, \"bias\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n        NetUtil.defineArrayProperty(this, \"deltaWeights\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n\r\n        switch (updateFn) {\r\n            case \"gain\":\r\n                NetUtil.defineProperty(this, \"biasGain\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineArrayProperty(this, \"weightGain\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n                break\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n                NetUtil.defineProperty(this, \"biasCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineArrayProperty(this, \"weightsCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    NetUtil.defineProperty(this, \"adadeltaBiasCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                    NetUtil.defineArrayProperty(this, \"adadeltaCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                NetUtil.defineProperty(this, \"m\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineProperty(this, \"v\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                break\r\n        }\r\n\r\n    }\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Neuron = Neuron)\r\n\"use strict\"\r\n\r\nclass PoolLayer {\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.PoolLayer = PoolLayer)\r\n\n//# sourceMappingURL=jsNetWebAssembly.concat.js.map"]}