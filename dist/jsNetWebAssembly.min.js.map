{"version":3,"sources":["jsNetWebAssembly.concat.js"],"names":["ConvLayer","[object Object]","size","filterSize","zeroPadding","stride","activation","this","layer","nextLayer","netInstance","layerIndex","prevLayer","weights","filters","map","filter","bias","data","window","exports","FCLayer","neurons","Array","n","Neuron","forEach","neuron","ni","init","updateFn","net","length","Error","Layer","NetMath","values","total","i","NetUtil","func","returnType","paramTypes","params","heapIn","heapOut","returnArraySize","heapMap","HEAP8","Int8Array","HEAPU8","Uint8Array","HEAP16","Int16Array","HEAPU16","Uint16Array","HEAP32","Int32Array","HEAPU32","Uint32Array","HEAPF32","Float32Array","HEAPF64","Float64Array","res","error","returnTypeParam","parameters","parameterTypes","bufs","p","isArray","typedArray","buf","Module","_malloc","BYTES_PER_ELEMENT","set","push","undefined","ccall","e","b","_free","returnData","v","value","type","replace","toLowerCase","date","Date","formatted","getMilliseconds","getSeconds","getHours","getMinutes","join","self","prop","valTypes","getCallback","x","setCallback","Object","defineProperty","get","val","concat","returnSize","ccallArrays","Network","learningRate","cost","layers","rmsDecay","rho","lreluSlope","eluAlpha","dropout","l2","l1","maxNorm","weightsConfig","state","cwrap","bind","activationsIndeces","sigmoid","tanh","lecuntanh","relu","lrelu","rrelu","elu","activationName","format","costIndeces","meansquarederror","crossentropy","costFunctionName","updateFnIndeces","vanillaupdatefn","gain","adagrad","rmsprop","adam","adadelta","index","keys","find","key","name","weightsConfigFns","uniform","gaussian","xavieruniform","xaviernormal","lecununiform","lecunnormal","Math","round","distribution","limit","mean","stdDeviation","epochs","iterations","every","item","Number","isInteger","initLayers","PoolLayer","input","expected","ceil","abs","l","joinLayer","assignNext","assignPrev","console","warn","callback","miniBatchSize","log","Promise","resolve","reject","output","startTime","now","dimension","itemSize","itemsCount","di","hasOwnProperty","ii","ei","elapsed","epochIndex","iterationIndex","doEpoch","l2Error","l1Error","doIteration","setTimeout","avgError","toJSON","li","fromJSON","version","neuronIndex","defineArrayProperty"],"mappings":"AAAA,mBAEMA,UAEFC,YAAaC,MAAMC,WAACA,WAAUC,YAAEA,YAAWC,OAAEA,OAAMC,WAAEA,gBAE7CH,aAAgBI,KAAKJ,WAAaA,YAClCE,SAAgBE,KAAKF,OAASA,QAC9BH,OAAgBK,KAAKL,KAAOA,MAEhCK,KAAKH,YAAcA,YAGvBH,WAAYO,OACRD,KAAKE,UAAYD,MAGrBP,WAAYS,YAAaF,MAAOG,YAE5BJ,KAAKG,YAAcA,YACnBH,KAAKK,UAAYJ,MACjBD,KAAKI,WAAaA,WAItBV,QAIAA,SACI,OACIY,QAASN,KAAKO,QAAQC,IAAIC,UAElBC,KAAMD,OAAOC,KACbJ,QAASG,OAAOH,YAMhCZ,SAAUiB,KAAMP,cAOL,oBAARQ,SAAwBC,QAAQpB,UAAYA,iBAI7CqB,QAEFpB,YAAaC,MACTK,KAAKL,KAAOA,KACZK,KAAKe,YAAc,IAAIC,MAAMrB,OAAOa,IAAIS,GAAK,IAAIC,QACjDlB,KAAKI,WAAa,EAGtBV,WAAYO,OACRD,KAAKE,UAAYD,MAGrBP,WAAYS,YAAaF,MAAOG,YAC5BJ,KAAKG,YAAcA,YACnBH,KAAKK,UAAYJ,MACjBD,KAAKI,WAAaA,WAGtBV,OACIM,KAAKe,QAAQI,QAAQ,CAACC,OAAQC,MAC1B,QAAQ,GAEJ,KAAKrB,KAAKK,qBAAqBS,QAC3BM,OAAOzB,KAAOK,KAAKK,UAAUV,KAIrCyB,OAAOE,KAAKtB,KAAKG,YAAaH,KAAKI,WAAYiB,IAC3CE,SAAUvB,KAAKwB,IAAID,aAK/B7B,SACI,OACIY,QAASN,KAAKe,QAAQP,IAAIY,UAElBV,KAAMU,OAAOV,KACbJ,QAASc,OAAOd,YAMhCZ,SAAUiB,KAAMP,YAEZJ,KAAKe,QAAQI,QAAQ,CAACC,OAAQC,MAE1B,GAAIV,KAAKL,QAAQe,IAAIf,QAAQmB,QAASL,OAAe,QAACK,OAClD,MAAM,IAAIC,0CAA0Cf,KAAKL,QAAQe,IAAIf,QAAQmB,oBAAoBL,OAAOd,QAAQmB,qBAAqBrB,wBAAwBiB,OAGjKD,OAAOV,KAAOC,KAAKL,QAAQe,IAAIX,KAC/BU,OAAOd,QAAUK,KAAKL,QAAQe,IAAIf,WAK9C,MAAMqB,MAAQb,QAEC,oBAARF,SAAwBC,QAAQC,QAAUD,QAAQc,MAAQb,eAG3Dc,QACFlC,eAAgBmC,QACZ,IAAIC,MAAQ,EAEZ,IAAK,IAAIC,EAAE,EAAGA,EAAEF,OAAOJ,OAAQM,IAC3BD,OAASD,OAAOE,GAGpB,IAAK,IAAIA,EAAE,EAAGA,EAAEF,OAAOJ,OAAQM,IACvBD,QACAD,OAAOE,IAAMD,OAIrB,OAAOD,QAIA,oBAARjB,SAAwBC,QAAQe,QAAUA,eAG3CI,QAEFtC,mBAAoBuC,KAAMC,WAAYC,WAAYC,QAAQC,OAACA,OAAO,UAASC,QAAEA,QAAQ,UAASC,gBAAEA,gBAAgB,OAE5G,MAAMC,WACNA,QAAQC,MAAQC,UAChBF,QAAQG,OAASC,WACjBJ,QAAQK,OAASC,WACjBN,QAAQO,QAAUC,YAClBR,QAAQS,OAASC,WACjBV,QAAQW,QAAUC,YAClBZ,QAAQa,QAAUC,aAClBd,QAAQe,QAAUC,aAElB,IAAIC,IACAC,MACJvB,WAAaA,eACb,MAAMwB,gBAA8B,SAAZzB,WAAsB,SAAWA,WACnD0B,cACAC,kBACAC,QAEN,IACI,GAAI1B,OACA,IAAK,IAAI2B,EAAE,EAAGA,EAAE3B,OAAOX,OAAQsC,IAE3B,GAAqB,SAAjB5B,WAAW4B,IAAiB/C,MAAMgD,QAAQ5B,OAAO2B,IAAK,CAEtD,MAAME,WAAa,IAAIzB,QAAQH,QAAQD,OAAO2B,GAAGtC,QAEjD,IAAK,IAAIM,EAAE,EAAGA,EAAEK,OAAO2B,GAAGtC,OAAQM,IAC9BkC,WAAWlC,GAAKK,OAAO2B,GAAGhC,GAG9B,MAAMmC,IAAMlC,QAAQmC,OAAOC,QAAQH,WAAWxC,OAASwC,WAAWI,mBAElE,OAAQhC,QACJ,IAAK,QAAS,IAAK,SACfL,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KACvC,MACJ,IAAK,SAAU,IAAK,UAChBlC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAC9C,MACJ,IAAK,SAAU,IAAK,UAAW,IAAK,UAChClC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAC9C,MACJ,IAAK,UACDlC,QAAQmC,OAAO9B,QAAQiC,IAAIL,WAAYC,KAAO,GAItDJ,KAAKS,KAAKL,KACVN,WAAWW,KAAKL,KAChBN,WAAWW,KAAKnC,OAAO2B,GAAGtC,QAC1BoC,eAAeU,KAAK,UACpBV,eAAeU,KAAK,eAGpBX,WAAWW,KAAKnC,OAAO2B,IACvBF,eAAeU,UAAoBC,GAAfrC,WAAW4B,GAAgB,SAAW5B,WAAW4B,IAKjFN,IAAMzB,QAAQmC,OAAOM,MAAMxC,KAAM0B,gBAAiBE,eAAgBD,YACpE,MAAOc,GACLhB,MAAQgB,EACV,QACE,IAAK,IAAIC,EAAE,EAAGA,EAAEb,KAAKrC,OAAQkD,IACzB3C,QAAQmC,OAAOS,MAAMd,KAAKa,IAIlC,GAAIjB,MAAO,MAAMA,MAGjB,GAAgB,SAAZxB,WAAqB,CACrB,MAAM2C,cAEN,IAAK,IAAIC,EAAE,EAAGA,EAAEvC,gBAAiBuC,IAC7BD,WAAWN,KAAKvC,QAAQmC,OAAO7B,SAASmB,IAAIjB,QAAQF,SAAS+B,kBAAkBS,IAGnF,OAAOD,WAEP,OAAOpB,IAIf/D,cAAeqF,MAAOC,KAAK,UACvB,QAAQ,GAEJ,IAAW,UAANA,MAAgC,iBAAPD,MAC1BA,MAAQA,MAAME,QAAQ,UAAW,IAAIC,cACrC,MAEJ,IAAW,QAANF,MAA8B,iBAAPD,MACxB,MAAMI,KAAO,IAAIC,KAAKL,OAChBM,aAEFN,MAAQ,IACRM,UAAUd,QAAQY,KAAKG,uBAEhBP,MAAQ,IACfM,UAAUd,QAAQY,KAAKI,gBAAgBJ,KAAKG,uBAIxCP,OAAS,MAASM,UAAUd,QAAQY,KAAKK,eAE7CH,UAAUd,QAAQY,KAAKM,iBACvBJ,UAAUd,QAAQY,KAAKI,kBAG3BR,MAAQM,UAAUK,KAAK,KAI/B,OAAOX,MAGXrF,sBAAuBiG,KAAMC,KAAMC,YAAahE,WAAWiE,YAACA,YAAYC,CAAAA,GAAGA,GAACC,YAAEA,YAAYD,CAAAA,GAAGA,QACzFE,OAAOC,eAAeP,KAAMC,MACxBO,IAAK,IAAML,YAAY9F,KAAKmE,OAAOM,aAAamB,OAAQ,SAAUC,SAAUhE,SAC5EyC,IAAK8B,KAAOpG,KAAKmE,OAAOM,aAAamB,OAAQ,KAAMC,SAASQ,OAAO,UAAWxE,OAAOwE,OAAOL,YAAYI,SAIhH1G,2BAA4BiG,KAAMC,KAAMC,SAAUhE,OAAQyE,YACtDL,OAAOC,eAAeP,KAAMC,MACxBO,IAAK,IAAMnE,QAAQuE,mBAAmBX,OAAQ,QAASC,SAAUhE,QAASU,gBAAiB+D,WAAYhE,QAAS,YAChHgC,IAAMS,OAAU/C,QAAQuE,mBAAmBX,OAAQ,KAAMC,SAASQ,OAAO,SAAUxE,OAAOwE,QAAQtB,SAAU1C,OAAQ,eAMjH,oBAARzB,SAAwBC,QAAQmB,QAAUA,eAG3CwE,QAEF9G,aAAayE,OAACA,OAAMsC,aAAEA,aAAY1G,WAAEA,WAAW,UAASwB,SAAEA,SAAS,kBAAiBmF,KAAEA,KAAK,mBAAkBC,OAAEA,UAASC,SACpHA,SAAQC,IAAEA,IAAGC,WAAEA,WAAUC,SAAEA,SAAQC,QAAEA,QAAQ,EAACC,GAAEA,IAAG,EAAIC,GAAEA,IAAG,EAAIC,QAAEA,QAAOC,cAAEA,gBAE3E,IAAKjD,OACD,MAAM,IAAIzC,MAAM,4BAGpB,GAAyB,mBAAd3B,YAA2C,mBAAR2G,KAC1C,MAAM,IAAIhF,MAAM,uDAGpBM,QAAQmC,OAASA,OACjBnE,KAAKmE,OAASA,OACdnE,KAAKG,YAAcH,KAAKmE,OAAOM,MAAM,aAAc,KAAM,KAAM,MAC/DzE,KAAKqH,MAAQ,cAGbpB,OAAOC,eAAelG,KAAM,gBACxBmG,IAAKnG,KAAKmE,OAAOmD,MAAM,kBAAmB,KAAM,MAAMC,KAAKvH,KAAMA,KAAKG,aACtEmE,IAAKtE,KAAKmE,OAAOmD,MAAM,kBAAmB,SAAU,MAAMC,KAAKvH,KAAMA,KAAKG,eAG1EsG,eAAczG,KAAKyG,aAAeA,cAEtCzE,QAAQkE,eAAelG,KAAM,WAAY,WAAYA,KAAKG,cAC1DH,KAAKgH,QAAmB,GAATA,QAAiB,EAAIA,QAEhCC,KACAjF,QAAQkE,eAAelG,KAAM,MAAO,WAAYA,KAAKG,cACrD6B,QAAQkE,eAAelG,KAAM,WAAY,WAAYA,KAAKG,cAC1DH,KAAKiH,GAAgB,kBAAJA,GAAgB,KAAQA,IAGzCC,KACAlF,QAAQkE,eAAelG,KAAM,MAAO,WAAYA,KAAKG,cACrD6B,QAAQkE,eAAelG,KAAM,WAAY,WAAYA,KAAKG,cAC1DH,KAAKkH,GAAgB,kBAAJA,GAAgB,KAAQA,IAGzCC,UACAnF,QAAQkE,eAAelG,KAAM,WAAY,WAAYA,KAAKG,cAC1D6B,QAAQkE,eAAelG,KAAM,gBAAiB,WAAYA,KAAKG,cAC/DH,KAAKmH,QAA0B,kBAATA,SAAsBA,QAAU,IAAOA,SAGjElB,OAAOC,eAAelG,KAAM,SACxBmG,IAAK,IAAMhC,OAAOM,MAAM,WAAY,UAAW,WAAYzE,KAAKG,gBAIpE,MAAMqH,oBACFC,QAAS,EACTC,KAAM,EACNC,UAAW,EACXC,KAAM,EACNC,MAAO,EACPC,MAAO,EACPC,IAAK,GAET,IAAIC,eAAiBhG,QAAQiG,OAAOlI,YACpCkG,OAAOC,eAAelG,KAAM,cACxBmG,IAAK,YAAc6B,iBACnB1D,IAAKvE,aAED,QAAsCyE,GAAlCgD,mBAAmBzH,YACnB,MAAM,IAAI2B,aAAa3B,iDAE3BiI,eAAiBjI,WACjBC,KAAKmE,OAAOM,MAAM,gBAAiB,MAAO,SAAU,WAAYzE,KAAKG,YAAaqH,mBAAmBzH,iBAG7GC,KAAKD,WAAaiI,eAGlB,MAAME,aACFC,iBAAkB,EAClBC,aAAc,GAElB,IAAIC,iBAAmBrG,QAAQiG,OAAOvB,MACtCT,OAAOC,eAAelG,KAAM,QACxBmG,IAAK,YAAckC,mBACnB/D,IAAKoC,OACD,QAAyBlC,GAArB0D,YAAYxB,MACZ,MAAM,IAAIhF,aAAagF,gCAE3B2B,iBAAmB3B,KACnB1G,KAAKmE,OAAOM,MAAM,kBAAmB,MAAO,SAAU,WAAYzE,KAAKG,YAAa+H,YAAYxB,WAGxG1G,KAAK0G,KAAO2B,iBAEZ,MAAMC,iBACFC,gBAAiB,EACjBC,KAAM,EACNC,QAAS,EACTC,QAAS,EACTC,KAAM,EACNC,SAAU,GAEd5G,QAAQkE,eAAelG,KAAM,YAAa,WAAYA,KAAKG,cACvD2F,YAAa+C,OAAS5C,OAAO6C,KAAKR,iBAAiBS,KAAKC,KAAOV,gBAAgBU,MAAMH,OACrF7C,YAAaiD,MAAQX,gBAAgBW,QAEzCjJ,KAAKuB,SAAWS,QAAQiG,OAAO1G,UAI/B,MAAM2H,kBACFC,QAAS,EACTC,SAAU,EACVC,cAAe,EACfC,aAAc,EACdC,aAAc,EACdC,YAAa,GAcjB,GAZAxJ,KAAKoH,iBAELpF,QAAQkE,eAAelG,KAAKoH,cAAe,gBAAiB,WAAYpH,KAAKG,cACzE2F,YAAa+C,OAAS5C,OAAO6C,KAAKI,kBAAkBH,KAAKC,KAAOE,iBAAiBF,MAAMS,KAAKC,MAAMb,QAClG7C,YAAaiD,MAAQC,iBAAiBD,QAE1CjH,QAAQkE,eAAelG,KAAKoH,cAAe,SAAU,WAAYpH,KAAKG,cACtE6B,QAAQkE,eAAelG,KAAKoH,cAAe,QAAS,WAAYpH,KAAKG,cACrE6B,QAAQkE,eAAelG,KAAKoH,cAAe,gBAAiB,WAAYpH,KAAKG,cAE7EH,KAAKoH,cAAcuC,aAAe,qBAEfnF,GAAf4C,eAA4BA,cAAcuC,aAAc,CAExD,GAAyC,mBAA9BvC,cAAcuC,aACrB,MAAM,IAAIjI,MAAM,oEAGpB1B,KAAKoH,cAAcuC,aAAe3H,QAAQiG,OAAOb,cAAcuC,cAOnE,OAJA3J,KAAKoH,cAAcwC,MAAQxC,oBAAsC5C,GAArB4C,cAAcwC,MAAmBxC,cAAcwC,MAAQ,GACnG5J,KAAKoH,cAAcyC,KAAOzC,oBAAqC5C,GAApB4C,cAAcyC,KAAkBzC,cAAcyC,KAAO,EAChG7J,KAAKoH,cAAc0C,aAAe1C,oBAA6C5C,GAA5B4C,cAAc0C,aAA0B1C,cAAc0C,aAAe,IAEhH9H,QAAQiG,OAAO1G,WAEnB,IAAK,UACDvB,KAAKyG,kBAAkCjC,GAAnBxE,KAAKyG,aAA0B,KAAQzG,KAAKyG,aAChE,MAEJ,IAAK,OACDzG,KAAKyG,kBAAkCjC,GAAnBxE,KAAKyG,aAA0B,IAAOzG,KAAKyG,aAC/D,MAEJ,IAAK,WACDzE,QAAQkE,eAAelG,KAAM,OAAQ,WAAYA,KAAKG,cACtDH,KAAK6G,IAAW,MAALA,IAAY,IAAOA,IAC9B,MAEJ,QAEI,QAAkBrC,GAAdiC,aAEA,OAAQuB,gBACJ,IAAK,OACL,IAAK,QACL,IAAK,QACL,IAAK,MACDhI,KAAKyG,aAAe,IACpB,MAEJ,IAAK,OACL,IAAK,YACDzG,KAAKyG,aAAe,KACpB,MAEJ,QACIzG,KAAKyG,aAAe,IAuBxC,GAlBmB,WAAfzG,KAAKuB,WACLS,QAAQkE,eAAelG,KAAM,YAAa,WAAYA,KAAKG,cAC3DH,KAAK4G,cAAsBpC,IAAXoC,SAAuB,IAAOA,UAG9B,SAAhBoB,gBACAhG,QAAQkE,eAAelG,KAAM,cAAe,WAAYA,KAAKG,cAC7DH,KAAK8G,gBAAyBtC,GAAZsC,YAAyB,KAASA,YAC7B,OAAhBkB,iBACPhG,QAAQkE,eAAelG,KAAM,YAAa,WAAYA,KAAKG,cAC3DH,KAAK+G,cAAqBvC,GAAVuC,SAAsB,EAAIA,UAG9C/G,KAAK2G,UACL3G,KAAK+J,OAAS,EACd/J,KAAKgK,WAAa,EAGdrD,OAAOlF,OAIP,OAFAzB,KAAKqH,MAAQ,eAEL,GACJ,KAAKV,OAAOsD,MAAMC,MAAQC,OAAOC,UAAUF,OACvClK,KAAK2G,OAASA,OAAOnG,IAAIb,MAAQ,IAAImB,QAAQnB,OAC7CK,KAAKqK,aACL,MAEJ,KAAK1D,OAAOsD,MAAMhK,OAASA,iBAAiBa,SAAWb,iBAAiBR,WAAaQ,iBAAiBqK,WAClGtK,KAAK2G,OAASA,OACd3G,KAAKqK,aACL,MAEJ,QACI,MAAM,IAAI3I,MAAM,2DAMhChC,WAAY6K,MAAOC,UAEf,GAAkB,eAAdxK,KAAKqH,MAAT,CAIkB,eAAdrH,KAAKqH,QACLrH,KAAK2G,OAAO,GAAK,IAAI7F,QAAQyJ,OAC7BvK,KAAK2G,OAAO,GAAK,IAAI7F,QAAQ2I,KAAKgB,KAAKF,MAAMC,SAAW,EAAIA,SAAYf,KAAKiB,IAAIH,MAAMC,UAAW,EACtCD,MAAQC,WACpExK,KAAK2G,OAAO,GAAK,IAAI7F,QAAQ2I,KAAKgB,KAAKD,YAG3CxK,KAAKqH,MAAQ,cAEb,IAAK,IAAIsD,EAAE,EAAGA,EAAE3K,KAAK2G,OAAOlF,OAAQkJ,IAAK,CAErC,MAAM1K,MAAQD,KAAK2G,OAAOgE,GAEtB1K,iBAAiBa,UACjBd,KAAKmE,OAAOM,MAAM,aAAc,MAAO,SAAU,WAAYzE,KAAKG,YAAaF,MAAMN,OACrFK,KAAK4K,UAAU3K,MAAO0K,IAI9B3K,KAAKmE,OAAOM,MAAM,aAAc,MAAO,WAAYzE,KAAKG,eAG5DT,UAAWO,MAAOG,YAEdH,MAAMuB,IAAMxB,KACZC,MAAMG,WAAaA,WAEfA,aACAJ,KAAK2G,OAAOvG,WAAW,GAAGyK,WAAW5K,OACrCA,MAAM6K,WAAW9K,KAAKG,YAAaH,KAAK2G,OAAOvG,WAAW,GAAIA,YAC9DH,MAAMqB,QAId5B,QAASiB,MAEL,GAAgB,eAAZX,KAAKqH,MACL,MAAM,IAAI3F,MAAM,iDAGpB,QAAa8C,IAAT7D,MAA+B,OAATA,KACtB,MAAM,IAAIe,MAAM,uCAOpB,OAJIf,KAAKc,QAAUzB,KAAK2G,OAAO,GAAG5F,QAAQU,QACtCsJ,QAAQC,KAAK,8DAGVhJ,QAAQuE,YAAY,UAAW,SAAU,SAAU,UAAWvG,KAAKG,YAAaQ,OACnF2B,QAAS,UACTC,gBAAiBvC,KAAK2G,OAAO3G,KAAK2G,OAAOlF,OAAO,GAAGV,QAAQU,SAInE/B,MAAOiB,MAAMoJ,OAACA,OAAO,EAACkB,SAAEA,SAAQC,cAAEA,cAAc,EAACC,IAAEA,KAAI,OAKnD,OAHAD,cAAsC,kBAAfA,eAA4BA,cAAgBvK,KAAK,GAAG6J,SAAS/I,OAASyJ,cAC7FlL,KAAKmE,OAAOM,MAAM,oBAAqB,MAAO,SAAU,WAAYzE,KAAKG,YAAa+K,gBAE/E,IAAIE,QAAQ,CAACC,QAASC,UAEzB,QAAa9G,IAAT7D,MAA+B,OAATA,KACtB,YAAY2K,OAAO,oBAGL,eAAdtL,KAAKqH,OACLrH,KAAKqK,WAAW1J,KAAK,GAAG4J,MAAM9I,QAASd,KAAK,GAAG6J,UAAY7J,KAAK,GAAG4K,QAAQ9J,QAG/E,MAAM+J,UAAYpG,KAAKqG,MAEjBC,UAAY/K,KAAK,GAAG4J,MAAM9I,OAC1BkK,SAAWD,WAAa/K,KAAK,GAAG6J,UAAY7J,KAAK,GAAG4K,QAAQ9J,OAC5DmK,WAAaD,SAAWhL,KAAKc,OAE7BwC,WAAa,IAAIX,aAAasI,YAEhCT,KACAJ,QAAQI,iCAAiCpB,sBAAsBmB,iBAGnE,IAAK,IAAIW,GAAG,EAAGA,GAAGlL,KAAKc,OAAQoK,KAAM,CAEjC,IAAKlL,KAAKkL,IAAIC,eAAe,WAAcnL,KAAKkL,IAAIC,eAAe,cAAgBnL,KAAKkL,IAAIC,eAAe,UACvG,YAAYR,OAAO,sFAGvB,IAAIzC,MAAQ8C,SAASE,GAErB,IAAK,IAAIE,GAAG,EAAGA,GAAGpL,KAAKkL,IAAItB,MAAM9I,OAAQsK,KACrC9H,WAAW4E,OAASlI,KAAKkL,IAAItB,MAAMwB,IACnClD,QAGJ,IAAK,IAAImD,GAAG,EAAGA,IAAIrL,KAAKkL,IAAIrB,UAAY7J,KAAKkL,IAAIN,QAAQ9J,OAAQuK,KAC7D/H,WAAW4E,QAAUlI,KAAKkL,IAAIrB,UAAY7J,KAAKkL,IAAIN,QAAQS,IAC3DnD,QAIR,MAAM3E,IAAMlE,KAAKmE,OAAOC,QAAQH,WAAWxC,OAAOwC,WAAWI,mBAC7DrE,KAAKmE,OAAOd,QAAQiB,IAAIL,WAAYC,KAAO,GAE3C,IAAI+H,QAMJ,GAJAjM,KAAKmE,OAAOM,MAAM,mBAAoB,UAAW,SAAU,SAAU,SAAU,SAAU,WACxDzE,KAAKG,YAAa+D,IAAK0H,WAAYD,SAAUD,YAG1ET,SAAU,CAEV,IAAIiB,WAAa,EACbC,eAAiB,EAErB,MAAMC,QAAU,KAERpM,KAAKiH,KAAIjH,KAAKqM,QAAU,GACxBrM,KAAKkH,KAAIlH,KAAKsM,QAAU,GAE5BH,eAAiB,EACjBI,eAGEA,YAAc,KAEhBvM,KAAKmE,OAAOM,MAAM,QAAS,UAAW,SAAU,WAAYzE,KAAKG,YAAa+K,cAAeiB,iBAE7FlB,UACIjB,WAAamC,eAAe,EAC5BzI,MAAO1D,KAAK0D,MACZuI,QAAS7G,KAAKqG,MAAQD,UACtBjB,MAAO5J,KAAKX,KAAKgK,YAAYO,SAGjC4B,gBAAkBjB,eAEGvK,KAAKc,OACtB+K,WAAWD,YAAYhF,KAAKvH,MAAO,IAEnCkM,aAEAD,QAAU7G,KAAKqG,MAAQD,UAEvBL,KAAOJ,QAAQI,aAAae,qBAAqBlM,KAAK0D,aAAiBc,GAATxE,KAAKiH,GAAgB,iBAAkBjH,KAAKqM,QAAQF,iCACxFnK,QAAQiG,OAAOgE,QAAS,6BAA6BjK,QAAQiG,OAAOgE,QAAQC,WAAY,WAE9GA,WAAanC,OACbqC,UAEAf,YAIZe,cAEG,CACH,IAAK,IAAI1H,EAAE,EAAGA,EAAEqF,OAAQrF,IAEhB1E,KAAKiH,KAAIjH,KAAKqM,QAAU,GACxBrM,KAAKkH,KAAIlH,KAAKsM,QAAU,GAE5BtM,KAAKmE,OAAOM,MAAM,QAAS,UAAW,SAAU,WAAYzE,KAAKG,aAAc,EAAG,IAClF8L,QAAU7G,KAAKqG,MAAQD,UACnBL,KACAJ,QAAQI,aAAazG,EAAE,YAAY1E,KAAK0D,aAAiBc,GAATxE,KAAKiH,GAAgB,iBAAkBjH,KAAKqM,QAAQ1L,KAAKc,yBAC/EO,QAAQiG,OAAOgE,QAAS,6BAA6BjK,QAAQiG,OAAOgE,SAASvH,EAAE,GAAI,WAGrH1E,KAAKmE,OAAOS,MAAMV,KACdiH,KACAJ,QAAQI,sCAAsCnJ,QAAQiG,OAAOgE,QAAS,WAE1EZ,aAKZ3L,KAAMiB,MAAMwK,IAACA,KAAI,OACb,OAAO,IAAIC,QAAQ,CAACC,QAASC,eAEZ9G,IAAT7D,MAA+B,OAATA,MACtB2K,OAAO,oBAGPH,KACAJ,QAAQI,IAAI,mBAGhB,MAAMK,UAAYpG,KAAKqG,MACjBC,UAAY/K,KAAK,GAAG4J,MAAM9I,OAC1BkK,SAAWD,WAAa/K,KAAK,GAAG6J,UAAY7J,KAAK,GAAG4K,QAAQ9J,OAC5DmK,WAAaD,SAAWhL,KAAKc,OAC7BwC,WAAa,IAAIX,aAAasI,YAEpC,IAAK,IAAIC,GAAG,EAAGA,GAAGlL,KAAKc,OAAQoK,KAAM,CAEjC,IAAIhD,MAAQ8C,SAASE,GAErB,IAAK,IAAIE,GAAG,EAAGA,GAAGpL,KAAKkL,IAAItB,MAAM9I,OAAQsK,KACrC9H,WAAW4E,OAASlI,KAAKkL,IAAItB,MAAMwB,IACnClD,QAGJ,IAAK,IAAImD,GAAG,EAAGA,IAAIrL,KAAKkL,IAAIrB,UAAY7J,KAAKkL,IAAIN,QAAQ9J,OAAQuK,KAC7D/H,WAAW4E,QAAUlI,KAAKkL,IAAIrB,UAAY7J,KAAKkL,IAAIN,QAAQS,IAC3DnD,QAIR,MAAM3E,IAAMlE,KAAKmE,OAAOC,QAAQH,WAAWxC,OAAOwC,WAAWI,mBAC7DrE,KAAKmE,OAAOd,QAAQiB,IAAIL,WAAYC,KAAO,GAC3C,MAAMuI,SAAWzM,KAAKmE,OAAOM,MAAM,OAAQ,UAAW,SAAU,SAAU,SAAU,SAAU,WAC7DzE,KAAKG,YAAa+D,IAAK0H,WAAYD,SAAUD,YAC9E1L,KAAKmE,OAAOS,MAAMV,KAElB,MAAM+H,QAAU7G,KAAKqG,MAAQD,UAEzBL,KACAJ,QAAQI,qCAAqCnJ,QAAQiG,OAAOgE,QAAS,oCAAoCjK,QAAQiG,OAAOgE,QAAQtL,KAAKc,OAAQ,WAGjJ4J,QAAQoB,YAIhB/M,SACI,OACIiH,OAAQ3G,KAAK2G,OAAOnG,IAAIP,OAASA,MAAMyM,WAI/ChN,SAAUiB,MAEN,QAAa6D,IAAT7D,MAA+B,OAATA,KACtB,MAAM,IAAIe,MAAM,iCAGpB,GAAIf,KAAKgG,OAAOlF,QAAUzB,KAAK2G,OAAOlF,OAClC,MAAM,IAAIC,4BAA4Bf,KAAKgG,OAAOlF,qCAAqCzB,KAAK2G,OAAOlF,sBAGvGzB,KAAKmE,OAAOM,MAAM,oBAAqB,MAAO,WAAYzE,KAAKG,cAC/DH,KAAK2G,OAAOxF,QAAQ,CAAClB,MAAO0M,KAAOA,IAAM1M,MAAM2M,SAASjM,KAAKgG,OAAOgG,IAAKA,KAG7EE,qBACI,MAAO,SAIA,oBAARjM,SAAwBC,QAAQ2F,QAAUA,eAG3CtF,OAEFxB,eAEAA,KAAMS,YAAaC,WAAY0M,aAAavL,SAACA,WAMzC,OAJAS,QAAQ+K,oBAAoB/M,KAAM,WAAY,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,aAAc9M,KAAKL,MAC1HqC,QAAQkE,eAAelG,KAAM,QAAS,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,cAC/F9K,QAAQ+K,oBAAoB/M,KAAM,gBAAiB,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,aAAc9M,KAAKL,MAEvH4B,UACJ,IAAK,OACDS,QAAQkE,eAAelG,KAAM,YAAa,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,cACnG9K,QAAQ+K,oBAAoB/M,KAAM,cAAe,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,aAAc9M,KAAKL,MAC7H,MACJ,IAAK,UACL,IAAK,UACL,IAAK,WACDqC,QAAQkE,eAAelG,KAAM,aAAc,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,cACpG9K,QAAQ+K,oBAAoB/M,KAAM,gBAAiB,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,aAAc9M,KAAKL,MAEjH,YAAV4B,WACAS,QAAQkE,eAAelG,KAAM,qBAAsB,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,cAC5G9K,QAAQ+K,oBAAoB/M,KAAM,iBAAkB,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,aAAc9M,KAAKL,OAEpI,MAEJ,IAAK,OACDqC,QAAQkE,eAAelG,KAAM,KAAM,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,cAC5F9K,QAAQkE,eAAelG,KAAM,KAAM,SAAU,SAAU,WAAYG,YAAaC,WAAY0M,gBAQ7F,oBAARlM,SAAwBC,QAAQK,OAASA,cAG1CoJ,WAIS,oBAAR1J,SAAwBC,QAAQyJ,UAAYA","file":"jsNetWebAssembly.min.js","sourcesContent":["\"use strict\"\r\n\r\nclass ConvLayer {\r\n\r\n    constructor (size, {filterSize, zeroPadding, stride, activation}={}) {\r\n\r\n        if (filterSize)     this.filterSize = filterSize\r\n        if (stride)         this.stride = stride\r\n        if (size)           this.size = size\r\n\r\n        this.zeroPadding = zeroPadding\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (netInstance, layer, layerIndex) {\r\n\r\n        this.netInstance = netInstance\r\n        this.prevLayer = layer\r\n        this.layerIndex = layerIndex\r\n\r\n    }\r\n\r\n    init () {\r\n\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.filters.map(filter => {\r\n                return {\r\n                    bias: filter.bias,\r\n                    weights: filter.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n\r\n    }\r\n\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.ConvLayer = ConvLayer)\r\n\r\n\"use strict\"\r\n\r\nclass FCLayer {\r\n\r\n    constructor (size) {\r\n        this.size = size\r\n        this.neurons = [...new Array(size)].map(n => new Neuron())\r\n        this.layerIndex = 0\r\n    }\r\n\r\n    assignNext (layer) {\r\n        this.nextLayer = layer\r\n    }\r\n\r\n    assignPrev (netInstance, layer, layerIndex) {\r\n        this.netInstance = netInstance\r\n        this.prevLayer = layer\r\n        this.layerIndex = layerIndex\r\n    }\r\n\r\n    init () {\r\n        this.neurons.forEach((neuron, ni) => {\r\n            switch (true) {\r\n\r\n                case this.prevLayer instanceof FCLayer:\r\n                    neuron.size = this.prevLayer.size\r\n                    break\r\n            }\r\n\r\n            neuron.init(this.netInstance, this.layerIndex, ni, {\r\n                updateFn: this.net.updateFn\r\n            })\r\n        })\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            weights: this.neurons.map(neuron => {\r\n                return {\r\n                    bias: neuron.bias,\r\n                    weights: neuron.weights\r\n                }\r\n            })\r\n        }\r\n    }\r\n\r\n    fromJSON (data, layerIndex) {\r\n\r\n        this.neurons.forEach((neuron, ni) => {\r\n\r\n            if (data.weights[ni].weights.length!=(neuron.weights).length) {\r\n                throw new Error(`Mismatched weights count. Given: ${data.weights[ni].weights.length} Existing: ${neuron.weights.length}. At layers[${layerIndex}], neurons[${ni}]`)\r\n            }\r\n\r\n            neuron.bias = data.weights[ni].bias\r\n            neuron.weights = data.weights[ni].weights\r\n        })\r\n    }\r\n}\r\n\r\nconst Layer = FCLayer\r\n\r\ntypeof window==\"undefined\" && (exports.FCLayer = exports.Layer = FCLayer)\r\n\"use strict\"\r\n\r\nclass NetMath {\r\n    static softmax (values) {\r\n        let total = 0\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            total += values[i]\r\n        }\r\n\r\n        for (let i=0; i<values.length; i++) {\r\n            if (total) {\r\n                values[i] /= total\r\n            }\r\n        }\r\n\r\n        return values\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetMath = NetMath)\r\n\"use strict\"\r\n\r\nclass NetUtil {\r\n\r\n    static ccallArrays (func, returnType, paramTypes, params, {heapIn=\"HEAPF32\", heapOut=\"HEAPF32\", returnArraySize=1}={}) {\r\n\r\n        const heapMap = {}\r\n        heapMap.HEAP8 = Int8Array // int8_t\r\n        heapMap.HEAPU8 = Uint8Array // uint8_t\r\n        heapMap.HEAP16 = Int16Array // int16_t\r\n        heapMap.HEAPU16 = Uint16Array // uint16_t\r\n        heapMap.HEAP32 = Int32Array // int32_t\r\n        heapMap.HEAPU32 = Uint32Array // uint32_t\r\n        heapMap.HEAPF32 = Float32Array // float\r\n        heapMap.HEAPF64 = Float64Array // double\r\n\r\n        let res\r\n        let error\r\n        paramTypes = paramTypes || []\r\n        const returnTypeParam = returnType==\"array\" ? \"number\" : returnType\r\n        const parameters = []\r\n        const parameterTypes = []\r\n        const bufs = []\r\n\r\n        try {\r\n            if (params) {\r\n                for (let p=0; p<params.length; p++) {\r\n\r\n                    if (paramTypes[p] == \"array\" || Array.isArray(params[p])) {\r\n\r\n                        const typedArray = new heapMap[heapIn](params[p].length)\r\n\r\n                        for (let i=0; i<params[p].length; i++) {\r\n                            typedArray[i] = params[p][i]\r\n                        }\r\n\r\n                        const buf = NetUtil.Module._malloc(typedArray.length * typedArray.BYTES_PER_ELEMENT)\r\n\r\n                        switch (heapIn) {\r\n                            case \"HEAP8\": case \"HEAPU8\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf)\r\n                                break\r\n                            case \"HEAP16\": case \"HEAPU16\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 1)\r\n                                break\r\n                            case \"HEAP32\": case \"HEAPU32\": case \"HEAPF32\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 2)\r\n                                break\r\n                            case \"HEAPF64\":\r\n                                NetUtil.Module[heapIn].set(typedArray, buf >> 3)\r\n                                break\r\n                        }\r\n\r\n                        bufs.push(buf)\r\n                        parameters.push(buf)\r\n                        parameters.push(params[p].length)\r\n                        parameterTypes.push(\"number\")\r\n                        parameterTypes.push(\"number\")\r\n\r\n                    } else {\r\n                        parameters.push(params[p])\r\n                        parameterTypes.push(paramTypes[p]==undefined ? \"number\" : paramTypes[p])\r\n                    }\r\n                }\r\n            }\r\n\r\n            res = NetUtil.Module.ccall(func, returnTypeParam, parameterTypes, parameters)\r\n        } catch (e) {\r\n            error = e\r\n        } finally {\r\n            for (let b=0; b<bufs.length; b++) {\r\n                NetUtil.Module._free(bufs[b])\r\n            }\r\n        }\r\n\r\n        if (error) throw error\r\n\r\n\r\n        if (returnType==\"array\") {\r\n            const returnData = []\r\n\r\n            for (let v=0; v<returnArraySize; v++) {\r\n                returnData.push(NetUtil.Module[heapOut][res/heapMap[heapOut].BYTES_PER_ELEMENT+v])\r\n            }\r\n\r\n            return returnData\r\n        } else {\r\n            return res\r\n        }\r\n    }\r\n\r\n    static format (value, type=\"string\") {\r\n        switch (true) {\r\n\r\n            case type==\"string\" && typeof value==\"string\":\r\n                value = value.replace(/(_|\\s)/g, \"\").toLowerCase()\r\n                break\r\n\r\n            case type==\"time\" && typeof value==\"number\":\r\n                const date = new Date(value)\r\n                const formatted = []\r\n\r\n                if (value < 1000) {\r\n                    formatted.push(`${date.getMilliseconds()}ms`)\r\n\r\n                } else if (value < 60000) {\r\n                    formatted.push(`${date.getSeconds()}.${date.getMilliseconds()}s`)\r\n\r\n                } else {\r\n\r\n                    if (value >= 3600000) formatted.push(`${date.getHours()}h`)\r\n\r\n                    formatted.push(`${date.getMinutes()}m`)\r\n                    formatted.push(`${date.getSeconds()}s`)\r\n                }\r\n\r\n                value = formatted.join(\" \")\r\n                break\r\n        }\r\n\r\n        return value\r\n    }\r\n\r\n    static defineProperty (self, prop, valTypes=[], values=[], {getCallback=x=>x, setCallback=x=>x}={}) {\r\n        Object.defineProperty(self, prop, {\r\n            get: () => getCallback(this.Module.ccall(`get_${prop}`, \"number\", valTypes, values)),\r\n            set: val => this.Module.ccall(`set_${prop}`, null, valTypes.concat(\"number\"), values.concat(setCallback(val)))\r\n        })\r\n    }\r\n\r\n    static defineArrayProperty (self, prop, valTypes, values, returnSize) {\r\n        Object.defineProperty(self, prop, {\r\n            get: () => NetUtil.ccallArrays(`get_${prop}`, \"array\", valTypes, values, {returnArraySize: returnSize, heapOut: \"HEAPF64\"}),\r\n            set: (value) => NetUtil.ccallArrays(`set_${prop}`, null, valTypes.concat(\"array\"), values.concat([value]), {heapIn: \"HEAPF64\"})\r\n        })\r\n    }\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.NetUtil = NetUtil)\r\n\"use strict\"\r\n\r\nclass Network {\r\n\r\n    constructor ({Module, learningRate, activation=\"sigmoid\", updateFn=\"vanillaupdatefn\", cost=\"meansquarederror\", layers=[],\r\n        rmsDecay, rho, lreluSlope, eluAlpha, dropout=1, l2=true, l1=true, maxNorm, weightsConfig}) {\r\n\r\n        if (!Module) {\r\n            throw new Error(\"WASM module not provided\")\r\n        }\r\n\r\n        if (typeof activation == \"function\" || typeof cost == \"function\") {\r\n            throw new Error(\"Custom functions are not (yet) supported with WASM.\")\r\n        }\r\n\r\n        NetUtil.Module = Module\r\n        this.Module = Module\r\n        this.netInstance = this.Module.ccall(\"newNetwork\", null, null, null)\r\n        this.state = \"not-defined\"\r\n\r\n        // Learning Rate get / set\r\n        Object.defineProperty(this, \"learningRate\", {\r\n            get: this.Module.cwrap(\"getLearningRate\", null, null).bind(this, this.netInstance),\r\n            set: this.Module.cwrap(\"setLearningRate\", \"number\", null).bind(this, this.netInstance)\r\n        })\r\n\r\n        if (learningRate) this.learningRate = learningRate\r\n\r\n        NetUtil.defineProperty(this, \"dropout\", [\"number\"], [this.netInstance])\r\n        this.dropout = dropout==false ? 1 : dropout\r\n\r\n        if (l2) {\r\n            NetUtil.defineProperty(this, \"l2\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"l2Error\", [\"number\"], [this.netInstance])\r\n            this.l2 = typeof l2==\"boolean\" ? 0.001 : l2\r\n        }\r\n\r\n        if (l1) {\r\n            NetUtil.defineProperty(this, \"l1\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"l1Error\", [\"number\"], [this.netInstance])\r\n            this.l1 = typeof l1==\"boolean\" ? 0.005 : l1\r\n        }\r\n\r\n        if (maxNorm) {\r\n            NetUtil.defineProperty(this, \"maxNorm\", [\"number\"], [this.netInstance])\r\n            NetUtil.defineProperty(this, \"maxNormTotal\", [\"number\"], [this.netInstance])\r\n            this.maxNorm = typeof maxNorm==\"boolean\" && maxNorm ? 1000 : maxNorm\r\n        }\r\n\r\n        Object.defineProperty(this, \"error\", {\r\n            get: () => Module.ccall(\"getError\", \"number\", [\"number\"], [this.netInstance])\r\n        })\r\n\r\n        // Activation function get / set\r\n        const activationsIndeces = {\r\n            sigmoid: 0,\r\n            tanh: 1,\r\n            lecuntanh: 2,\r\n            relu: 3,\r\n            lrelu: 4,\r\n            rrelu: 5,\r\n            elu: 6\r\n        }\r\n        let activationName = NetUtil.format(activation)\r\n        Object.defineProperty(this, \"activation\", {\r\n            get: () => `WASM ${activationName}`,\r\n            set: activation => {\r\n\r\n                if (activationsIndeces[activation] == undefined) {\r\n                    throw new Error(`The ${activation} activation function does not exist`)\r\n                }\r\n                activationName = activation\r\n                this.Module.ccall(\"setActivation\", null, [\"number\", \"number\"], [this.netInstance, activationsIndeces[activation]])\r\n            }\r\n        })\r\n        this.activation = activationName\r\n\r\n        // Cost function get / set\r\n        const costIndeces = {\r\n            meansquarederror: 0,\r\n            crossentropy: 1\r\n        }\r\n        let costFunctionName = NetUtil.format(cost)\r\n        Object.defineProperty(this, \"cost\", {\r\n            get: () => `WASM ${costFunctionName}`,\r\n            set: cost => {\r\n                if (costIndeces[cost] == undefined) {\r\n                    throw new Error(`The ${cost} function does not exist`)\r\n                }\r\n                costFunctionName = cost\r\n                this.Module.ccall(\"setCostFunction\", null, [\"number\", \"number\"], [this.netInstance, costIndeces[cost]])\r\n            }\r\n        })\r\n        this.cost = costFunctionName\r\n\r\n        const updateFnIndeces = {\r\n            vanillaupdatefn: 0,\r\n            gain: 1,\r\n            adagrad: 2,\r\n            rmsprop: 3,\r\n            adam: 4,\r\n            adadelta: 5\r\n        }\r\n        NetUtil.defineProperty(this, \"updateFn\", [\"number\"], [this.netInstance], {\r\n            getCallback: index => Object.keys(updateFnIndeces).find(key => updateFnIndeces[key]==index),\r\n            setCallback: name => updateFnIndeces[name]\r\n        })\r\n        this.updateFn = NetUtil.format(updateFn)\r\n\r\n\r\n        // Weights init configs\r\n        const weightsConfigFns = {\r\n            uniform: 0,\r\n            gaussian: 1,\r\n            xavieruniform: 2,\r\n            xaviernormal: 3,\r\n            lecununiform: 4,\r\n            lecunnormal: 5\r\n        }\r\n        this.weightsConfig = {}\r\n\r\n        NetUtil.defineProperty(this.weightsConfig, \"distribution\", [\"number\"], [this.netInstance], {\r\n            getCallback: index => Object.keys(weightsConfigFns).find(key => weightsConfigFns[key]==Math.round(index)),\r\n            setCallback: name => weightsConfigFns[name]\r\n        })\r\n        NetUtil.defineProperty(this.weightsConfig, \"limit\", [\"number\"], [this.netInstance])\r\n        NetUtil.defineProperty(this.weightsConfig, \"mean\", [\"number\"], [this.netInstance])\r\n        NetUtil.defineProperty(this.weightsConfig, \"stdDeviation\", [\"number\"], [this.netInstance])\r\n\r\n        this.weightsConfig.distribution = \"xavieruniform\"\r\n\r\n        if (weightsConfig!=undefined && weightsConfig.distribution) {\r\n\r\n            if (typeof weightsConfig.distribution == \"function\") {\r\n                throw new Error(\"Custom weights init functions are not (yet) supported with WASM.\")\r\n            }\r\n\r\n            this.weightsConfig.distribution = NetUtil.format(weightsConfig.distribution)\r\n        }\r\n\r\n        this.weightsConfig.limit = weightsConfig && weightsConfig.limit!=undefined ? weightsConfig.limit : 0.1\r\n        this.weightsConfig.mean = weightsConfig && weightsConfig.mean!=undefined ? weightsConfig.mean : 0\r\n        this.weightsConfig.stdDeviation = weightsConfig && weightsConfig.stdDeviation!=undefined ? weightsConfig.stdDeviation : 0.05\r\n\r\n        switch (NetUtil.format(updateFn)) {\r\n\r\n            case \"rmsprop\":\r\n                this.learningRate = this.learningRate==undefined ? 0.001 : this.learningRate\r\n                break\r\n\r\n            case \"adam\":\r\n                this.learningRate = this.learningRate==undefined ? 0.01 : this.learningRate\r\n                break\r\n\r\n            case \"adadelta\":\r\n                NetUtil.defineProperty(this, \"rho\", [\"number\"], [this.netInstance])\r\n                this.rho = rho==null ? 0.95 : rho\r\n                break\r\n\r\n            default:\r\n\r\n                if (learningRate==undefined) {\r\n\r\n                    switch (activationName) {\r\n                        case \"relu\":\r\n                        case \"lrelu\":\r\n                        case \"rrelu\":\r\n                        case \"elu\":\r\n                            this.learningRate = 0.01\r\n                            break\r\n\r\n                        case \"tanh\":\r\n                        case \"lecuntanh\":\r\n                            this.learningRate = 0.001\r\n                            break\r\n\r\n                        default:\r\n                            this.learningRate = 0.2\r\n                    }\r\n                }\r\n        }\r\n\r\n        if (this.updateFn==\"rmsprop\") {\r\n            NetUtil.defineProperty(this, \"rmsDecay\", [\"number\"], [this.netInstance])\r\n            this.rmsDecay = rmsDecay===undefined ? 0.99 : rmsDecay\r\n        }\r\n\r\n        if (activationName==\"lrelu\") {\r\n            NetUtil.defineProperty(this, \"lreluSlope\", [\"number\"], [this.netInstance])\r\n            this.lreluSlope = lreluSlope==undefined ? -0.0005 : lreluSlope\r\n        } else if (activationName==\"elu\") {\r\n            NetUtil.defineProperty(this, \"eluAlpha\", [\"number\"], [this.netInstance])\r\n            this.eluAlpha = eluAlpha==undefined ? 1 : eluAlpha\r\n        }\r\n\r\n        this.layers = []\r\n        this.epochs = 0\r\n        this.iterations = 0\r\n\r\n\r\n        if (layers.length) {\r\n\r\n            this.state = \"constructed\"\r\n\r\n            switch (true) {\r\n                case layers.every(item => Number.isInteger(item)):\r\n                    this.layers = layers.map(size => new FCLayer(size))\r\n                    this.initLayers()\r\n                    break\r\n\r\n                case layers.every(layer => layer instanceof FCLayer || layer instanceof ConvLayer || layer instanceof PoolLayer):\r\n                    this.layers = layers\r\n                    this.initLayers()\r\n                    break\r\n\r\n                default:\r\n                    throw new Error(\"There was an error constructing from the layers given.\")\r\n\r\n            }\r\n        }\r\n    }\r\n\r\n    initLayers (input, expected) {\r\n\r\n        if (this.state == \"initialised\") {\r\n            return\r\n        }\r\n\r\n        if (this.state == \"not-defined\") {\r\n            this.layers[0] = new FCLayer(input)\r\n            this.layers[1] = new FCLayer(Math.ceil(input/expected > 5 ? expected + (Math.abs(input-expected))/4\r\n                                                                      : input + expected))\r\n            this.layers[2] = new FCLayer(Math.ceil(expected))\r\n        }\r\n\r\n        this.state = \"initialised\"\r\n\r\n        for (let l=0; l<this.layers.length; l++) {\r\n\r\n            const layer = this.layers[l]\r\n\r\n            if (layer instanceof FCLayer) {\r\n                this.Module.ccall(\"addFCLayer\", null, [\"number\", \"number\"], [this.netInstance, layer.size])\r\n                this.joinLayer(layer, l)\r\n            }\r\n        }\r\n\r\n        this.Module.ccall(\"initLayers\", null, [\"number\"], [this.netInstance])\r\n    }\r\n\r\n    joinLayer (layer, layerIndex) {\r\n\r\n        layer.net = this\r\n        layer.layerIndex = layerIndex\r\n\r\n        if (layerIndex) {\r\n            this.layers[layerIndex-1].assignNext(layer)\r\n            layer.assignPrev(this.netInstance, this.layers[layerIndex-1], layerIndex)\r\n            layer.init()\r\n        }\r\n    }\r\n\r\n    forward (data) {\r\n\r\n        if (this.state!=\"initialised\") {\r\n            throw new Error(\"The network layers have not been initialised.\")\r\n        }\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No data passed to Network.forward()\")\r\n        }\r\n\r\n        if (data.length != this.layers[0].neurons.length) {\r\n            console.warn(\"Input data length did not match input layer neurons count.\")\r\n        }\r\n\r\n        return NetUtil.ccallArrays(\"forward\", \"array\", [\"number\", \"array\"], [this.netInstance, data], {\r\n            heapOut: \"HEAPF64\",\r\n            returnArraySize: this.layers[this.layers.length-1].neurons.length\r\n        })\r\n    }\r\n\r\n    train (data, {epochs=1, callback, miniBatchSize=1, log=true}={}) {\r\n\r\n        miniBatchSize = typeof miniBatchSize==\"boolean\" && miniBatchSize ? data[0].expected.length : miniBatchSize\r\n        this.Module.ccall(\"set_miniBatchSize\", null, [\"number\", \"number\"], [this.netInstance, miniBatchSize])\r\n\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (data === undefined || data === null) {\r\n                return void reject(\"No data provided\")\r\n            }\r\n\r\n            if (this.state != \"initialised\") {\r\n                this.initLayers(data[0].input.length, (data[0].expected || data[0].output).length)\r\n            }\r\n\r\n            const startTime = Date.now()\r\n\r\n            const dimension = data[0].input.length\r\n            const itemSize = dimension + (data[0].expected || data[0].output).length\r\n            const itemsCount = itemSize * data.length\r\n\r\n            const typedArray = new Float32Array(itemsCount)\r\n\r\n            if (log) {\r\n                console.log(`Training started. Epochs: ${epochs} Batch size: ${miniBatchSize}`)\r\n            }\r\n\r\n            for (let di=0; di<data.length; di++) {\r\n\r\n                if (!data[di].hasOwnProperty(\"input\") || (!data[di].hasOwnProperty(\"expected\") && !data[di].hasOwnProperty(\"output\"))) {\r\n                    return void reject(\"Data set must be a list of objects with keys: 'input' and 'expected' (or 'output')\")\r\n                }\r\n\r\n                let index = itemSize*di\r\n\r\n                for (let ii=0; ii<data[di].input.length; ii++) {\r\n                    typedArray[index] = data[di].input[ii]\r\n                    index++\r\n                }\r\n\r\n                for (let ei=0; ei<(data[di].expected || data[di].output).length; ei++) {\r\n                    typedArray[index] = (data[di].expected || data[di].output)[ei]\r\n                    index++\r\n                }\r\n            }\r\n\r\n            const buf = this.Module._malloc(typedArray.length*typedArray.BYTES_PER_ELEMENT)\r\n            this.Module.HEAPF32.set(typedArray, buf >> 2)\r\n\r\n            let elapsed\r\n\r\n            this.Module.ccall(\"loadTrainingData\", \"number\", [\"number\", \"number\", \"number\", \"number\", \"number\"],\r\n                                            [this.netInstance, buf, itemsCount, itemSize, dimension])\r\n\r\n\r\n            if (callback) {\r\n\r\n                let epochIndex = 0\r\n                let iterationIndex = 0\r\n\r\n                const doEpoch = () => {\r\n\r\n                    if (this.l2) this.l2Error = 0\r\n                    if (this.l1) this.l1Error = 0\r\n\r\n                    iterationIndex = 0\r\n                    doIteration()\r\n                }\r\n\r\n                const doIteration = () => {\r\n\r\n                    this.Module.ccall(\"train\", \"number\", [\"number\", \"number\"], [this.netInstance, miniBatchSize, iterationIndex])\r\n\r\n                    callback({\r\n                        iterations: (iterationIndex+1),\r\n                        error: this.error,\r\n                        elapsed: Date.now() - startTime,\r\n                        input: data[this.iterations].input\r\n                    })\r\n\r\n                    iterationIndex += miniBatchSize\r\n\r\n                    if (iterationIndex < data.length) {\r\n                        setTimeout(doIteration.bind(this), 0)\r\n                    } else {\r\n                        epochIndex++\r\n\r\n                        elapsed = Date.now() - startTime\r\n\r\n                        log && console.log(`Epoch ${epochIndex} Error: ${this.error}${this.l2==undefined ? \"\": ` L2 Error: ${this.l2Error/iterationIndex}`}`,\r\n                                    `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/epochIndex, \"time\")}`)\r\n\r\n                        if (epochIndex < epochs) {\r\n                            doEpoch()\r\n                        } else {\r\n                            resolve()\r\n                        }\r\n                    }\r\n                }\r\n                doEpoch()\r\n\r\n            } else {\r\n                for (let e=0; e<epochs; e++) {\r\n\r\n                    if (this.l2) this.l2Error = 0\r\n                    if (this.l1) this.l1Error = 0\r\n\r\n                    this.Module.ccall(\"train\", \"number\", [\"number\", \"number\"], [this.netInstance, -1, 0])\r\n                    elapsed = Date.now() - startTime\r\n                    if (log) {\r\n                        console.log(`Epoch ${e+1} Error: ${this.error}${this.l2==undefined ? \"\": ` L2 Error: ${this.l2Error/data.length}`}`,\r\n                                    `\\nElapsed: ${NetUtil.format(elapsed, \"time\")} Average Duration: ${NetUtil.format(elapsed/(e+1), \"time\")}`)\r\n                    }\r\n                }\r\n                this.Module._free(buf)\r\n                if (log) {\r\n                    console.log(`Training finished. Total time: ${NetUtil.format(elapsed, \"time\")}`)\r\n                }\r\n                resolve()\r\n            }\r\n        })\r\n    }\r\n\r\n    test (data, {log=true}={}) {\r\n        return new Promise((resolve, reject) => {\r\n\r\n            if (data === undefined || data === null) {\r\n                reject(\"No data provided\")\r\n            }\r\n\r\n            if (log) {\r\n                console.log(\"Testing started\")\r\n            }\r\n\r\n            const startTime = Date.now()\r\n            const dimension = data[0].input.length\r\n            const itemSize = dimension + (data[0].expected || data[0].output).length\r\n            const itemsCount = itemSize * data.length\r\n            const typedArray = new Float32Array(itemsCount)\r\n\r\n            for (let di=0; di<data.length; di++) {\r\n\r\n                let index = itemSize*di\r\n\r\n                for (let ii=0; ii<data[di].input.length; ii++) {\r\n                    typedArray[index] = data[di].input[ii]\r\n                    index++\r\n                }\r\n\r\n                for (let ei=0; ei<(data[di].expected || data[di].output).length; ei++) {\r\n                    typedArray[index] = (data[di].expected || data[di].output)[ei]\r\n                    index++\r\n                }\r\n            }\r\n\r\n            const buf = this.Module._malloc(typedArray.length*typedArray.BYTES_PER_ELEMENT)\r\n            this.Module.HEAPF32.set(typedArray, buf >> 2)\r\n            const avgError = this.Module.ccall(\"test\", \"number\", [\"number\", \"number\", \"number\", \"number\", \"number\"],\r\n                                            [this.netInstance, buf, itemsCount, itemSize, dimension])\r\n            this.Module._free(buf)\r\n\r\n            const elapsed = Date.now() - startTime\r\n\r\n            if (log) {\r\n                console.log(`Testing finished. Total time: ${NetUtil.format(elapsed, \"time\")}  Average iteration time: ${NetUtil.format(elapsed/data.length, \"time\")}`)\r\n            }\r\n\r\n            resolve(avgError)\r\n        })\r\n    }\r\n\r\n    toJSON () {\r\n        return {\r\n            layers: this.layers.map(layer => layer.toJSON())\r\n        }\r\n    }\r\n\r\n    fromJSON (data) {\r\n\r\n        if (data === undefined || data === null) {\r\n            throw new Error(\"No JSON data given to import.\")\r\n        }\r\n\r\n        if (data.layers.length != this.layers.length) {\r\n            throw new Error(`Mismatched layers (${data.layers.length} layers in import data, but ${this.layers.length} configured)`)\r\n        }\r\n\r\n        this.Module.ccall(\"resetDeltaWeights\", null, [\"number\"], [this.netInstance])\r\n        this.layers.forEach((layer, li) => li && layer.fromJSON(data.layers[li], li))\r\n    }\r\n\r\n    static get version () {\r\n        return \"2.1.1\"\r\n    }\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Network = Network)\r\n\"use strict\"\r\n\r\nclass Neuron {\r\n\r\n    constructor () {}\r\n\r\n    init (netInstance, layerIndex, neuronIndex, {updateFn}) {\r\n\r\n        NetUtil.defineArrayProperty(this, \"weights\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n        NetUtil.defineProperty(this, \"bias\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n        NetUtil.defineArrayProperty(this, \"deltaWeights\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n\r\n        switch (updateFn) {\r\n            case \"gain\":\r\n                NetUtil.defineProperty(this, \"biasGain\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineArrayProperty(this, \"weightGain\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n                break\r\n            case \"adagrad\":\r\n            case \"rmsprop\":\r\n            case \"adadelta\":\r\n                NetUtil.defineProperty(this, \"biasCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineArrayProperty(this, \"weightsCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n\r\n                if (updateFn==\"adadelta\") {\r\n                    NetUtil.defineProperty(this, \"adadeltaBiasCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                    NetUtil.defineArrayProperty(this, \"adadeltaCache\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex], this.size)\r\n                }\r\n                break\r\n\r\n            case \"adam\":\r\n                NetUtil.defineProperty(this, \"m\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                NetUtil.defineProperty(this, \"v\", [\"number\", \"number\", \"number\"], [netInstance, layerIndex, neuronIndex])\r\n                break\r\n        }\r\n\r\n    }\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.Neuron = Neuron)\r\n\"use strict\"\r\n\r\nclass PoolLayer {\r\n\r\n}\r\n\r\ntypeof window==\"undefined\" && (exports.PoolLayer = PoolLayer)\r\n\n//# sourceMappingURL=jsNetWebAssembly.concat.js.map"]}